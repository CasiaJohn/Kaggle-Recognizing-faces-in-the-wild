{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/c/recognizing-faces-in-the-wild/leaderboard#score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "id": "vV8ptKK6Dbut",
    "outputId": "f9c5a88b-b670-454f-caf9-e6182a4c0f11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
      "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-2it25gf5\n",
      "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-2it25gf5\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.3.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.8.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (4.3.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (3.13)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->keras-vggface==0.6) (0.46)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.1.0)\n",
      "Building wheels for collected packages: keras-vggface\n",
      "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8311 sha256=538ecb81019b212fb7087bb7d1c445f3b3f671c1e7c6ffa3855cb5a09bfd1831\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nzazqyah/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
      "Successfully built keras-vggface\n",
      "Installing collected packages: keras-vggface\n",
      "Successfully installed keras-vggface-0.6\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/rcmalli/keras-vggface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "oS3FKkpct-L7",
    "outputId": "b60c907a-16c8-447d-cfc4-9a75d88ee697"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from random import choice, sample\n",
    "\n",
    "from keras_vggface.utils import preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def auroc(y_true, y_pred):\n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "! pip install joblib\n",
    "import joblib\n",
    "\n",
    "import cv2\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Input, Dense, Flatten, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract, Add, Conv2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "#from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import h5py\n",
    "\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UJJX7UEAU2vH",
    "outputId": "dbeb1d80-912b-4441-dcd1-7030033600e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pandas' from '/usr/local/lib/python3.6/dist-packages/pandas/__init__.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cx9PRveJU24L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "pOlij-RXupe4",
    "outputId": "448a5d99-fc2a-4770-938b-db45c3ca0575"
   },
   "outputs": [],
   "source": [
    "! pip show cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3MLi3il-uDLf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "Y9_TzvWYutMh",
    "outputId": "82af7bd6-4b43-47d7-e8d0-9f4acb64fb62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Kl8RmF0t-MQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QmLvfdbcxRm"
   },
   "source": [
    "### Preparing files for dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBoPRw7ht-MZ"
   },
   "outputs": [],
   "source": [
    "train_file_path = \"drive/My Drive/Face_recognition/train_relationships.csv\"\n",
    "train_folders_path = \"drive/My Drive/Face_recognition/train/\"\n",
    "val_famillies = \"F09\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "g7n2pStzuoy9",
    "outputId": "ba8c90f5-40e4-4c8c-9378-dc56b60202cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drive/My Drive/Face_recognition/train/F0009/MID4/P00089_face4.jpg',\n",
       " 'drive/My Drive/Face_recognition/train/F0009/MID4/P11720_face2.jpg',\n",
       " 'drive/My Drive/Face_recognition/train/F0009/MID4/P10574_face5.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images = glob(train_folders_path + \"*/*/*.jpg\")\n",
    "all_images[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "TR-IW-46t-Mj",
    "outputId": "919c6d6f-43ea-4515-bcf9-bde9bbb34651"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drive/My Drive/Face_recognition/train/F0009/MID4/P00089_face4.jpg',\n",
       " 'drive/My Drive/Face_recognition/train/F0009/MID4/P11720_face2.jpg',\n",
       " 'drive/My Drive/Face_recognition/train/F0009/MID4/P10574_face5.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images = glob(train_folders_path + \"*/*/*.jpg\")\n",
    "all_images = list(map(lambda x:x.replace(\"\\\\\",\"/\"),all_images))\n",
    "all_images[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NOf9pPNva80A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05xZv60Ft-NP"
   },
   "outputs": [],
   "source": [
    "#all_images[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SD4apYhKnRdU"
   },
   "outputs": [],
   "source": [
    "#Code inspiration link : https://www.kaggle.com/hsinwenchang/vggface-baseline-197x197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "5AL3CaK3t-NX",
    "outputId": "131404a4-958c-4722-c289-9576e4a85e54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11252\n",
      "1147\n",
      "drive/My Drive/Face_recognition/train/F0009/MID4/P00089_face4.jpg\n",
      "F0009/MID4\n"
     ]
    }
   ],
   "source": [
    "train_images = [x for x in all_images if val_famillies not in x]\n",
    "val_images = [x for x in all_images if val_famillies in x]\n",
    "print(len(train_images))\n",
    "print(len(val_images))\n",
    "print(all_images[0])\n",
    "print(all_images[0].split(\"/\")[-3] + \"/\" + all_images[0].split(\"/\")[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "YsgM5B8-aECy",
    "outputId": "f7af5f35-1a3f-43d4-ce3f-f5bcb3def7cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drive/My Drive/Face_recognition/train/F1000/MID5/P10586_face1.jpg',\n",
       " 'drive/My Drive/Face_recognition/train/F1000/MID3/P10578_face2.jpg',\n",
       " 'drive/My Drive/Face_recognition/train/F1000/MID6/P10584_face1.jpg']"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "FCeHUwGUt-Ni",
    "outputId": "afa139c5-980a-4170-a654-06edaf834458"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F0009/MID4',\n",
       " 'F0009/MID4',\n",
       " 'F0009/MID4',\n",
       " 'F0009/MID4',\n",
       " 'F0009/MID4',\n",
       " 'F0009/MID4',\n",
       " 'F0009/MID4',\n",
       " 'F0009/MID4',\n",
       " 'F0009/MID4',\n",
       " 'F0009/MID4']"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_person_to_images_map = defaultdict(list)\n",
    "ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images]\n",
    "ppl[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6r53IEMt-N5"
   },
   "outputs": [],
   "source": [
    "for sample_img in train_images:\n",
    "    train_person_to_images_map[sample_img.split(\"/\")[-3] + \"/\" + sample_img.split(\"/\")[-2]].append(sample_img)\n",
    "    \n",
    "val_person_to_images_map = defaultdict(list)\n",
    "for sample_img in val_images:\n",
    "    val_person_to_images_map[sample_img.split(\"/\")[-3] + \"/\" + sample_img.split(\"/\")[-2]].append(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1la-76Mt-OD"
   },
   "outputs": [],
   "source": [
    "train_person_to_images_map = dict(train_person_to_images_map)\n",
    "val_person_to_images_map = dict(val_person_to_images_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VK-cWD4ft-OR"
   },
   "outputs": [],
   "source": [
    "#'F0002\\MID1' in val_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkmari9Ht-OZ"
   },
   "outputs": [],
   "source": [
    "#val_person_to_images_map[list(val_person_to_images_map.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfmVH84mt-Oo"
   },
   "outputs": [],
   "source": [
    "for k in val_person_to_images_map.keys():\n",
    "    if len(val_person_to_images_map[k]) == 0:\n",
    "        print(\"VAL Damn\")\n",
    "        print(k)\n",
    "for k in train_person_to_images_map.keys():\n",
    "    if len(train_person_to_images_map[k]) == 0:\n",
    "        print(\"Train Damn\")\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BM6FM6rwt-Ov"
   },
   "outputs": [],
   "source": [
    "#train_file_path = \"drive/My Drive/Face_recognition/train_relationships.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dCVbD9KEt-O1"
   },
   "outputs": [],
   "source": [
    "relationships = pd.read_csv(train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nPEZuFQt-O-"
   },
   "outputs": [],
   "source": [
    "relationships = list(zip(relationships['p1'].values, relationships['p2'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RnThpErTt-Pj",
    "outputId": "16b2b085-ff55-4f1b-fcd6-c28cbcd72bf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3598"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1who1RIt-Pz"
   },
   "outputs": [],
   "source": [
    "#ppl = [x.replace(\"\\\\\",\"/\") for x in ppl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obnQSPJOt-P7"
   },
   "outputs": [],
   "source": [
    "relationships = [x for x in relationships if x[0] in ppl and x[1] in ppl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I7ogU6Gct-QU",
    "outputId": "74f7f1b9-cbac-41a8-ac95-14208e388165"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3362"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hrPem-cut-Qi"
   },
   "source": [
    "##### Getting train and val sets from relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybCf83Dut-Q1"
   },
   "outputs": [],
   "source": [
    "train = [x for x in relationships if val_famillies not in x[0]]\n",
    "val = [x for x in relationships if val_famillies in x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "eEa5zdWrt-Q9",
    "outputId": "70100fea-235e-4f3c-f596-e4c8bcfbc8b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('F0002/MID1', 'F0002/MID3'),\n",
       " ('F0002/MID2', 'F0002/MID3'),\n",
       " ('F0005/MID1', 'F0005/MID2'),\n",
       " ('F0005/MID3', 'F0005/MID2'),\n",
       " ('F0009/MID1', 'F0009/MID4')]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "02yzH3sxt-RR",
    "outputId": "6d4da97d-6627-4f14-d8c8-b4eb8033cbf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('F0998/MID5', 'F0998/MID3'),\n",
       " ('F0998/MID5', 'F0998/MID1'),\n",
       " ('F0998/MID6', 'F0998/MID1'),\n",
       " ('F0998/MID6', 'F0998/MID2'),\n",
       " ('F0998/MID6', 'F0998/MID3')]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "HqXqm4-It-Rb",
    "outputId": "a86f0d7f-1f0c-4676-89b4-cd95a49e96f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3066\n",
      "296\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r_TcKnAKt-R9"
   },
   "outputs": [],
   "source": [
    "#from keras.preprocessing import image\n",
    "def read_img(path):\n",
    "    #change1\n",
    "    img = image.load_img(path, target_size=(197, 197))\n",
    "    img = np.array(img).astype(np.float)\n",
    "    return preprocess_input(img, version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "SXk5oo4Kt-SE",
    "outputId": "fef3322a-e790-40b3-c5b8-e72f571ea8c8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAIAAACVT/22AADDc0lEQVR4nMz9244kSbYliK21RdTM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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=224x224 at 0x7F31BA081908>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.load_img(\"drive/My Drive/Face_recognition/train/F0002/MID1/P00010_face4.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YncZMXF6t-SN",
    "outputId": "9905f36d-64c2-43d4-9150-38e313af11b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array(image.load_img(\"drive/My Drive/Face_recognition/train/F0002/MID1/P00010_face4.jpg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "fhWNHtslt-SY",
    "outputId": "1ffaeb81-c075-40fb-d907-5592c06a2807"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAADFCAIAAABrWqGnAACfeElEQVR4nMT9W48kSZMliJ0jombu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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=197x197 at 0x7F31825FC470>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.load_img(\"drive/My Drive/Face_recognition/train/F0002/MID1/P00010_face4.jpg\", target_size=(197, 197))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "id": "2w5Vor1HuvaJ",
    "outputId": "b478e48d-372d-4544-8623-764c3df82d8c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAACgCAIAAAAErfB6AAB0s0lEQVR4nKz9aY8kS7IliB0RUTX3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\nRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=160x160 at 0x7F31825FC438>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.load_img(\"drive/My Drive/Face_recognition/train/F0002/MID1/P00010_face4.jpg\", target_size=(160, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cjxrhXyLt-Sj",
    "outputId": "7636e54a-9a79-4955-d25f-4e3ad11b1360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array(image.load_img(\"drive/My Drive/Face_recognition/train/F0002/MID1/P00010_face4.jpg\", target_size=(197, 197))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQYOL4vFt-S_"
   },
   "outputs": [],
   "source": [
    "temp = read_img(\"drive/My Drive/Face_recognition/train/F0002/MID1/P00010_face4.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ocLodNB1t-TH",
    "outputId": "4433642f-be76-4810-921f-282e5ff0b17b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 197, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z-rSYspmt-TP"
   },
   "outputs": [],
   "source": [
    "#temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muo9df4nt-TU"
   },
   "outputs": [],
   "source": [
    "#val_person_to_images_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7y9qKlzqp8Tx"
   },
   "source": [
    "### 1. VGGFace and Distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yvuYp03Yt-Ta"
   },
   "outputs": [],
   "source": [
    "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
    "    ppl = list(person_to_images_map.keys())\n",
    "    while True:\n",
    "        #sample() Chooses k unique random elements from a population sequence or set\n",
    "        # Filling batch tuples with half 1 lables\n",
    "        batch_tuples = sample(list_tuples, batch_size // 2)\n",
    "        # Assigning 1 label to all the pairs given in relationships file\n",
    "        labels = [1] * len(batch_tuples)\n",
    "        # Filling half batch_tuples with 0 labels\n",
    "        while len(batch_tuples) < batch_size:\n",
    "            p1 = choice(ppl)\n",
    "            p2 = choice(ppl)\n",
    "\n",
    "            if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:\n",
    "                batch_tuples.append((p1, p2))\n",
    "                labels.append(0)\n",
    "\n",
    "        for x in batch_tuples:\n",
    "            if not len(person_to_images_map[x[0]]):\n",
    "                print(x[0])\n",
    "        \n",
    "        # Selecting a single image out of many provided for each user\n",
    "        X1 = [choice(person_to_images_map[x[0]]) for x in batch_tuples]\n",
    "        X1 = np.array([read_img(x) for x in X1])\n",
    "        \n",
    "        # Selecting a single image out of many provided for each user\n",
    "        X2 = [choice(person_to_images_map[x[1]]) for x in batch_tuples]\n",
    "        X2 = np.array([read_img(x) for x in X2])\n",
    "\n",
    "        yield [X1, X2], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qI--1hw7M3ZW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-F7UMd0t-Tj"
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    #change 2\n",
    "    input_1 = Input(shape=(197, 197, 3))\n",
    "    input_2 = Input(shape=(197, 197, 3))\n",
    "\n",
    "    base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "\n",
    "    x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)])\n",
    "    x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n",
    "\n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "\n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    x = Concatenate(axis=-1)([x4, x3])\n",
    "\n",
    "    x = Dense(100, activation=\"relu\")(x)\n",
    "    x = Dropout(0.01)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=['acc',auroc], optimizer=Adam(0.00001))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPFTGc62t-Tq"
   },
   "outputs": [],
   "source": [
    "file_path = \"vgg_face.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.1, patience=20, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "model = baseline_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p4P8EvTkt-Tz"
   },
   "outputs": [],
   "source": [
    "for k in val_person_to_images_map.keys():\n",
    "    if len(val_person_to_images_map[k]) == 0:\n",
    "        print(\"VAL Damn\")\n",
    "        print(k)\n",
    "for k in train_person_to_images_map.keys():\n",
    "    if len(train_person_to_images_map[k]) == 0:\n",
    "        print(\"Train Damn\")\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGJnF_8At-T5"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=True,\n",
    "                    validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=100, verbose=1,\n",
    "                    workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "manfWqS6t-UB"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BzPVP0Vgt-UK"
   },
   "outputs": [],
   "source": [
    "! pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tn03bUL8t-UP"
   },
   "outputs": [],
   "source": [
    "\n",
    "joblib.dump(model,\"drive/My Drive/Face_recognition/model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VHBVFFjht-UX"
   },
   "outputs": [],
   "source": [
    "! dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4c38k1qOt-Ui"
   },
   "outputs": [],
   "source": [
    "with open(\"vgg_face.h5\",'rb') as f:\n",
    "    with open(\"drive/My Drive/Face_recognition/vgg_face_copy.h5\", \"wb\") as f1:\n",
    "        for line in f:\n",
    "            f1.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ljckll_1t-Us"
   },
   "outputs": [],
   "source": [
    "model.load_weights('vgg_face.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uOJcOwJbt-Uw"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", metrics=['acc',auroc], optimizer=Adam(0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "23ySnUxgt-U1"
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"drive/My Drive/Face_recognition/vgg_face_copy(2).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Q1UYOaYt-U7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_w-zvJCt-VB"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"drive/My Drive/Face_recognition/vgg_face.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D9KLhiZQt-VG"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", metrics=['acc',auroc], optimizer=Adam(0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wv_AsC-2t-VO",
    "outputId": "10ffedc4-cf6e-4361-8875-91ad1fc9f648"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:24, 24.43s/it]\u001b[A\n",
      "2it [00:42, 22.55s/it]\u001b[A\n",
      "3it [00:59, 20.89s/it]\u001b[A\n",
      "4it [01:17, 20.07s/it]\u001b[A\n",
      "5it [01:35, 19.31s/it]\u001b[A\n",
      "6it [01:52, 18.73s/it]\u001b[A\n",
      "7it [02:10, 18.38s/it]\u001b[A\n",
      "8it [02:26, 17.70s/it]\u001b[A\n",
      "9it [02:43, 17.43s/it]\u001b[A\n",
      "10it [03:00, 17.37s/it]\u001b[A\n",
      "11it [03:16, 17.03s/it]\u001b[A\n",
      "12it [03:31, 16.50s/it]\u001b[A\n",
      "13it [03:47, 16.38s/it]\u001b[A\n",
      "14it [04:03, 16.06s/it]\u001b[A\n",
      "15it [04:20, 16.33s/it]\u001b[A\n",
      "16it [04:35, 15.96s/it]\u001b[A\n",
      "17it [04:51, 16.07s/it]\u001b[A\n",
      "18it [05:06, 15.60s/it]\u001b[A\n",
      "19it [05:21, 15.38s/it]\u001b[A\n",
      "20it [05:35, 15.22s/it]\u001b[A\n",
      "21it [05:51, 15.24s/it]\u001b[A\n",
      "22it [06:07, 15.55s/it]\u001b[A\n",
      "23it [06:22, 15.46s/it]\u001b[A\n",
      "24it [06:36, 15.02s/it]\u001b[A\n",
      "25it [06:51, 15.08s/it]\u001b[A\n",
      "26it [07:05, 14.58s/it]\u001b[A\n",
      "27it [07:19, 14.33s/it]\u001b[A\n",
      "28it [07:31, 13.71s/it]\u001b[A\n",
      "29it [07:46, 14.04s/it]\u001b[A\n",
      "30it [07:58, 13.50s/it]\u001b[A\n",
      "31it [08:11, 13.27s/it]\u001b[A\n",
      "32it [08:24, 13.30s/it]\u001b[A\n",
      "33it [08:39, 13.71s/it]\u001b[A\n",
      "34it [08:53, 13.81s/it]\u001b[A\n",
      "35it [09:04, 13.16s/it]\u001b[A\n",
      "36it [09:18, 13.19s/it]\u001b[A\n",
      "37it [09:28, 12.25s/it]\u001b[A\n",
      "38it [09:43, 13.09s/it]\u001b[A\n",
      "39it [09:54, 12.55s/it]\u001b[A\n",
      "40it [10:07, 12.76s/it]\u001b[A\n",
      "41it [10:19, 12.59s/it]\u001b[A\n",
      "42it [10:31, 12.19s/it]\u001b[A\n",
      "43it [10:42, 12.03s/it]\u001b[A\n",
      "44it [10:56, 12.64s/it]\u001b[A\n",
      "45it [11:07, 12.13s/it]\u001b[A\n",
      "46it [11:20, 12.13s/it]\u001b[A\n",
      "47it [11:32, 12.11s/it]\u001b[A\n",
      "48it [11:42, 11.61s/it]\u001b[A\n",
      "49it [11:56, 12.24s/it]\u001b[A\n",
      "50it [12:07, 11.81s/it]\u001b[A\n",
      "51it [12:18, 11.58s/it]\u001b[A\n",
      "52it [12:31, 12.14s/it]\u001b[A\n",
      "53it [12:42, 11.79s/it]\u001b[A\n",
      "54it [12:55, 12.13s/it]\u001b[A\n",
      "55it [13:07, 12.21s/it]\u001b[A\n",
      "56it [13:19, 12.16s/it]\u001b[A\n",
      "57it [13:32, 12.32s/it]\u001b[A\n",
      "58it [13:41, 11.24s/it]\u001b[A\n",
      "59it [13:53, 11.41s/it]\u001b[A\n",
      "60it [14:04, 11.32s/it]\u001b[A\n",
      "61it [14:16, 11.60s/it]\u001b[A\n",
      "62it [14:26, 11.15s/it]\u001b[A\n",
      "63it [14:36, 10.84s/it]\u001b[A\n",
      "64it [14:47, 10.75s/it]\u001b[A\n",
      "65it [14:56, 10.32s/it]\u001b[A\n",
      "66it [15:09, 11.20s/it]\u001b[A\n",
      "67it [15:18, 10.41s/it]\u001b[A\n",
      "68it [15:29, 10.70s/it]\u001b[A\n",
      "69it [15:41, 10.90s/it]\u001b[A\n",
      "70it [15:48,  9.82s/it]\u001b[A\n",
      "71it [15:57,  9.76s/it]\u001b[A\n",
      "72it [16:08,  9.90s/it]\u001b[A\n",
      "73it [16:16,  9.31s/it]\u001b[A\n",
      "74it [16:23,  8.75s/it]\u001b[A\n",
      "75it [16:34,  9.51s/it]\u001b[A\n",
      "76it [16:46, 10.06s/it]\u001b[A\n",
      "77it [16:56, 10.05s/it]\u001b[A\n",
      "78it [17:08, 10.65s/it]\u001b[A\n",
      "79it [17:17, 10.14s/it]\u001b[A\n",
      "80it [17:26,  9.97s/it]\u001b[A\n",
      "81it [17:34,  9.33s/it]\u001b[A\n",
      "82it [17:44,  9.33s/it]\u001b[A\n",
      "83it [17:52,  9.15s/it]\u001b[A\n",
      "84it [17:59,  8.51s/it]\u001b[A\n",
      "85it [18:07,  8.42s/it]\u001b[A\n",
      "86it [18:17,  8.74s/it]\u001b[A\n",
      "87it [18:26,  8.91s/it]\u001b[A\n",
      "88it [18:35,  8.89s/it]\u001b[A\n",
      "89it [18:45,  9.10s/it]\u001b[A\n",
      "90it [18:55,  9.43s/it]\u001b[A\n",
      "91it [19:03,  9.09s/it]\u001b[A\n",
      "92it [19:13,  9.35s/it]\u001b[A\n",
      "93it [19:22,  9.21s/it]\u001b[A\n",
      "94it [19:32,  9.45s/it]\u001b[A\n",
      "95it [19:41,  9.28s/it]\u001b[A\n",
      "96it [19:49,  8.85s/it]\u001b[A\n",
      "97it [19:57,  8.76s/it]\u001b[A\n",
      "98it [20:05,  8.40s/it]\u001b[A\n",
      "99it [20:13,  8.32s/it]\u001b[A\n",
      "100it [20:22,  8.48s/it]\u001b[A\n",
      "101it [20:30,  8.36s/it]\u001b[A\n",
      "102it [20:38,  8.30s/it]\u001b[A\n",
      "103it [20:47,  8.58s/it]\u001b[A\n",
      "104it [20:57,  8.90s/it]\u001b[A\n",
      "105it [21:06,  8.83s/it]\u001b[A\n",
      "106it [21:15,  8.88s/it]\u001b[A\n",
      "107it [21:24,  8.88s/it]\u001b[A\n",
      "108it [21:32,  8.64s/it]\u001b[A\n",
      "109it [21:40,  8.51s/it]\u001b[A\n",
      "110it [21:46,  7.91s/it]\u001b[A\n",
      "111it [21:54,  7.85s/it]\u001b[A\n",
      "112it [22:02,  7.81s/it]\u001b[A\n",
      "113it [22:10,  8.09s/it]\u001b[A\n",
      "114it [22:20,  8.39s/it]\u001b[A\n",
      "115it [22:29,  8.60s/it]\u001b[A\n",
      "116it [22:37,  8.66s/it]\u001b[A\n",
      "117it [22:44,  8.13s/it]\u001b[A\n",
      "118it [22:50,  7.40s/it]\u001b[A\n",
      "119it [22:59,  7.88s/it]\u001b[A\n",
      "120it [23:06,  7.73s/it]\u001b[A\n",
      "121it [23:14,  7.68s/it]\u001b[A\n",
      "122it [23:23,  8.18s/it]\u001b[A\n",
      "123it [23:30,  7.62s/it]\u001b[A\n",
      "124it [23:39,  8.16s/it]\u001b[A\n",
      "125it [23:46,  7.66s/it]\u001b[A\n",
      "126it [23:54,  7.87s/it]\u001b[A\n",
      "127it [24:02,  7.81s/it]\u001b[A\n",
      "128it [24:08,  7.52s/it]\u001b[A\n",
      "129it [24:16,  7.57s/it]\u001b[A\n",
      "130it [24:24,  7.77s/it]\u001b[A\n",
      "131it [24:31,  7.55s/it]\u001b[A\n",
      "132it [24:38,  7.38s/it]\u001b[A\n",
      "133it [24:48,  7.90s/it]\u001b[A\n",
      "134it [24:56,  8.06s/it]\u001b[A\n",
      "135it [25:04,  8.12s/it]\u001b[A\n",
      "136it [25:12,  7.91s/it]\u001b[A\n",
      "137it [25:20,  7.98s/it]\u001b[A\n",
      "138it [25:27,  7.63s/it]\u001b[A\n",
      "139it [25:34,  7.43s/it]\u001b[A\n",
      "140it [25:42,  7.78s/it]\u001b[A\n",
      "141it [25:51,  8.16s/it]\u001b[A\n",
      "142it [26:01,  8.52s/it]\u001b[A\n",
      "143it [26:07,  8.02s/it]\u001b[A\n",
      "144it [26:15,  7.81s/it]\u001b[A\n",
      "145it [26:24,  8.26s/it]\u001b[A\n",
      "146it [26:33,  8.41s/it]\u001b[A\n",
      "147it [26:41,  8.44s/it]\u001b[A\n",
      "148it [26:52,  9.22s/it]\u001b[A\n",
      "149it [27:01,  9.13s/it]\u001b[A\n",
      "150it [27:09,  8.74s/it]\u001b[A\n",
      "151it [27:17,  8.55s/it]\u001b[A\n",
      "152it [27:23,  7.80s/it]\u001b[A\n",
      "153it [27:28,  6.97s/it]\u001b[A\n",
      "154it [27:37,  7.60s/it]\u001b[A\n",
      "155it [27:44,  7.43s/it]\u001b[A\n",
      "156it [27:53,  7.65s/it]\u001b[A\n",
      "157it [28:01,  7.89s/it]\u001b[A\n",
      "158it [28:10,  8.27s/it]\u001b[A\n",
      "159it [28:18,  8.01s/it]\u001b[A\n",
      "160it [28:25,  7.95s/it]\u001b[A\n",
      "161it [28:35,  8.43s/it]\u001b[A\n",
      "162it [28:45,  8.87s/it]\u001b[A\n",
      "163it [28:53,  8.69s/it]\u001b[A\n",
      "164it [29:02,  8.74s/it]\u001b[A\n",
      "165it [29:09,  8.15s/it]\u001b[A\n",
      "166it [29:17,  8.21s/it]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "test_path = \"drive/My Drive/Face_recognition/test/\"\n",
    "def chunker(seq, size=32):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "submission = pd.read_csv('drive/My Drive/Face_recognition/sample_submission.csv')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in tqdm(chunker(submission.img_pair.values)):\n",
    "    X1 = [x.split(\"-\")[0] for x in batch]\n",
    "    X1 = np.array([read_img(test_path + x) for x in X1])\n",
    "\n",
    "    X2 = [x.split(\"-\")[1] for x in batch]\n",
    "    X2 = np.array([read_img(test_path + x) for x in X2])\n",
    "\n",
    "    pred = model.predict([X1, X2]).ravel().tolist()\n",
    "    predictions += pred\n",
    "\n",
    "submission['is_related'] = predictions\n",
    "\n",
    "submission.to_csv(\"vgg_face.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6La7e_at-Vo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eh-62z-nW_3V"
   },
   "source": [
    "#### Test AUC score on kaggle submission: 0.852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rxidY3RZWS2X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gMxHQS1WkkZ8"
   },
   "source": [
    "### 2. Experimenting with few additional layers at end and different dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1rLQ18Rnkk5P"
   },
   "outputs": [],
   "source": [
    "def baseline_model2():\n",
    "    #change 2\n",
    "    input_1 = Input(shape=(197, 197, 3))\n",
    "    input_2 = Input(shape=(197, 197, 3))\n",
    "\n",
    "    base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "\n",
    "    x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)])\n",
    "    x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n",
    "\n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "\n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    x = Concatenate(axis=-1)([x4, x3])\n",
    "\n",
    "    x = Dense(100, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=['acc',auroc], optimizer=Adam(0.0001))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "colab_type": "code",
    "id": "dln1fFC9k2M8",
    "outputId": "4f0962bb-b575-495d-e553-7eaf94572f35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vggface_resnet50 (Model)        multiple             23561152    input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_5 (GlobalM (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_6 (GlobalM (None, 2048)         0           vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 2048)         0           vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 4096)         0           global_max_pooling2d_5[0][0]     \n",
      "                                                                 global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 4096)         0           global_max_pooling2d_6[0][0]     \n",
      "                                                                 global_average_pooling2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 4096)         0           concatenate_7[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 4096)         0           concatenate_8[0][0]              \n",
      "                                                                 concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract_5 (Subtract)           (None, 4096)         0           concatenate_7[0][0]              \n",
      "                                                                 concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract_6 (Subtract)           (None, 4096)         0           multiply_8[0][0]                 \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 4096)         0           subtract_5[0][0]                 \n",
      "                                                                 subtract_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 8192)         0           subtract_6[0][0]                 \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 100)          819300      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 50)           5050        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            51          dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,385,553\n",
      "Trainable params: 24,332,433\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "file_path = \"drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_auroc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_auroc\", mode=\"max\", factor=0.1, patience=20, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "model = baseline_model2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UcDzwvfNlT0o",
    "outputId": "22391f49-e8f8-4e5c-a311-4a9512548427"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 116s 578ms/step - loss: 1.5499 - acc: 0.5709 - auroc: 0.6005 - val_loss: 0.6931 - val_acc: 0.6206 - val_auroc: 0.6713\n",
      "\n",
      "Epoch 00001: val_auroc improved from -inf to 0.67125, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 92s 459ms/step - loss: 0.6614 - acc: 0.6084 - auroc: 0.6545 - val_loss: 0.6613 - val_acc: 0.6400 - val_auroc: 0.6694\n",
      "\n",
      "Epoch 00002: val_auroc did not improve from 0.67125\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.6413 - acc: 0.6234 - auroc: 0.6792 - val_loss: 0.6560 - val_acc: 0.6375 - val_auroc: 0.6669\n",
      "\n",
      "Epoch 00003: val_auroc did not improve from 0.67125\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.6182 - acc: 0.6594 - auroc: 0.7100 - val_loss: 0.6179 - val_acc: 0.6756 - val_auroc: 0.7142\n",
      "\n",
      "Epoch 00004: val_auroc improved from 0.67125 to 0.71422, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.6185 - acc: 0.6522 - auroc: 0.6983 - val_loss: 0.5956 - val_acc: 0.6894 - val_auroc: 0.7417\n",
      "\n",
      "Epoch 00005: val_auroc improved from 0.71422 to 0.74172, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.5982 - acc: 0.6784 - auroc: 0.7360 - val_loss: 0.5879 - val_acc: 0.6944 - val_auroc: 0.7480\n",
      "\n",
      "Epoch 00006: val_auroc improved from 0.74172 to 0.74797, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 92s 459ms/step - loss: 0.5909 - acc: 0.6947 - auroc: 0.7457 - val_loss: 0.6025 - val_acc: 0.6781 - val_auroc: 0.7186\n",
      "\n",
      "Epoch 00007: val_auroc did not improve from 0.74797\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.5667 - acc: 0.7022 - auroc: 0.7678 - val_loss: 0.5701 - val_acc: 0.7181 - val_auroc: 0.7694\n",
      "\n",
      "Epoch 00008: val_auroc improved from 0.74797 to 0.76938, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.5668 - acc: 0.7022 - auroc: 0.7691 - val_loss: 0.5811 - val_acc: 0.6906 - val_auroc: 0.7514\n",
      "\n",
      "Epoch 00009: val_auroc did not improve from 0.76938\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.5524 - acc: 0.7150 - auroc: 0.7799 - val_loss: 0.5841 - val_acc: 0.7000 - val_auroc: 0.7584\n",
      "\n",
      "Epoch 00010: val_auroc did not improve from 0.76938\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.5388 - acc: 0.7231 - auroc: 0.7927 - val_loss: 0.5569 - val_acc: 0.7244 - val_auroc: 0.7941\n",
      "\n",
      "Epoch 00011: val_auroc improved from 0.76938 to 0.79406, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.5327 - acc: 0.7356 - auroc: 0.7998 - val_loss: 0.5345 - val_acc: 0.7381 - val_auroc: 0.8064\n",
      "\n",
      "Epoch 00012: val_auroc improved from 0.79406 to 0.80641, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.5291 - acc: 0.7384 - auroc: 0.8041 - val_loss: 0.5406 - val_acc: 0.7238 - val_auroc: 0.8002\n",
      "\n",
      "Epoch 00013: val_auroc did not improve from 0.80641\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.5175 - acc: 0.7494 - auroc: 0.8120 - val_loss: 0.5172 - val_acc: 0.7525 - val_auroc: 0.8217\n",
      "\n",
      "Epoch 00014: val_auroc improved from 0.80641 to 0.82172, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.5285 - acc: 0.7400 - auroc: 0.7959 - val_loss: 0.5620 - val_acc: 0.7181 - val_auroc: 0.7855\n",
      "\n",
      "Epoch 00015: val_auroc did not improve from 0.82172\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 91s 456ms/step - loss: 0.5066 - acc: 0.7541 - auroc: 0.8250 - val_loss: 0.5166 - val_acc: 0.7469 - val_auroc: 0.8128\n",
      "\n",
      "Epoch 00016: val_auroc did not improve from 0.82172\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.5035 - acc: 0.7619 - auroc: 0.8306 - val_loss: 0.5318 - val_acc: 0.7444 - val_auroc: 0.7953\n",
      "\n",
      "Epoch 00017: val_auroc did not improve from 0.82172\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.4993 - acc: 0.7569 - auroc: 0.8277 - val_loss: 0.5358 - val_acc: 0.7163 - val_auroc: 0.8033\n",
      "\n",
      "Epoch 00018: val_auroc did not improve from 0.82172\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.5058 - acc: 0.7625 - auroc: 0.8289 - val_loss: 0.5125 - val_acc: 0.7425 - val_auroc: 0.8241\n",
      "\n",
      "Epoch 00019: val_auroc improved from 0.82172 to 0.82406, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 92s 459ms/step - loss: 0.4889 - acc: 0.7744 - auroc: 0.8366 - val_loss: 0.5257 - val_acc: 0.7494 - val_auroc: 0.8186\n",
      "\n",
      "Epoch 00020: val_auroc did not improve from 0.82406\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.4941 - acc: 0.7594 - auroc: 0.8329 - val_loss: 0.5313 - val_acc: 0.7269 - val_auroc: 0.8034\n",
      "\n",
      "Epoch 00021: val_auroc did not improve from 0.82406\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 92s 459ms/step - loss: 0.4885 - acc: 0.7616 - auroc: 0.8334 - val_loss: 0.5356 - val_acc: 0.7356 - val_auroc: 0.8061\n",
      "\n",
      "Epoch 00022: val_auroc did not improve from 0.82406\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 92s 459ms/step - loss: 0.4978 - acc: 0.7556 - auroc: 0.8310 - val_loss: 0.5313 - val_acc: 0.7431 - val_auroc: 0.8087\n",
      "\n",
      "Epoch 00023: val_auroc did not improve from 0.82406\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.4865 - acc: 0.7719 - auroc: 0.8331 - val_loss: 0.5240 - val_acc: 0.7406 - val_auroc: 0.8217\n",
      "\n",
      "Epoch 00024: val_auroc did not improve from 0.82406\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 92s 459ms/step - loss: 0.4734 - acc: 0.7766 - auroc: 0.8438 - val_loss: 0.5236 - val_acc: 0.7262 - val_auroc: 0.8063\n",
      "\n",
      "Epoch 00025: val_auroc did not improve from 0.82406\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.4748 - acc: 0.7837 - auroc: 0.8482 - val_loss: 0.5180 - val_acc: 0.7488 - val_auroc: 0.8177\n",
      "\n",
      "Epoch 00026: val_auroc did not improve from 0.82406\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.4837 - acc: 0.7678 - auroc: 0.8389 - val_loss: 0.5154 - val_acc: 0.7331 - val_auroc: 0.8056\n",
      "\n",
      "Epoch 00027: val_auroc did not improve from 0.82406\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.4683 - acc: 0.7803 - auroc: 0.8522 - val_loss: 0.5417 - val_acc: 0.7331 - val_auroc: 0.8056\n",
      "\n",
      "Epoch 00028: val_auroc did not improve from 0.82406\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.4772 - acc: 0.7728 - auroc: 0.8449 - val_loss: 0.5090 - val_acc: 0.7488 - val_auroc: 0.8217\n",
      "\n",
      "Epoch 00029: val_auroc did not improve from 0.82406\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.4721 - acc: 0.7803 - auroc: 0.8483 - val_loss: 0.5410 - val_acc: 0.7325 - val_auroc: 0.8027\n",
      "\n",
      "Epoch 00030: val_auroc did not improve from 0.82406\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.4676 - acc: 0.7691 - auroc: 0.8541 - val_loss: 0.5140 - val_acc: 0.7394 - val_auroc: 0.8169\n",
      "\n",
      "Epoch 00031: val_auroc did not improve from 0.82406\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.4602 - acc: 0.7797 - auroc: 0.8573 - val_loss: 0.5365 - val_acc: 0.7325 - val_auroc: 0.8072\n",
      "\n",
      "Epoch 00032: val_auroc did not improve from 0.82406\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.4593 - acc: 0.7894 - auroc: 0.8582 - val_loss: 0.5455 - val_acc: 0.7331 - val_auroc: 0.7934\n",
      "\n",
      "Epoch 00033: val_auroc did not improve from 0.82406\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 92s 459ms/step - loss: 0.4623 - acc: 0.7822 - auroc: 0.8532 - val_loss: 0.5368 - val_acc: 0.7306 - val_auroc: 0.8042\n",
      "\n",
      "Epoch 00034: val_auroc did not improve from 0.82406\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.4476 - acc: 0.7884 - auroc: 0.8624 - val_loss: 0.5636 - val_acc: 0.7150 - val_auroc: 0.7825\n",
      "\n",
      "Epoch 00035: val_auroc did not improve from 0.82406\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 92s 459ms/step - loss: 0.4563 - acc: 0.7897 - auroc: 0.8566 - val_loss: 0.5311 - val_acc: 0.7312 - val_auroc: 0.8045\n",
      "\n",
      "Epoch 00036: val_auroc did not improve from 0.82406\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.4524 - acc: 0.7875 - auroc: 0.8577 - val_loss: 0.5702 - val_acc: 0.7144 - val_auroc: 0.7941\n",
      "\n",
      "Epoch 00037: val_auroc did not improve from 0.82406\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.4527 - acc: 0.7816 - auroc: 0.8548 - val_loss: 0.5452 - val_acc: 0.7212 - val_auroc: 0.8016\n",
      "\n",
      "Epoch 00038: val_auroc did not improve from 0.82406\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.4416 - acc: 0.7981 - auroc: 0.8709 - val_loss: 0.5273 - val_acc: 0.7388 - val_auroc: 0.7992\n",
      "\n",
      "Epoch 00039: val_auroc did not improve from 0.82406\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.4250 - acc: 0.8091 - auroc: 0.8808 - val_loss: 0.5244 - val_acc: 0.7450 - val_auroc: 0.8137\n",
      "\n",
      "Epoch 00040: val_auroc did not improve from 0.82406\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.4025 - acc: 0.8203 - auroc: 0.8893 - val_loss: 0.5023 - val_acc: 0.7500 - val_auroc: 0.8248\n",
      "\n",
      "Epoch 00041: val_auroc improved from 0.82406 to 0.82484, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3977 - acc: 0.8181 - auroc: 0.8932 - val_loss: 0.4808 - val_acc: 0.7712 - val_auroc: 0.8531\n",
      "\n",
      "Epoch 00042: val_auroc improved from 0.82484 to 0.85313, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3836 - acc: 0.8322 - auroc: 0.9031 - val_loss: 0.4973 - val_acc: 0.7650 - val_auroc: 0.8470\n",
      "\n",
      "Epoch 00043: val_auroc did not improve from 0.85313\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3721 - acc: 0.8394 - auroc: 0.9028 - val_loss: 0.4918 - val_acc: 0.7775 - val_auroc: 0.8363\n",
      "\n",
      "Epoch 00044: val_auroc did not improve from 0.85313\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.3814 - acc: 0.8334 - auroc: 0.9012 - val_loss: 0.5181 - val_acc: 0.7562 - val_auroc: 0.8208\n",
      "\n",
      "Epoch 00045: val_auroc did not improve from 0.85313\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3631 - acc: 0.8438 - auroc: 0.9111 - val_loss: 0.4935 - val_acc: 0.7650 - val_auroc: 0.8444\n",
      "\n",
      "Epoch 00046: val_auroc did not improve from 0.85313\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3502 - acc: 0.8475 - auroc: 0.9196 - val_loss: 0.5196 - val_acc: 0.7606 - val_auroc: 0.8367\n",
      "\n",
      "Epoch 00047: val_auroc did not improve from 0.85313\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3664 - acc: 0.8409 - auroc: 0.9063 - val_loss: 0.5184 - val_acc: 0.7519 - val_auroc: 0.8292\n",
      "\n",
      "Epoch 00048: val_auroc did not improve from 0.85313\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3635 - acc: 0.8409 - auroc: 0.9123 - val_loss: 0.5369 - val_acc: 0.7550 - val_auroc: 0.8214\n",
      "\n",
      "Epoch 00049: val_auroc did not improve from 0.85313\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3415 - acc: 0.8506 - auroc: 0.9205 - val_loss: 0.5044 - val_acc: 0.7738 - val_auroc: 0.8445\n",
      "\n",
      "Epoch 00050: val_auroc did not improve from 0.85313\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3459 - acc: 0.8481 - auroc: 0.9209 - val_loss: 0.4944 - val_acc: 0.7706 - val_auroc: 0.8459\n",
      "\n",
      "Epoch 00051: val_auroc did not improve from 0.85313\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3265 - acc: 0.8616 - auroc: 0.9277 - val_loss: 0.5153 - val_acc: 0.7606 - val_auroc: 0.8316\n",
      "\n",
      "Epoch 00052: val_auroc did not improve from 0.85313\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3301 - acc: 0.8634 - auroc: 0.9261 - val_loss: 0.4784 - val_acc: 0.7887 - val_auroc: 0.8575\n",
      "\n",
      "Epoch 00053: val_auroc improved from 0.85313 to 0.85750, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.3222 - acc: 0.8594 - auroc: 0.9305 - val_loss: 0.5009 - val_acc: 0.7712 - val_auroc: 0.8386\n",
      "\n",
      "Epoch 00054: val_auroc did not improve from 0.85750\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3140 - acc: 0.8672 - auroc: 0.9306 - val_loss: 0.5033 - val_acc: 0.7625 - val_auroc: 0.8414\n",
      "\n",
      "Epoch 00055: val_auroc did not improve from 0.85750\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.3478 - acc: 0.8525 - auroc: 0.9112 - val_loss: 0.4923 - val_acc: 0.7638 - val_auroc: 0.8525\n",
      "\n",
      "Epoch 00056: val_auroc did not improve from 0.85750\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3253 - acc: 0.8603 - auroc: 0.9259 - val_loss: 0.5084 - val_acc: 0.7731 - val_auroc: 0.8494\n",
      "\n",
      "Epoch 00057: val_auroc did not improve from 0.85750\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3175 - acc: 0.8638 - auroc: 0.9320 - val_loss: 0.4658 - val_acc: 0.7712 - val_auroc: 0.8511\n",
      "\n",
      "Epoch 00058: val_auroc did not improve from 0.85750\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.3140 - acc: 0.8712 - auroc: 0.9330 - val_loss: 0.5037 - val_acc: 0.7606 - val_auroc: 0.8425\n",
      "\n",
      "Epoch 00059: val_auroc did not improve from 0.85750\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3039 - acc: 0.8744 - auroc: 0.9384 - val_loss: 0.5194 - val_acc: 0.7506 - val_auroc: 0.8322\n",
      "\n",
      "Epoch 00060: val_auroc did not improve from 0.85750\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3165 - acc: 0.8597 - auroc: 0.9297 - val_loss: 0.5537 - val_acc: 0.7531 - val_auroc: 0.8270\n",
      "\n",
      "Epoch 00061: val_auroc did not improve from 0.85750\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 91s 456ms/step - loss: 0.3030 - acc: 0.8675 - auroc: 0.9373 - val_loss: 0.4956 - val_acc: 0.7762 - val_auroc: 0.8495\n",
      "\n",
      "Epoch 00062: val_auroc did not improve from 0.85750\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.2896 - acc: 0.8819 - auroc: 0.9402 - val_loss: 0.5407 - val_acc: 0.7488 - val_auroc: 0.8339\n",
      "\n",
      "Epoch 00063: val_auroc did not improve from 0.85750\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 91s 456ms/step - loss: 0.3017 - acc: 0.8725 - auroc: 0.9356 - val_loss: 0.5112 - val_acc: 0.7606 - val_auroc: 0.8505\n",
      "\n",
      "Epoch 00064: val_auroc did not improve from 0.85750\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.3089 - acc: 0.8694 - auroc: 0.9348 - val_loss: 0.4905 - val_acc: 0.7762 - val_auroc: 0.8622\n",
      "\n",
      "Epoch 00065: val_auroc improved from 0.85750 to 0.86219, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 92s 459ms/step - loss: 0.3072 - acc: 0.8747 - auroc: 0.9305 - val_loss: 0.5083 - val_acc: 0.7700 - val_auroc: 0.8505\n",
      "\n",
      "Epoch 00066: val_auroc did not improve from 0.86219\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 91s 456ms/step - loss: 0.2875 - acc: 0.8853 - auroc: 0.9401 - val_loss: 0.5629 - val_acc: 0.7519 - val_auroc: 0.8289\n",
      "\n",
      "Epoch 00067: val_auroc did not improve from 0.86219\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 91s 456ms/step - loss: 0.2848 - acc: 0.8797 - auroc: 0.9438 - val_loss: 0.5196 - val_acc: 0.7631 - val_auroc: 0.8425\n",
      "\n",
      "Epoch 00068: val_auroc did not improve from 0.86219\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.2837 - acc: 0.8869 - auroc: 0.9441 - val_loss: 0.5176 - val_acc: 0.7750 - val_auroc: 0.8619\n",
      "\n",
      "Epoch 00069: val_auroc did not improve from 0.86219\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.2888 - acc: 0.8762 - auroc: 0.9434 - val_loss: 0.5108 - val_acc: 0.7638 - val_auroc: 0.8542\n",
      "\n",
      "Epoch 00070: val_auroc did not improve from 0.86219\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.2751 - acc: 0.8897 - auroc: 0.9478 - val_loss: 0.5843 - val_acc: 0.7619 - val_auroc: 0.8381\n",
      "\n",
      "Epoch 00071: val_auroc did not improve from 0.86219\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 91s 456ms/step - loss: 0.2808 - acc: 0.8881 - auroc: 0.9422 - val_loss: 0.6048 - val_acc: 0.7488 - val_auroc: 0.8367\n",
      "\n",
      "Epoch 00072: val_auroc did not improve from 0.86219\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.2800 - acc: 0.8872 - auroc: 0.9440 - val_loss: 0.5737 - val_acc: 0.7406 - val_auroc: 0.8381\n",
      "\n",
      "Epoch 00073: val_auroc did not improve from 0.86219\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.2668 - acc: 0.8906 - auroc: 0.9502 - val_loss: 0.5711 - val_acc: 0.7494 - val_auroc: 0.8350\n",
      "\n",
      "Epoch 00074: val_auroc did not improve from 0.86219\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.2695 - acc: 0.8906 - auroc: 0.9495 - val_loss: 0.5791 - val_acc: 0.7669 - val_auroc: 0.8516\n",
      "\n",
      "Epoch 00075: val_auroc did not improve from 0.86219\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 91s 456ms/step - loss: 0.2553 - acc: 0.8991 - auroc: 0.9548 - val_loss: 0.6802 - val_acc: 0.7288 - val_auroc: 0.8320\n",
      "\n",
      "Epoch 00076: val_auroc did not improve from 0.86219\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.2764 - acc: 0.8837 - auroc: 0.9479 - val_loss: 0.5462 - val_acc: 0.7550 - val_auroc: 0.8431\n",
      "\n",
      "Epoch 00077: val_auroc did not improve from 0.86219\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 91s 456ms/step - loss: 0.2825 - acc: 0.8884 - auroc: 0.9462 - val_loss: 0.6010 - val_acc: 0.7312 - val_auroc: 0.8248\n",
      "\n",
      "Epoch 00078: val_auroc did not improve from 0.86219\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.2673 - acc: 0.8872 - auroc: 0.9530 - val_loss: 0.6254 - val_acc: 0.7469 - val_auroc: 0.8414\n",
      "\n",
      "Epoch 00079: val_auroc did not improve from 0.86219\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 91s 456ms/step - loss: 0.2668 - acc: 0.8884 - auroc: 0.9507 - val_loss: 0.5363 - val_acc: 0.7625 - val_auroc: 0.8617\n",
      "\n",
      "Epoch 00080: val_auroc did not improve from 0.86219\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.2660 - acc: 0.8934 - auroc: 0.9480 - val_loss: 0.5738 - val_acc: 0.7475 - val_auroc: 0.8480\n",
      "\n",
      "Epoch 00081: val_auroc did not improve from 0.86219\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.2638 - acc: 0.8875 - auroc: 0.9523 - val_loss: 0.5364 - val_acc: 0.7588 - val_auroc: 0.8634\n",
      "\n",
      "Epoch 00082: val_auroc improved from 0.86219 to 0.86344, saving model to drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.2419 - acc: 0.9066 - auroc: 0.9580 - val_loss: 0.6077 - val_acc: 0.7425 - val_auroc: 0.8406\n",
      "\n",
      "Epoch 00083: val_auroc did not improve from 0.86344\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.2544 - acc: 0.8975 - auroc: 0.9519 - val_loss: 0.5900 - val_acc: 0.7581 - val_auroc: 0.8509\n",
      "\n",
      "Epoch 00084: val_auroc did not improve from 0.86344\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 92s 458ms/step - loss: 0.2502 - acc: 0.9016 - auroc: 0.9553 - val_loss: 0.5971 - val_acc: 0.7475 - val_auroc: 0.8489\n",
      "\n",
      "Epoch 00085: val_auroc did not improve from 0.86344\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.2462 - acc: 0.9084 - auroc: 0.9572 - val_loss: 0.6158 - val_acc: 0.7362 - val_auroc: 0.8391\n",
      "\n",
      "Epoch 00086: val_auroc did not improve from 0.86344\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 91s 457ms/step - loss: 0.2554 - acc: 0.9003 - auroc: 0.9525 - val_loss: 0.6371 - val_acc: 0.7300 - val_auroc: 0.8280\n",
      "\n",
      "Epoch 00087: val_auroc did not improve from 0.86344\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 94s 468ms/step - loss: 0.2613 - acc: 0.8941 - auroc: 0.9510 - val_loss: 0.6200 - val_acc: 0.7544 - val_auroc: 0.8386\n",
      "\n",
      "Epoch 00088: val_auroc did not improve from 0.86344\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 92s 461ms/step - loss: 0.2425 - acc: 0.9053 - auroc: 0.9593 - val_loss: 0.6374 - val_acc: 0.7506 - val_auroc: 0.8381\n",
      "\n",
      "Epoch 00089: val_auroc did not improve from 0.86344\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 92s 461ms/step - loss: 0.2429 - acc: 0.9000 - auroc: 0.9602 - val_loss: 0.6468 - val_acc: 0.7381 - val_auroc: 0.8352\n",
      "\n",
      "Epoch 00090: val_auroc did not improve from 0.86344\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 92s 462ms/step - loss: 0.2296 - acc: 0.9091 - auroc: 0.9577 - val_loss: 0.6681 - val_acc: 0.7225 - val_auroc: 0.8208\n",
      "\n",
      "Epoch 00091: val_auroc did not improve from 0.86344\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 92s 462ms/step - loss: 0.2180 - acc: 0.9106 - auroc: 0.9656 - val_loss: 0.6524 - val_acc: 0.7300 - val_auroc: 0.8387\n",
      "\n",
      "Epoch 00092: val_auroc did not improve from 0.86344\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 92s 462ms/step - loss: 0.2378 - acc: 0.9075 - auroc: 0.9581 - val_loss: 0.6537 - val_acc: 0.7331 - val_auroc: 0.8327\n",
      "\n",
      "Epoch 00093: val_auroc did not improve from 0.86344\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 92s 461ms/step - loss: 0.2547 - acc: 0.8972 - auroc: 0.9498 - val_loss: 0.6413 - val_acc: 0.7506 - val_auroc: 0.8512\n",
      "\n",
      "Epoch 00094: val_auroc did not improve from 0.86344\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 92s 462ms/step - loss: 0.2273 - acc: 0.9116 - auroc: 0.9602 - val_loss: 0.6491 - val_acc: 0.7319 - val_auroc: 0.8314\n",
      "\n",
      "Epoch 00095: val_auroc did not improve from 0.86344\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 92s 461ms/step - loss: 0.2318 - acc: 0.9106 - auroc: 0.9619 - val_loss: 0.6758 - val_acc: 0.7306 - val_auroc: 0.8258\n",
      "\n",
      "Epoch 00096: val_auroc did not improve from 0.86344\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 92s 460ms/step - loss: 0.2317 - acc: 0.9075 - auroc: 0.9611 - val_loss: 0.6366 - val_acc: 0.7200 - val_auroc: 0.8281\n",
      "\n",
      "Epoch 00097: val_auroc did not improve from 0.86344\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 92s 461ms/step - loss: 0.2165 - acc: 0.9166 - auroc: 0.9662 - val_loss: 0.7162 - val_acc: 0.7350 - val_auroc: 0.8209\n",
      "\n",
      "Epoch 00098: val_auroc did not improve from 0.86344\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 92s 461ms/step - loss: 0.2188 - acc: 0.9147 - auroc: 0.9664 - val_loss: 0.6919 - val_acc: 0.7375 - val_auroc: 0.8191\n",
      "\n",
      "Epoch 00099: val_auroc did not improve from 0.86344\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 92s 461ms/step - loss: 0.2501 - acc: 0.9072 - auroc: 0.9541 - val_loss: 0.6812 - val_acc: 0.7188 - val_auroc: 0.8155\n",
      "\n",
      "Epoch 00100: val_auroc did not improve from 0.86344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f64f86c88>"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=True,\n",
    "                    validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=100, verbose=1,\n",
    "                    workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GozowxQclhHd"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"drive/My Drive/Face_recognition/vgg_face_baseline_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vwbi-7HUtmzP"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", metrics=['acc',auroc], optimizer=Adam(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_9yCwnoQtzk6",
    "outputId": "e0307bd0-28dc-42c9-8c23-22e53f2b7e59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166it [45:15, 12.36s/it]\n"
     ]
    }
   ],
   "source": [
    "test_path = \"drive/My Drive/Face_recognition/test/\"\n",
    "def chunker(seq, size=32):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "submission = pd.read_csv('drive/My Drive/Face_recognition/sample_submission.csv')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in tqdm(chunker(submission.img_pair.values)):\n",
    "    X1 = [x.split(\"-\")[0] for x in batch]\n",
    "    X1 = np.array([read_img(test_path + x) for x in X1])\n",
    "\n",
    "    X2 = [x.split(\"-\")[1] for x in batch]\n",
    "    X2 = np.array([read_img(test_path + x) for x in X2])\n",
    "\n",
    "    pred = model.predict([X1, X2]).ravel().tolist()\n",
    "    predictions += pred\n",
    "\n",
    "submission['is_related'] = predictions\n",
    "\n",
    "submission.to_csv(\"vgg_face.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHcpOrv07i4c"
   },
   "source": [
    "### Test score: 0.825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2VheqsY9DRsK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WydnGDTtvB_N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bRfympEEvEDz"
   },
   "source": [
    "### 3. Adding Cosine similiarity among other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bf1Q6UG9xM2v"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9umYVhVvCGh"
   },
   "outputs": [],
   "source": [
    "def cosine_model():\n",
    "    #change 2\n",
    "    input_1 = Input(shape=(197, 197, 3))\n",
    "    input_2 = Input(shape=(197, 197, 3))\n",
    "\n",
    "    base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "\n",
    "    x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)])\n",
    "    x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n",
    "\n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "\n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    \n",
    "    #https://stackoverflow.com/a/51003359/10650182\n",
    "    x5 = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([x1, x2])\n",
    "    \n",
    "    x = Concatenate(axis=-1)([x5,x4, x3])\n",
    "\n",
    "    x = Dense(100, activation=\"relu\")(x)\n",
    "    x = Dropout(0.01)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=['acc',auroc], optimizer=Adam(0.00001))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1BGC-WQ9DRsL",
    "outputId": "e707c753-957c-48f7-8ddc-688f4ad566b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0730 03:44:42.807980 139937882212224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0730 03:44:42.825098 139937882212224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0730 03:44:42.830878 139937882212224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0730 03:44:42.852989 139937882212224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0730 03:44:42.854120 139937882212224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0730 03:44:43.725043 139937882212224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0730 03:44:43.792669 139937882212224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0730 03:44:48.188672 139937882212224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0730 03:44:57.684166 139937882212224 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0730 03:44:57.723798 139937882212224 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0730 03:44:57.733903 139937882212224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0730 03:44:57.753005 139937882212224 deprecation.py:323] From <ipython-input-3-bc412d992b42>:14: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vggface_resnet50 (Model)        multiple             23561152    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (None, 2048)         0           vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4096)         0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4096)         0           global_max_pooling2d_2[0][0]     \n",
      "                                                                 global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 4096)         0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 4096)         0           concatenate_2[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 4096)         0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 4096)         0           multiply_2[0][0]                 \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 4096)         0           subtract_1[0][0]                 \n",
      "                                                                 subtract_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8193)         0           lambda_1[0][0]                   \n",
      "                                                                 subtract_2[0][0]                 \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          819400      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            101         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,380,653\n",
      "Trainable params: 24,327,533\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "file_path = \"drive/My Drive/Face_recognition/vgg_face_cosine.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_auroc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_auroc\", mode=\"max\", factor=0.1, patience=7, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "model = cosine_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "T8DkQAgwx6Bf",
    "outputId": "fa1776a5-dbcd-4cd2-b8ac-d2327cacf6eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "200/200 [==============================] - 109s 547ms/step - loss: 3.4510 - acc: 0.5600 - auroc: 0.5945 - val_loss: 3.8314 - val_acc: 0.5775 - val_auroc: 0.5927\n",
      "\n",
      "Epoch 00001: val_auroc improved from -inf to 0.59273, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 1.6573 - acc: 0.6275 - auroc: 0.6880 - val_loss: 2.1614 - val_acc: 0.5869 - val_auroc: 0.6169\n",
      "\n",
      "Epoch 00002: val_auroc improved from 0.59273 to 0.61687, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 1.0561 - acc: 0.6234 - auroc: 0.6745 - val_loss: 1.5515 - val_acc: 0.5781 - val_auroc: 0.6034\n",
      "\n",
      "Epoch 00003: val_auroc did not improve from 0.61687\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.7581 - acc: 0.6663 - auroc: 0.7195 - val_loss: 0.9396 - val_acc: 0.6338 - val_auroc: 0.6734\n",
      "\n",
      "Epoch 00004: val_auroc improved from 0.61687 to 0.67344, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.6359 - acc: 0.6822 - auroc: 0.7468 - val_loss: 0.7451 - val_acc: 0.6569 - val_auroc: 0.7186\n",
      "\n",
      "Epoch 00005: val_auroc improved from 0.67344 to 0.71859, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.5734 - acc: 0.7116 - auroc: 0.7801 - val_loss: 0.7261 - val_acc: 0.6381 - val_auroc: 0.7036\n",
      "\n",
      "Epoch 00006: val_auroc did not improve from 0.71859\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.5750 - acc: 0.7122 - auroc: 0.7802 - val_loss: 0.7025 - val_acc: 0.6731 - val_auroc: 0.7244\n",
      "\n",
      "Epoch 00007: val_auroc improved from 0.71859 to 0.72437, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.5463 - acc: 0.7306 - auroc: 0.7976 - val_loss: 0.6555 - val_acc: 0.6781 - val_auroc: 0.7330\n",
      "\n",
      "Epoch 00008: val_auroc improved from 0.72437 to 0.73297, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.5143 - acc: 0.7384 - auroc: 0.8127 - val_loss: 0.6490 - val_acc: 0.6719 - val_auroc: 0.7300\n",
      "\n",
      "Epoch 00009: val_auroc did not improve from 0.73297\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.4857 - acc: 0.7591 - auroc: 0.8387 - val_loss: 0.5800 - val_acc: 0.7087 - val_auroc: 0.7741\n",
      "\n",
      "Epoch 00010: val_auroc improved from 0.73297 to 0.77406, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.4823 - acc: 0.7616 - auroc: 0.8422 - val_loss: 0.5829 - val_acc: 0.7019 - val_auroc: 0.7744\n",
      "\n",
      "Epoch 00011: val_auroc improved from 0.77406 to 0.77438, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.4798 - acc: 0.7731 - auroc: 0.8466 - val_loss: 0.5535 - val_acc: 0.7294 - val_auroc: 0.8000\n",
      "\n",
      "Epoch 00012: val_auroc improved from 0.77438 to 0.80000, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.4510 - acc: 0.7816 - auroc: 0.8635 - val_loss: 0.5731 - val_acc: 0.7294 - val_auroc: 0.7964\n",
      "\n",
      "Epoch 00013: val_auroc did not improve from 0.80000\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.4709 - acc: 0.7712 - auroc: 0.8504 - val_loss: 0.5526 - val_acc: 0.7244 - val_auroc: 0.8002\n",
      "\n",
      "Epoch 00014: val_auroc improved from 0.80000 to 0.80016, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 90s 448ms/step - loss: 0.4365 - acc: 0.8000 - auroc: 0.8741 - val_loss: 0.5764 - val_acc: 0.7206 - val_auroc: 0.7953\n",
      "\n",
      "Epoch 00015: val_auroc did not improve from 0.80016\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.4287 - acc: 0.8013 - auroc: 0.8760 - val_loss: 0.5557 - val_acc: 0.7319 - val_auroc: 0.8019\n",
      "\n",
      "Epoch 00016: val_auroc improved from 0.80016 to 0.80188, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.4194 - acc: 0.8050 - auroc: 0.8808 - val_loss: 0.5475 - val_acc: 0.7238 - val_auroc: 0.7994\n",
      "\n",
      "Epoch 00017: val_auroc did not improve from 0.80188\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 90s 448ms/step - loss: 0.4334 - acc: 0.7994 - auroc: 0.8717 - val_loss: 0.5121 - val_acc: 0.7438 - val_auroc: 0.8177\n",
      "\n",
      "Epoch 00018: val_auroc improved from 0.80188 to 0.81766, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.4049 - acc: 0.8075 - auroc: 0.8884 - val_loss: 0.4813 - val_acc: 0.7806 - val_auroc: 0.8423\n",
      "\n",
      "Epoch 00019: val_auroc improved from 0.81766 to 0.84234, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 90s 448ms/step - loss: 0.4003 - acc: 0.8103 - auroc: 0.8915 - val_loss: 0.4997 - val_acc: 0.7612 - val_auroc: 0.8433\n",
      "\n",
      "Epoch 00020: val_auroc improved from 0.84234 to 0.84328, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.4008 - acc: 0.8175 - auroc: 0.8931 - val_loss: 0.4799 - val_acc: 0.7744 - val_auroc: 0.8531\n",
      "\n",
      "Epoch 00021: val_auroc improved from 0.84328 to 0.85313, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.4041 - acc: 0.8125 - auroc: 0.8916 - val_loss: 0.4871 - val_acc: 0.7706 - val_auroc: 0.8519\n",
      "\n",
      "Epoch 00022: val_auroc did not improve from 0.85313\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 90s 448ms/step - loss: 0.3990 - acc: 0.8181 - auroc: 0.8925 - val_loss: 0.5196 - val_acc: 0.7525 - val_auroc: 0.8147\n",
      "\n",
      "Epoch 00023: val_auroc did not improve from 0.85313\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 90s 448ms/step - loss: 0.3920 - acc: 0.8228 - auroc: 0.8998 - val_loss: 0.4916 - val_acc: 0.7631 - val_auroc: 0.8375\n",
      "\n",
      "Epoch 00024: val_auroc did not improve from 0.85313\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.3764 - acc: 0.8322 - auroc: 0.9062 - val_loss: 0.4836 - val_acc: 0.7681 - val_auroc: 0.8570\n",
      "\n",
      "Epoch 00025: val_auroc improved from 0.85313 to 0.85703, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.3639 - acc: 0.8403 - auroc: 0.9095 - val_loss: 0.4906 - val_acc: 0.7694 - val_auroc: 0.8478\n",
      "\n",
      "Epoch 00026: val_auroc did not improve from 0.85703\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 90s 448ms/step - loss: 0.3877 - acc: 0.8269 - auroc: 0.9020 - val_loss: 0.5182 - val_acc: 0.7556 - val_auroc: 0.8352\n",
      "\n",
      "Epoch 00027: val_auroc did not improve from 0.85703\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 90s 448ms/step - loss: 0.3662 - acc: 0.8309 - auroc: 0.9098 - val_loss: 0.5003 - val_acc: 0.7538 - val_auroc: 0.8438\n",
      "\n",
      "Epoch 00028: val_auroc did not improve from 0.85703\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.3626 - acc: 0.8353 - auroc: 0.9113 - val_loss: 0.5201 - val_acc: 0.7588 - val_auroc: 0.8366\n",
      "\n",
      "Epoch 00029: val_auroc did not improve from 0.85703\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 90s 448ms/step - loss: 0.3490 - acc: 0.8462 - auroc: 0.9187 - val_loss: 0.4875 - val_acc: 0.7769 - val_auroc: 0.8475\n",
      "\n",
      "Epoch 00030: val_auroc did not improve from 0.85703\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 90s 452ms/step - loss: 0.3600 - acc: 0.8413 - auroc: 0.9134 - val_loss: 0.4738 - val_acc: 0.7875 - val_auroc: 0.8592\n",
      "\n",
      "Epoch 00031: val_auroc improved from 0.85703 to 0.85922, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.3529 - acc: 0.8422 - auroc: 0.9170 - val_loss: 0.5163 - val_acc: 0.7606 - val_auroc: 0.8481\n",
      "\n",
      "Epoch 00032: val_auroc did not improve from 0.85922\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.3329 - acc: 0.8538 - auroc: 0.9254 - val_loss: 0.5157 - val_acc: 0.7575 - val_auroc: 0.8472\n",
      "\n",
      "Epoch 00033: val_auroc did not improve from 0.85922\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.3313 - acc: 0.8512 - auroc: 0.9273 - val_loss: 0.5425 - val_acc: 0.7512 - val_auroc: 0.8239\n",
      "\n",
      "Epoch 00034: val_auroc did not improve from 0.85922\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.3253 - acc: 0.8597 - auroc: 0.9299 - val_loss: 0.5138 - val_acc: 0.7650 - val_auroc: 0.8522\n",
      "\n",
      "Epoch 00035: val_auroc did not improve from 0.85922\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.3422 - acc: 0.8522 - auroc: 0.9197 - val_loss: 0.4909 - val_acc: 0.7725 - val_auroc: 0.8605\n",
      "\n",
      "Epoch 00036: val_auroc improved from 0.85922 to 0.86047, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.3304 - acc: 0.8556 - auroc: 0.9293 - val_loss: 0.5204 - val_acc: 0.7619 - val_auroc: 0.8420\n",
      "\n",
      "Epoch 00037: val_auroc did not improve from 0.86047\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.3194 - acc: 0.8606 - auroc: 0.9323 - val_loss: 0.5221 - val_acc: 0.7788 - val_auroc: 0.8506\n",
      "\n",
      "Epoch 00038: val_auroc did not improve from 0.86047\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.3090 - acc: 0.8741 - auroc: 0.9363 - val_loss: 0.5307 - val_acc: 0.7806 - val_auroc: 0.8525\n",
      "\n",
      "Epoch 00039: val_auroc did not improve from 0.86047\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.3239 - acc: 0.8622 - auroc: 0.9323 - val_loss: 0.5153 - val_acc: 0.7506 - val_auroc: 0.8492\n",
      "\n",
      "Epoch 00040: val_auroc did not improve from 0.86047\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.3144 - acc: 0.8628 - auroc: 0.9355 - val_loss: 0.5152 - val_acc: 0.7462 - val_auroc: 0.8431\n",
      "\n",
      "Epoch 00041: val_auroc did not improve from 0.86047\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.3131 - acc: 0.8722 - auroc: 0.9345 - val_loss: 0.5175 - val_acc: 0.7688 - val_auroc: 0.8533\n",
      "\n",
      "Epoch 00042: val_auroc did not improve from 0.86047\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.3143 - acc: 0.8719 - auroc: 0.9317 - val_loss: 0.5195 - val_acc: 0.7731 - val_auroc: 0.8527\n",
      "\n",
      "Epoch 00043: val_auroc did not improve from 0.86047\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2866 - acc: 0.8816 - auroc: 0.9448 - val_loss: 0.5074 - val_acc: 0.7531 - val_auroc: 0.8581\n",
      "\n",
      "Epoch 00044: val_auroc did not improve from 0.86047\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.3053 - acc: 0.8609 - auroc: 0.9385 - val_loss: 0.5216 - val_acc: 0.7562 - val_auroc: 0.8480\n",
      "\n",
      "Epoch 00045: val_auroc did not improve from 0.86047\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2833 - acc: 0.8731 - auroc: 0.9451 - val_loss: 0.5270 - val_acc: 0.7638 - val_auroc: 0.8502\n",
      "\n",
      "Epoch 00046: val_auroc did not improve from 0.86047\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2889 - acc: 0.8766 - auroc: 0.9464 - val_loss: 0.5364 - val_acc: 0.7612 - val_auroc: 0.8544\n",
      "\n",
      "Epoch 00047: val_auroc did not improve from 0.86047\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2924 - acc: 0.8794 - auroc: 0.9405 - val_loss: 0.4772 - val_acc: 0.7844 - val_auroc: 0.8719\n",
      "\n",
      "Epoch 00048: val_auroc improved from 0.86047 to 0.87187, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2692 - acc: 0.8903 - auroc: 0.9520 - val_loss: 0.5205 - val_acc: 0.7756 - val_auroc: 0.8580\n",
      "\n",
      "Epoch 00049: val_auroc did not improve from 0.87187\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 90s 449ms/step - loss: 0.2809 - acc: 0.8856 - auroc: 0.9480 - val_loss: 0.5114 - val_acc: 0.7681 - val_auroc: 0.8672\n",
      "\n",
      "Epoch 00050: val_auroc did not improve from 0.87187\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2813 - acc: 0.8756 - auroc: 0.9493 - val_loss: 0.5375 - val_acc: 0.7644 - val_auroc: 0.8653\n",
      "\n",
      "Epoch 00051: val_auroc did not improve from 0.87187\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2819 - acc: 0.8834 - auroc: 0.9487 - val_loss: 0.4932 - val_acc: 0.7656 - val_auroc: 0.8639\n",
      "\n",
      "Epoch 00052: val_auroc did not improve from 0.87187\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2581 - acc: 0.8944 - auroc: 0.9559 - val_loss: 0.4994 - val_acc: 0.7681 - val_auroc: 0.8638\n",
      "\n",
      "Epoch 00053: val_auroc did not improve from 0.87187\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2593 - acc: 0.8925 - auroc: 0.9579 - val_loss: 0.5149 - val_acc: 0.7606 - val_auroc: 0.8586\n",
      "\n",
      "Epoch 00054: val_auroc did not improve from 0.87187\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2644 - acc: 0.8934 - auroc: 0.9527 - val_loss: 0.5162 - val_acc: 0.7744 - val_auroc: 0.8666\n",
      "\n",
      "Epoch 00055: val_auroc did not improve from 0.87187\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2628 - acc: 0.8922 - auroc: 0.9523 - val_loss: 0.5314 - val_acc: 0.7588 - val_auroc: 0.8491\n",
      "\n",
      "Epoch 00056: val_auroc did not improve from 0.87187\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2635 - acc: 0.8897 - auroc: 0.9519 - val_loss: 0.5239 - val_acc: 0.7588 - val_auroc: 0.8586\n",
      "\n",
      "Epoch 00057: val_auroc did not improve from 0.87187\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2626 - acc: 0.8934 - auroc: 0.9554 - val_loss: 0.5038 - val_acc: 0.7756 - val_auroc: 0.8744\n",
      "\n",
      "Epoch 00058: val_auroc improved from 0.87187 to 0.87438, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2384 - acc: 0.9006 - auroc: 0.9622 - val_loss: 0.4869 - val_acc: 0.7788 - val_auroc: 0.8716\n",
      "\n",
      "Epoch 00059: val_auroc did not improve from 0.87438\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2485 - acc: 0.8972 - auroc: 0.9591 - val_loss: 0.5366 - val_acc: 0.7494 - val_auroc: 0.8489\n",
      "\n",
      "Epoch 00060: val_auroc did not improve from 0.87438\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2530 - acc: 0.8956 - auroc: 0.9577 - val_loss: 0.4809 - val_acc: 0.7769 - val_auroc: 0.8839\n",
      "\n",
      "Epoch 00061: val_auroc improved from 0.87438 to 0.88391, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 90s 452ms/step - loss: 0.2614 - acc: 0.8966 - auroc: 0.9540 - val_loss: 0.5187 - val_acc: 0.7694 - val_auroc: 0.8653\n",
      "\n",
      "Epoch 00062: val_auroc did not improve from 0.88391\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2458 - acc: 0.9012 - auroc: 0.9587 - val_loss: 0.5027 - val_acc: 0.7662 - val_auroc: 0.8703\n",
      "\n",
      "Epoch 00063: val_auroc did not improve from 0.88391\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 90s 452ms/step - loss: 0.2436 - acc: 0.9050 - auroc: 0.9609 - val_loss: 0.4866 - val_acc: 0.7756 - val_auroc: 0.8719\n",
      "\n",
      "Epoch 00064: val_auroc did not improve from 0.88391\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2474 - acc: 0.8972 - auroc: 0.9573 - val_loss: 0.5297 - val_acc: 0.7569 - val_auroc: 0.8534\n",
      "\n",
      "Epoch 00065: val_auroc did not improve from 0.88391\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2635 - acc: 0.8847 - auroc: 0.9537 - val_loss: 0.5408 - val_acc: 0.7588 - val_auroc: 0.8472\n",
      "\n",
      "Epoch 00066: val_auroc did not improve from 0.88391\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2538 - acc: 0.8925 - auroc: 0.9557 - val_loss: 0.5259 - val_acc: 0.7662 - val_auroc: 0.8633\n",
      "\n",
      "Epoch 00067: val_auroc did not improve from 0.88391\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2514 - acc: 0.8950 - auroc: 0.9579 - val_loss: 0.5141 - val_acc: 0.7769 - val_auroc: 0.8648\n",
      "\n",
      "Epoch 00068: val_auroc did not improve from 0.88391\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 90s 452ms/step - loss: 0.2570 - acc: 0.8928 - auroc: 0.9521 - val_loss: 0.5505 - val_acc: 0.7662 - val_auroc: 0.8466\n",
      "\n",
      "Epoch 00069: val_auroc did not improve from 0.88391\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 90s 452ms/step - loss: 0.2620 - acc: 0.8906 - auroc: 0.9538 - val_loss: 0.5452 - val_acc: 0.7694 - val_auroc: 0.8512\n",
      "\n",
      "Epoch 00070: val_auroc did not improve from 0.88391\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2513 - acc: 0.9025 - auroc: 0.9583 - val_loss: 0.5387 - val_acc: 0.7569 - val_auroc: 0.8409\n",
      "\n",
      "Epoch 00071: val_auroc did not improve from 0.88391\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2461 - acc: 0.9025 - auroc: 0.9584 - val_loss: 0.4961 - val_acc: 0.7744 - val_auroc: 0.8673\n",
      "\n",
      "Epoch 00072: val_auroc did not improve from 0.88391\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 90s 452ms/step - loss: 0.2363 - acc: 0.9025 - auroc: 0.9620 - val_loss: 0.4859 - val_acc: 0.7788 - val_auroc: 0.8797\n",
      "\n",
      "Epoch 00073: val_auroc did not improve from 0.88391\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2475 - acc: 0.9034 - auroc: 0.9598 - val_loss: 0.5551 - val_acc: 0.7594 - val_auroc: 0.8530\n",
      "\n",
      "Epoch 00074: val_auroc did not improve from 0.88391\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 90s 452ms/step - loss: 0.2516 - acc: 0.8950 - auroc: 0.9583 - val_loss: 0.4576 - val_acc: 0.7981 - val_auroc: 0.8844\n",
      "\n",
      "Epoch 00075: val_auroc improved from 0.88391 to 0.88438, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 90s 452ms/step - loss: 0.2488 - acc: 0.8997 - auroc: 0.9572 - val_loss: 0.4975 - val_acc: 0.7925 - val_auroc: 0.8794\n",
      "\n",
      "Epoch 00076: val_auroc did not improve from 0.88438\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2442 - acc: 0.9056 - auroc: 0.9590 - val_loss: 0.4890 - val_acc: 0.7725 - val_auroc: 0.8791\n",
      "\n",
      "Epoch 00077: val_auroc did not improve from 0.88438\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 90s 452ms/step - loss: 0.2607 - acc: 0.8928 - auroc: 0.9520 - val_loss: 0.4553 - val_acc: 0.7925 - val_auroc: 0.8912\n",
      "\n",
      "Epoch 00078: val_auroc improved from 0.88438 to 0.89125, saving model to drive/My Drive/Face_recognition/vgg_face_cosine.h5\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 90s 452ms/step - loss: 0.2709 - acc: 0.8847 - auroc: 0.9486 - val_loss: 0.5141 - val_acc: 0.7700 - val_auroc: 0.8644\n",
      "\n",
      "Epoch 00079: val_auroc did not improve from 0.89125\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2540 - acc: 0.8962 - auroc: 0.9580 - val_loss: 0.5248 - val_acc: 0.7756 - val_auroc: 0.8655\n",
      "\n",
      "Epoch 00080: val_auroc did not improve from 0.89125\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 90s 452ms/step - loss: 0.2616 - acc: 0.8887 - auroc: 0.9516 - val_loss: 0.5499 - val_acc: 0.7681 - val_auroc: 0.8638\n",
      "\n",
      "Epoch 00081: val_auroc did not improve from 0.89125\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2368 - acc: 0.9038 - auroc: 0.9615 - val_loss: 0.4952 - val_acc: 0.7875 - val_auroc: 0.8598\n",
      "\n",
      "Epoch 00082: val_auroc did not improve from 0.89125\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2672 - acc: 0.8900 - auroc: 0.9521 - val_loss: 0.5342 - val_acc: 0.7606 - val_auroc: 0.8484\n",
      "\n",
      "Epoch 00083: val_auroc did not improve from 0.89125\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2529 - acc: 0.8931 - auroc: 0.9552 - val_loss: 0.5108 - val_acc: 0.7700 - val_auroc: 0.8673\n",
      "\n",
      "Epoch 00084: val_auroc did not improve from 0.89125\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2526 - acc: 0.8938 - auroc: 0.9559 - val_loss: 0.5087 - val_acc: 0.7762 - val_auroc: 0.8673\n",
      "\n",
      "Epoch 00085: val_auroc did not improve from 0.89125\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2532 - acc: 0.8884 - auroc: 0.9576 - val_loss: 0.5567 - val_acc: 0.7612 - val_auroc: 0.8459\n",
      "\n",
      "Epoch 00086: val_auroc did not improve from 0.89125\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2467 - acc: 0.9025 - auroc: 0.9605 - val_loss: 0.4852 - val_acc: 0.7744 - val_auroc: 0.8733\n",
      "\n",
      "Epoch 00087: val_auroc did not improve from 0.89125\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2336 - acc: 0.9066 - auroc: 0.9642 - val_loss: 0.5299 - val_acc: 0.7700 - val_auroc: 0.8575\n",
      "\n",
      "Epoch 00088: val_auroc did not improve from 0.89125\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2487 - acc: 0.9000 - auroc: 0.9573 - val_loss: 0.4943 - val_acc: 0.7806 - val_auroc: 0.8819\n",
      "\n",
      "Epoch 00089: val_auroc did not improve from 0.89125\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2518 - acc: 0.8981 - auroc: 0.9595 - val_loss: 0.5112 - val_acc: 0.7681 - val_auroc: 0.8628\n",
      "\n",
      "Epoch 00090: val_auroc did not improve from 0.89125\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2536 - acc: 0.8956 - auroc: 0.9591 - val_loss: 0.4838 - val_acc: 0.7906 - val_auroc: 0.8838\n",
      "\n",
      "Epoch 00091: val_auroc did not improve from 0.89125\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2477 - acc: 0.8969 - auroc: 0.9592 - val_loss: 0.4839 - val_acc: 0.7769 - val_auroc: 0.8616\n",
      "\n",
      "Epoch 00092: val_auroc did not improve from 0.89125\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2582 - acc: 0.8881 - auroc: 0.9555 - val_loss: 0.4622 - val_acc: 0.7950 - val_auroc: 0.8836\n",
      "\n",
      "Epoch 00093: val_auroc did not improve from 0.89125\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2481 - acc: 0.8997 - auroc: 0.9572 - val_loss: 0.5459 - val_acc: 0.7631 - val_auroc: 0.8550\n",
      "\n",
      "Epoch 00094: val_auroc did not improve from 0.89125\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2417 - acc: 0.8981 - auroc: 0.9605 - val_loss: 0.5286 - val_acc: 0.7594 - val_auroc: 0.8552\n",
      "\n",
      "Epoch 00095: val_auroc did not improve from 0.89125\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2504 - acc: 0.8991 - auroc: 0.9592 - val_loss: 0.5001 - val_acc: 0.7831 - val_auroc: 0.8725\n",
      "\n",
      "Epoch 00096: val_auroc did not improve from 0.89125\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2572 - acc: 0.8953 - auroc: 0.9583 - val_loss: 0.4603 - val_acc: 0.8019 - val_auroc: 0.8858\n",
      "\n",
      "Epoch 00097: val_auroc did not improve from 0.89125\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 90s 450ms/step - loss: 0.2515 - acc: 0.8972 - auroc: 0.9585 - val_loss: 0.5237 - val_acc: 0.7694 - val_auroc: 0.8764\n",
      "\n",
      "Epoch 00098: val_auroc did not improve from 0.89125\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2411 - acc: 0.9041 - auroc: 0.9595 - val_loss: 0.5039 - val_acc: 0.7725 - val_auroc: 0.8658\n",
      "\n",
      "Epoch 00099: val_auroc did not improve from 0.89125\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 90s 451ms/step - loss: 0.2454 - acc: 0.9034 - auroc: 0.9592 - val_loss: 0.5166 - val_acc: 0.7794 - val_auroc: 0.8634\n",
      "\n",
      "Epoch 00100: val_auroc did not improve from 0.89125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4578687c50>"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=True,\n",
    "                    validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=100, verbose=1,\n",
    "                    workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6LExOS6x5yF"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"drive/My Drive/Face_recognition/vgg_face_cosine.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJsTr5iQx5tV"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", metrics=['acc',auroc], optimizer=Adam(0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3rxS09I-7l8f",
    "outputId": "7433f0b1-7eb9-4939-d314-af256f8ae0b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166it [32:28,  9.13s/it]\n"
     ]
    }
   ],
   "source": [
    "test_path = \"drive/My Drive/Face_recognition/test/\"\n",
    "def chunker(seq, size=32):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "submission = pd.read_csv('drive/My Drive/Face_recognition/sample_submission.csv')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in tqdm(chunker(submission.img_pair.values)):\n",
    "    X1 = [x.split(\"-\")[0] for x in batch]\n",
    "    X1 = np.array([read_img(test_path + x) for x in X1])\n",
    "\n",
    "    X2 = [x.split(\"-\")[1] for x in batch]\n",
    "    X2 = np.array([read_img(test_path + x) for x in X2])\n",
    "\n",
    "    pred = model.predict([X1, X2]).ravel().tolist()\n",
    "    predictions += pred\n",
    "\n",
    "submission['is_related'] = predictions\n",
    "\n",
    "submission.to_csv(\"drive/My Drive/Face_recognition/cosine_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XcyH1lqV5P-D"
   },
   "source": [
    "### Test Score: 0.858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QETJ6qiXPh3k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rm5_56bCa6um"
   },
   "source": [
    "### 4. Experimenting with dropouts and learning rates from previous model(Model 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BfeTh5Z7Vsx"
   },
   "outputs": [],
   "source": [
    "def cosine_model2():\n",
    "    #change 2\n",
    "    input_1 = Input(shape=(197, 197, 3))\n",
    "    input_2 = Input(shape=(197, 197, 3))\n",
    "\n",
    "    base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "\n",
    "    x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)])\n",
    "    x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n",
    "\n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "\n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    \n",
    "    #https://stackoverflow.com/a/51003359/10650182\n",
    "    x5 = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([x1, x2])\n",
    "    \n",
    "    x = Concatenate(axis=-1)([x5,x4, x3])\n",
    "\n",
    "    x = Dense(100, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=['acc',auroc], optimizer=Adam(0.00001))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 958
    },
    "colab_type": "code",
    "id": "VtMZR-3u7VoC",
    "outputId": "a2a3bb57-5b79-4915-f889-190648561058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vggface_resnet50 (Model)        multiple             23561152    input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalM (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_4 (GlobalM (None, 2048)         0           vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 2048)         0           vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4096)         0           global_max_pooling2d_3[0][0]     \n",
      "                                                                 global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 4096)         0           global_max_pooling2d_4[0][0]     \n",
      "                                                                 global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 4096)         0           concatenate_4[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 4096)         0           concatenate_5[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 4096)         0           concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract_4 (Subtract)           (None, 4096)         0           multiply_5[0][0]                 \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 4096)         0           subtract_3[0][0]                 \n",
      "                                                                 subtract_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8193)         0           lambda_2[0][0]                   \n",
      "                                                                 subtract_4[0][0]                 \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          819400      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            101         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,380,653\n",
      "Trainable params: 24,327,533\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "file_path = \"drive/My Drive/Face_recognition/vgg_face_cosine2.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_auroc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_auroc\", mode=\"max\", factor=0.1, patience=5, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "model2 = cosine_model2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YdHUMlcb7VjS",
    "outputId": "800584c9-0096-4ca0-ea35-71788acca86b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 74s 744ms/step - loss: 4.1887 - acc: 0.5363 - auroc: 0.5628 - val_loss: 4.1303 - val_acc: 0.5719 - val_auroc: 0.5984\n",
      "\n",
      "Epoch 00001: val_auroc improved from -inf to 0.59844, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 53s 530ms/step - loss: 2.9020 - acc: 0.5981 - auroc: 0.6362 - val_loss: 2.9841 - val_acc: 0.6162 - val_auroc: 0.6570\n",
      "\n",
      "Epoch 00002: val_auroc improved from 0.59844 to 0.65695, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 53s 528ms/step - loss: 2.1237 - acc: 0.6038 - auroc: 0.6441 - val_loss: 2.3747 - val_acc: 0.5837 - val_auroc: 0.6227\n",
      "\n",
      "Epoch 00003: val_auroc did not improve from 0.65695\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 53s 525ms/step - loss: 1.5186 - acc: 0.6106 - auroc: 0.6531 - val_loss: 1.8971 - val_acc: 0.5731 - val_auroc: 0.5910\n",
      "\n",
      "Epoch 00004: val_auroc did not improve from 0.65695\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 52s 525ms/step - loss: 1.1004 - acc: 0.6106 - auroc: 0.6633 - val_loss: 1.2777 - val_acc: 0.6200 - val_auroc: 0.6670\n",
      "\n",
      "Epoch 00005: val_auroc improved from 0.65695 to 0.66695, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 53s 526ms/step - loss: 0.9189 - acc: 0.6281 - auroc: 0.6831 - val_loss: 1.1927 - val_acc: 0.6306 - val_auroc: 0.6572\n",
      "\n",
      "Epoch 00006: val_auroc did not improve from 0.66695\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.7722 - acc: 0.6388 - auroc: 0.7020 - val_loss: 1.0478 - val_acc: 0.6438 - val_auroc: 0.6720\n",
      "\n",
      "Epoch 00007: val_auroc improved from 0.66695 to 0.67203, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 53s 525ms/step - loss: 0.7316 - acc: 0.6562 - auroc: 0.7016 - val_loss: 0.9022 - val_acc: 0.6388 - val_auroc: 0.6750\n",
      "\n",
      "Epoch 00008: val_auroc improved from 0.67203 to 0.67500, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.6975 - acc: 0.6531 - auroc: 0.7011 - val_loss: 0.7782 - val_acc: 0.6675 - val_auroc: 0.7098\n",
      "\n",
      "Epoch 00009: val_auroc improved from 0.67500 to 0.70984, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 53s 525ms/step - loss: 0.6261 - acc: 0.6750 - auroc: 0.7456 - val_loss: 0.7947 - val_acc: 0.6681 - val_auroc: 0.7196\n",
      "\n",
      "Epoch 00010: val_auroc improved from 0.70984 to 0.71961, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 53s 526ms/step - loss: 0.6075 - acc: 0.6813 - auroc: 0.7466 - val_loss: 0.8400 - val_acc: 0.6900 - val_auroc: 0.7268\n",
      "\n",
      "Epoch 00011: val_auroc improved from 0.71961 to 0.72680, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.6247 - acc: 0.6675 - auroc: 0.7281 - val_loss: 0.7698 - val_acc: 0.6863 - val_auroc: 0.7419\n",
      "\n",
      "Epoch 00012: val_auroc improved from 0.72680 to 0.74187, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.5928 - acc: 0.7137 - auroc: 0.7636 - val_loss: 0.7669 - val_acc: 0.6800 - val_auroc: 0.7243\n",
      "\n",
      "Epoch 00013: val_auroc did not improve from 0.74187\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.5613 - acc: 0.7125 - auroc: 0.7778 - val_loss: 0.7732 - val_acc: 0.6969 - val_auroc: 0.7519\n",
      "\n",
      "Epoch 00014: val_auroc improved from 0.74187 to 0.75187, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 53s 525ms/step - loss: 0.5383 - acc: 0.7144 - auroc: 0.7930 - val_loss: 0.6681 - val_acc: 0.7119 - val_auroc: 0.7577\n",
      "\n",
      "Epoch 00015: val_auroc improved from 0.75187 to 0.75766, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 52s 525ms/step - loss: 0.5552 - acc: 0.7181 - auroc: 0.7881 - val_loss: 0.8071 - val_acc: 0.7069 - val_auroc: 0.7437\n",
      "\n",
      "Epoch 00016: val_auroc did not improve from 0.75766\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.5575 - acc: 0.7119 - auroc: 0.7823 - val_loss: 0.6719 - val_acc: 0.7069 - val_auroc: 0.7645\n",
      "\n",
      "Epoch 00017: val_auroc improved from 0.75766 to 0.76453, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 53s 526ms/step - loss: 0.5262 - acc: 0.7250 - auroc: 0.8031 - val_loss: 0.6081 - val_acc: 0.7338 - val_auroc: 0.8023\n",
      "\n",
      "Epoch 00018: val_auroc improved from 0.76453 to 0.80234, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.5059 - acc: 0.7438 - auroc: 0.8238 - val_loss: 0.5877 - val_acc: 0.7350 - val_auroc: 0.7981\n",
      "\n",
      "Epoch 00019: val_auroc did not improve from 0.80234\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.5110 - acc: 0.7313 - auroc: 0.8136 - val_loss: 0.7667 - val_acc: 0.7206 - val_auroc: 0.7764\n",
      "\n",
      "Epoch 00020: val_auroc did not improve from 0.80234\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.5163 - acc: 0.7381 - auroc: 0.8123 - val_loss: 0.6657 - val_acc: 0.7231 - val_auroc: 0.7797\n",
      "\n",
      "Epoch 00021: val_auroc did not improve from 0.80234\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 53s 526ms/step - loss: 0.5262 - acc: 0.7356 - auroc: 0.8056 - val_loss: 0.6320 - val_acc: 0.7375 - val_auroc: 0.7863\n",
      "\n",
      "Epoch 00022: val_auroc did not improve from 0.80234\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 52s 525ms/step - loss: 0.5041 - acc: 0.7438 - auroc: 0.8256 - val_loss: 0.6443 - val_acc: 0.7412 - val_auroc: 0.7948\n",
      "\n",
      "Epoch 00023: val_auroc did not improve from 0.80234\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.5239 - acc: 0.7338 - auroc: 0.8103 - val_loss: 0.5888 - val_acc: 0.7519 - val_auroc: 0.8113\n",
      "\n",
      "Epoch 00024: val_auroc improved from 0.80234 to 0.81125, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 53s 526ms/step - loss: 0.4865 - acc: 0.7562 - auroc: 0.8397 - val_loss: 0.5690 - val_acc: 0.7375 - val_auroc: 0.8006\n",
      "\n",
      "Epoch 00025: val_auroc did not improve from 0.81125\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.4932 - acc: 0.7525 - auroc: 0.8356 - val_loss: 0.5807 - val_acc: 0.7219 - val_auroc: 0.7850\n",
      "\n",
      "Epoch 00026: val_auroc did not improve from 0.81125\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 52s 525ms/step - loss: 0.5044 - acc: 0.7537 - auroc: 0.8291 - val_loss: 0.5853 - val_acc: 0.7344 - val_auroc: 0.7981\n",
      "\n",
      "Epoch 00027: val_auroc did not improve from 0.81125\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 53s 525ms/step - loss: 0.4912 - acc: 0.7488 - auroc: 0.8319 - val_loss: 0.5588 - val_acc: 0.7288 - val_auroc: 0.8034\n",
      "\n",
      "Epoch 00028: val_auroc did not improve from 0.81125\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 53s 525ms/step - loss: 0.4878 - acc: 0.7694 - auroc: 0.8337 - val_loss: 0.5846 - val_acc: 0.7556 - val_auroc: 0.8134\n",
      "\n",
      "Epoch 00029: val_auroc improved from 0.81125 to 0.81344, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 53s 526ms/step - loss: 0.4927 - acc: 0.7594 - auroc: 0.8291 - val_loss: 0.5804 - val_acc: 0.7475 - val_auroc: 0.7992\n",
      "\n",
      "Epoch 00030: val_auroc did not improve from 0.81344\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 53s 525ms/step - loss: 0.4683 - acc: 0.7662 - auroc: 0.8530 - val_loss: 0.5566 - val_acc: 0.7462 - val_auroc: 0.8039\n",
      "\n",
      "Epoch 00031: val_auroc did not improve from 0.81344\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.5185 - acc: 0.7313 - auroc: 0.8131 - val_loss: 0.5889 - val_acc: 0.7481 - val_auroc: 0.8148\n",
      "\n",
      "Epoch 00032: val_auroc improved from 0.81344 to 0.81484, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 53s 525ms/step - loss: 0.4837 - acc: 0.7638 - auroc: 0.8409 - val_loss: 0.5893 - val_acc: 0.7419 - val_auroc: 0.8037\n",
      "\n",
      "Epoch 00033: val_auroc did not improve from 0.81484\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.4804 - acc: 0.7544 - auroc: 0.8353 - val_loss: 0.5907 - val_acc: 0.7569 - val_auroc: 0.8187\n",
      "\n",
      "Epoch 00034: val_auroc improved from 0.81484 to 0.81875, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 52s 525ms/step - loss: 0.4941 - acc: 0.7506 - auroc: 0.8286 - val_loss: 0.5282 - val_acc: 0.7544 - val_auroc: 0.8256\n",
      "\n",
      "Epoch 00035: val_auroc improved from 0.81875 to 0.82563, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4746 - acc: 0.7687 - auroc: 0.8486 - val_loss: 0.5397 - val_acc: 0.7712 - val_auroc: 0.8278\n",
      "\n",
      "Epoch 00036: val_auroc improved from 0.82563 to 0.82781, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 52s 525ms/step - loss: 0.4551 - acc: 0.7825 - auroc: 0.8603 - val_loss: 0.5595 - val_acc: 0.7481 - val_auroc: 0.8144\n",
      "\n",
      "Epoch 00037: val_auroc did not improve from 0.82781\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4835 - acc: 0.7600 - auroc: 0.8341 - val_loss: 0.6128 - val_acc: 0.7400 - val_auroc: 0.7948\n",
      "\n",
      "Epoch 00038: val_auroc did not improve from 0.82781\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4972 - acc: 0.7613 - auroc: 0.8333 - val_loss: 0.5603 - val_acc: 0.7512 - val_auroc: 0.8223\n",
      "\n",
      "Epoch 00039: val_auroc did not improve from 0.82781\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4665 - acc: 0.7831 - auroc: 0.8488 - val_loss: 0.6019 - val_acc: 0.7306 - val_auroc: 0.8095\n",
      "\n",
      "Epoch 00040: val_auroc did not improve from 0.82781\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4695 - acc: 0.7831 - auroc: 0.8467 - val_loss: 0.5723 - val_acc: 0.7431 - val_auroc: 0.8161\n",
      "\n",
      "Epoch 00041: val_auroc did not improve from 0.82781\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4640 - acc: 0.7738 - auroc: 0.8516 - val_loss: 0.5884 - val_acc: 0.7438 - val_auroc: 0.8025\n",
      "\n",
      "Epoch 00042: val_auroc did not improve from 0.82781\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.4722 - acc: 0.7700 - auroc: 0.8456 - val_loss: 0.5957 - val_acc: 0.7512 - val_auroc: 0.8033\n",
      "\n",
      "Epoch 00043: val_auroc did not improve from 0.82781\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4785 - acc: 0.7687 - auroc: 0.8370 - val_loss: 0.5481 - val_acc: 0.7381 - val_auroc: 0.8045\n",
      "\n",
      "Epoch 00044: val_auroc did not improve from 0.82781\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4636 - acc: 0.7800 - auroc: 0.8563 - val_loss: 0.5508 - val_acc: 0.7631 - val_auroc: 0.8315\n",
      "\n",
      "Epoch 00045: val_auroc improved from 0.82781 to 0.83148, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.4658 - acc: 0.7625 - auroc: 0.8473 - val_loss: 0.5364 - val_acc: 0.7494 - val_auroc: 0.8144\n",
      "\n",
      "Epoch 00046: val_auroc did not improve from 0.83148\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4715 - acc: 0.7800 - auroc: 0.8544 - val_loss: 0.6041 - val_acc: 0.7425 - val_auroc: 0.8105\n",
      "\n",
      "Epoch 00047: val_auroc did not improve from 0.83148\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4755 - acc: 0.7706 - auroc: 0.8470 - val_loss: 0.6028 - val_acc: 0.7569 - val_auroc: 0.8173\n",
      "\n",
      "Epoch 00048: val_auroc did not improve from 0.83148\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4703 - acc: 0.7775 - auroc: 0.8489 - val_loss: 0.5402 - val_acc: 0.7481 - val_auroc: 0.8119\n",
      "\n",
      "Epoch 00049: val_auroc did not improve from 0.83148\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4624 - acc: 0.7738 - auroc: 0.8544 - val_loss: 0.5875 - val_acc: 0.7419 - val_auroc: 0.8050\n",
      "\n",
      "Epoch 00050: val_auroc did not improve from 0.83148\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4612 - acc: 0.7825 - auroc: 0.8552 - val_loss: 0.5517 - val_acc: 0.7612 - val_auroc: 0.8284\n",
      "\n",
      "Epoch 00051: val_auroc did not improve from 0.83148\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4755 - acc: 0.7613 - auroc: 0.8406 - val_loss: 0.5563 - val_acc: 0.7606 - val_auroc: 0.8281\n",
      "\n",
      "Epoch 00052: val_auroc did not improve from 0.83148\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4672 - acc: 0.7687 - auroc: 0.8514 - val_loss: 0.6168 - val_acc: 0.7612 - val_auroc: 0.8259\n",
      "\n",
      "Epoch 00053: val_auroc did not improve from 0.83148\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4840 - acc: 0.7544 - auroc: 0.8419 - val_loss: 0.6068 - val_acc: 0.7412 - val_auroc: 0.8070\n",
      "\n",
      "Epoch 00054: val_auroc did not improve from 0.83148\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4460 - acc: 0.7975 - auroc: 0.8673 - val_loss: 0.5806 - val_acc: 0.7469 - val_auroc: 0.8036\n",
      "\n",
      "Epoch 00055: val_auroc did not improve from 0.83148\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4740 - acc: 0.7562 - auroc: 0.8409 - val_loss: 0.6157 - val_acc: 0.7600 - val_auroc: 0.8083\n",
      "\n",
      "Epoch 00056: val_auroc did not improve from 0.83148\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4707 - acc: 0.7662 - auroc: 0.8472 - val_loss: 0.5683 - val_acc: 0.7650 - val_auroc: 0.8156\n",
      "\n",
      "Epoch 00057: val_auroc did not improve from 0.83148\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4799 - acc: 0.7644 - auroc: 0.8361 - val_loss: 0.6448 - val_acc: 0.7412 - val_auroc: 0.7936\n",
      "\n",
      "Epoch 00058: val_auroc did not improve from 0.83148\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4823 - acc: 0.7731 - auroc: 0.8409 - val_loss: 0.5879 - val_acc: 0.7681 - val_auroc: 0.8177\n",
      "\n",
      "Epoch 00059: val_auroc did not improve from 0.83148\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4775 - acc: 0.7719 - auroc: 0.8461 - val_loss: 0.6125 - val_acc: 0.7406 - val_auroc: 0.8011\n",
      "\n",
      "Epoch 00060: val_auroc did not improve from 0.83148\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4601 - acc: 0.7831 - auroc: 0.8600 - val_loss: 0.5540 - val_acc: 0.7450 - val_auroc: 0.8152\n",
      "\n",
      "Epoch 00061: val_auroc did not improve from 0.83148\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4660 - acc: 0.7588 - auroc: 0.8519 - val_loss: 0.5615 - val_acc: 0.7531 - val_auroc: 0.8225\n",
      "\n",
      "Epoch 00062: val_auroc did not improve from 0.83148\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4812 - acc: 0.7681 - auroc: 0.8363 - val_loss: 0.5282 - val_acc: 0.7575 - val_auroc: 0.8271\n",
      "\n",
      "Epoch 00063: val_auroc did not improve from 0.83148\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4818 - acc: 0.7681 - auroc: 0.8327 - val_loss: 0.5750 - val_acc: 0.7594 - val_auroc: 0.8033\n",
      "\n",
      "Epoch 00064: val_auroc did not improve from 0.83148\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4713 - acc: 0.7562 - auroc: 0.8420 - val_loss: 0.5669 - val_acc: 0.7462 - val_auroc: 0.8153\n",
      "\n",
      "Epoch 00065: val_auroc did not improve from 0.83148\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4508 - acc: 0.7863 - auroc: 0.8634 - val_loss: 0.5896 - val_acc: 0.7575 - val_auroc: 0.8194\n",
      "\n",
      "Epoch 00066: val_auroc did not improve from 0.83148\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4614 - acc: 0.7906 - auroc: 0.8558 - val_loss: 0.5333 - val_acc: 0.7700 - val_auroc: 0.8439\n",
      "\n",
      "Epoch 00067: val_auroc improved from 0.83148 to 0.84391, saving model to drive/My Drive/Face_recognition/vgg_face_cosine2.h5\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4529 - acc: 0.7738 - auroc: 0.8644 - val_loss: 0.6006 - val_acc: 0.7375 - val_auroc: 0.7983\n",
      "\n",
      "Epoch 00068: val_auroc did not improve from 0.84391\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 52s 520ms/step - loss: 0.4806 - acc: 0.7662 - auroc: 0.8431 - val_loss: 0.5687 - val_acc: 0.7750 - val_auroc: 0.8102\n",
      "\n",
      "Epoch 00069: val_auroc did not improve from 0.84391\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4757 - acc: 0.7750 - auroc: 0.8450 - val_loss: 0.6301 - val_acc: 0.7294 - val_auroc: 0.7917\n",
      "\n",
      "Epoch 00070: val_auroc did not improve from 0.84391\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4798 - acc: 0.7750 - auroc: 0.8478 - val_loss: 0.5492 - val_acc: 0.7650 - val_auroc: 0.8234\n",
      "\n",
      "Epoch 00071: val_auroc did not improve from 0.84391\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4621 - acc: 0.7825 - auroc: 0.8525 - val_loss: 0.5530 - val_acc: 0.7594 - val_auroc: 0.8163\n",
      "\n",
      "Epoch 00072: val_auroc did not improve from 0.84391\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4815 - acc: 0.7525 - auroc: 0.8394 - val_loss: 0.5861 - val_acc: 0.7556 - val_auroc: 0.8155\n",
      "\n",
      "Epoch 00073: val_auroc did not improve from 0.84391\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4578 - acc: 0.7756 - auroc: 0.8545 - val_loss: 0.5514 - val_acc: 0.7619 - val_auroc: 0.8225\n",
      "\n",
      "Epoch 00074: val_auroc did not improve from 0.84391\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4738 - acc: 0.7756 - auroc: 0.8433 - val_loss: 0.5101 - val_acc: 0.7675 - val_auroc: 0.8391\n",
      "\n",
      "Epoch 00075: val_auroc did not improve from 0.84391\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 52s 520ms/step - loss: 0.4448 - acc: 0.7906 - auroc: 0.8662 - val_loss: 0.5849 - val_acc: 0.7531 - val_auroc: 0.8141\n",
      "\n",
      "Epoch 00076: val_auroc did not improve from 0.84391\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4695 - acc: 0.7756 - auroc: 0.8539 - val_loss: 0.5539 - val_acc: 0.7462 - val_auroc: 0.8142\n",
      "\n",
      "Epoch 00077: val_auroc did not improve from 0.84391\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 52s 520ms/step - loss: 0.4790 - acc: 0.7613 - auroc: 0.8375 - val_loss: 0.6746 - val_acc: 0.7381 - val_auroc: 0.7785\n",
      "\n",
      "Epoch 00078: val_auroc did not improve from 0.84391\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4998 - acc: 0.7475 - auroc: 0.8269 - val_loss: 0.5996 - val_acc: 0.7462 - val_auroc: 0.8111\n",
      "\n",
      "Epoch 00079: val_auroc did not improve from 0.84391\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4974 - acc: 0.7456 - auroc: 0.8289 - val_loss: 0.6001 - val_acc: 0.7600 - val_auroc: 0.8073\n",
      "\n",
      "Epoch 00080: val_auroc did not improve from 0.84391\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4621 - acc: 0.7675 - auroc: 0.8548 - val_loss: 0.5348 - val_acc: 0.7750 - val_auroc: 0.8312\n",
      "\n",
      "Epoch 00081: val_auroc did not improve from 0.84391\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4777 - acc: 0.7669 - auroc: 0.8481 - val_loss: 0.6064 - val_acc: 0.7569 - val_auroc: 0.8070\n",
      "\n",
      "Epoch 00082: val_auroc did not improve from 0.84391\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 9.999999146890344e-15.\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4614 - acc: 0.7831 - auroc: 0.8533 - val_loss: 0.6006 - val_acc: 0.7469 - val_auroc: 0.8037\n",
      "\n",
      "Epoch 00083: val_auroc did not improve from 0.84391\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4562 - acc: 0.7900 - auroc: 0.8563 - val_loss: 0.5664 - val_acc: 0.7494 - val_auroc: 0.8069\n",
      "\n",
      "Epoch 00084: val_auroc did not improve from 0.84391\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4862 - acc: 0.7613 - auroc: 0.8337 - val_loss: 0.5651 - val_acc: 0.7669 - val_auroc: 0.8283\n",
      "\n",
      "Epoch 00085: val_auroc did not improve from 0.84391\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4552 - acc: 0.7950 - auroc: 0.8609 - val_loss: 0.5394 - val_acc: 0.7625 - val_auroc: 0.8346\n",
      "\n",
      "Epoch 00086: val_auroc did not improve from 0.84391\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 0.4674 - acc: 0.7706 - auroc: 0.8481 - val_loss: 0.5746 - val_acc: 0.7375 - val_auroc: 0.8016\n",
      "\n",
      "Epoch 00087: val_auroc did not improve from 0.84391\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 9.999998977483753e-16.\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4632 - acc: 0.7731 - auroc: 0.8491 - val_loss: 0.6042 - val_acc: 0.7306 - val_auroc: 0.7931\n",
      "\n",
      "Epoch 00088: val_auroc did not improve from 0.84391\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.4706 - acc: 0.7650 - auroc: 0.8409 - val_loss: 0.6055 - val_acc: 0.7462 - val_auroc: 0.8009\n",
      "\n",
      "Epoch 00089: val_auroc did not improve from 0.84391\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4833 - acc: 0.7656 - auroc: 0.8373 - val_loss: 0.5956 - val_acc: 0.7512 - val_auroc: 0.8056\n",
      "\n",
      "Epoch 00090: val_auroc did not improve from 0.84391\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 53s 526ms/step - loss: 0.4760 - acc: 0.7444 - auroc: 0.8344 - val_loss: 0.5473 - val_acc: 0.7475 - val_auroc: 0.8219\n",
      "\n",
      "Epoch 00091: val_auroc did not improve from 0.84391\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.4700 - acc: 0.7687 - auroc: 0.8405 - val_loss: 0.5808 - val_acc: 0.7431 - val_auroc: 0.8034\n",
      "\n",
      "Epoch 00092: val_auroc did not improve from 0.84391\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 9.999998977483754e-17.\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4592 - acc: 0.7875 - auroc: 0.8570 - val_loss: 0.5682 - val_acc: 0.7500 - val_auroc: 0.8116\n",
      "\n",
      "Epoch 00093: val_auroc did not improve from 0.84391\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.5013 - acc: 0.7463 - auroc: 0.8216 - val_loss: 0.5723 - val_acc: 0.7519 - val_auroc: 0.8203\n",
      "\n",
      "Epoch 00094: val_auroc did not improve from 0.84391\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 52s 525ms/step - loss: 0.4737 - acc: 0.7762 - auroc: 0.8453 - val_loss: 0.5848 - val_acc: 0.7625 - val_auroc: 0.8167\n",
      "\n",
      "Epoch 00095: val_auroc did not improve from 0.84391\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4862 - acc: 0.7625 - auroc: 0.8341 - val_loss: 0.6308 - val_acc: 0.7469 - val_auroc: 0.7863\n",
      "\n",
      "Epoch 00096: val_auroc did not improve from 0.84391\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.4784 - acc: 0.7581 - auroc: 0.8395 - val_loss: 0.6145 - val_acc: 0.7225 - val_auroc: 0.8011\n",
      "\n",
      "Epoch 00097: val_auroc did not improve from 0.84391\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 9.999998845134856e-18.\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.4691 - acc: 0.7694 - auroc: 0.8472 - val_loss: 0.5939 - val_acc: 0.7606 - val_auroc: 0.8105\n",
      "\n",
      "Epoch 00098: val_auroc did not improve from 0.84391\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.4918 - acc: 0.7681 - auroc: 0.8416 - val_loss: 0.5698 - val_acc: 0.7675 - val_auroc: 0.8283\n",
      "\n",
      "Epoch 00099: val_auroc did not improve from 0.84391\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 52s 524ms/step - loss: 0.4686 - acc: 0.7662 - auroc: 0.8456 - val_loss: 0.5841 - val_acc: 0.7594 - val_auroc: 0.8211\n",
      "\n",
      "Epoch 00100: val_auroc did not improve from 0.84391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f44f069a710>"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit_generator(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=True,\n",
    "                    validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=100, verbose=1,\n",
    "                    workers = 4, callbacks=callbacks_list, steps_per_epoch=100, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eLfmBna97VdX"
   },
   "outputs": [],
   "source": [
    "model2.load_weights(\"drive/My Drive/Face_recognition/vgg_face_cosine2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0p8xIOc7VYn"
   },
   "outputs": [],
   "source": [
    "model2.compile(loss=\"binary_crossentropy\", metrics=['acc',auroc], optimizer=Adam(0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vHLhgf7X7VTh",
    "outputId": "cea65d6d-a5fe-4747-8b19-b3b4dcc272d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166it [01:18,  2.28it/s]\n"
     ]
    }
   ],
   "source": [
    "test_path = \"drive/My Drive/Face_recognition/test/\"\n",
    "def chunker(seq, size=32):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "submission = pd.read_csv('drive/My Drive/Face_recognition/sample_submission.csv')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in tqdm(chunker(submission.img_pair.values)):\n",
    "    X1 = [x.split(\"-\")[0] for x in batch]\n",
    "    X1 = np.array([read_img(test_path + x) for x in X1])\n",
    "\n",
    "    X2 = [x.split(\"-\")[1] for x in batch]\n",
    "    X2 = np.array([read_img(test_path + x) for x in X2])\n",
    "\n",
    "    pred = model.predict([X1, X2]).ravel().tolist()\n",
    "    predictions += pred\n",
    "\n",
    "submission['is_related'] = predictions\n",
    "\n",
    "submission.to_csv(\"drive/My Drive/Face_recognition/cosine_submission2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TVmOoEHZ3J7"
   },
   "source": [
    "### test score : 0.858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fC4abwLZ8Cy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1u3F-UVIbHJQ"
   },
   "source": [
    "### 5. Experimenting with focal loss and Global Max Pool layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2p_ywdGgoFm"
   },
   "source": [
    "### https://www.kaggle.com/tenffe/vggface-cv-focal-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SIe3IzCzeuW7"
   },
   "outputs": [],
   "source": [
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(K.epsilon()+pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MNX1SUyphI7S"
   },
   "outputs": [],
   "source": [
    "def cosine_focal_model():\n",
    "    #change 2\n",
    "    input_1 = Input(shape=(197, 197, 3))\n",
    "    input_2 = Input(shape=(197, 197, 3))\n",
    "\n",
    "    base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "\n",
    "    x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)])\n",
    "    x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n",
    "\n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "\n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    \n",
    "    #https://stackoverflow.com/a/51003359/10650182\n",
    "    x5 = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([x1, x2])\n",
    "    \n",
    "    x = Concatenate(axis=-1)([x5,x4, x3])\n",
    "\n",
    "    x = Dense(100, activation=\"relu\")(x)\n",
    "    x = Dropout(0.01)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc',auroc], optimizer=Adam(0.00001))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "apAKylAweupK",
    "outputId": "da6924a9-fc12-45c2-c699-c78e39307cb8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0731 05:47:04.422280 139844433500032 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0731 05:47:04.461184 139844433500032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0731 05:47:04.467456 139844433500032 deprecation.py:323] From <ipython-input-39-5d124dd4d6b8>:3: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0731 05:47:04.498289 139844433500032 deprecation.py:323] From <ipython-input-2-bc412d992b42>:14: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vggface_resnet50 (Model)        multiple             23561152    input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalM (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_4 (GlobalM (None, 2048)         0           vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4096)         0           global_max_pooling2d_3[0][0]     \n",
      "                                                                 global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4096)         0           global_max_pooling2d_4[0][0]     \n",
      "                                                                 global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 4096)         0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 4096)         0           concatenate_2[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 4096)         0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 4096)         0           multiply_2[0][0]                 \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 4096)         0           subtract_2[0][0]                 \n",
      "                                                                 subtract_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8193)         0           lambda_1[0][0]                   \n",
      "                                                                 subtract_3[0][0]                 \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          819400      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            101         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,380,653\n",
      "Trainable params: 24,327,533\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "file_path = \"drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_auroc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_auroc\", mode=\"max\", factor=0.1, patience=10, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "model = cosine_focal_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7YzYLAHdg8CD",
    "outputId": "c6af1489-402a-4db2-8f50-63570fbe3063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "200/200 [==============================] - 296s 1s/step - loss: 22.2924 - acc: 0.5687 - auroc: 0.6291 - val_loss: 24.6558 - val_acc: 0.6000 - val_auroc: 0.6250\n",
      "\n",
      "Epoch 00001: val_auroc improved from -inf to 0.62500, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 136s 678ms/step - loss: 12.5627 - acc: 0.5809 - auroc: 0.6542 - val_loss: 17.2172 - val_acc: 0.5794 - val_auroc: 0.6200\n",
      "\n",
      "Epoch 00002: val_auroc did not improve from 0.62500\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 97s 486ms/step - loss: 5.3335 - acc: 0.5997 - auroc: 0.6770 - val_loss: 6.9322 - val_acc: 0.5850 - val_auroc: 0.6465\n",
      "\n",
      "Epoch 00003: val_auroc improved from 0.62500 to 0.64648, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 89s 445ms/step - loss: 2.8715 - acc: 0.6134 - auroc: 0.6917 - val_loss: 3.6709 - val_acc: 0.6144 - val_auroc: 0.6909\n",
      "\n",
      "Epoch 00004: val_auroc improved from 0.64648 to 0.69094, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 90s 448ms/step - loss: 1.9031 - acc: 0.6078 - auroc: 0.6862 - val_loss: 2.5229 - val_acc: 0.5875 - val_auroc: 0.6694\n",
      "\n",
      "Epoch 00005: val_auroc did not improve from 0.69094\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 89s 446ms/step - loss: 1.3842 - acc: 0.6219 - auroc: 0.7294 - val_loss: 1.9658 - val_acc: 0.6206 - val_auroc: 0.6956\n",
      "\n",
      "Epoch 00006: val_auroc improved from 0.69094 to 0.69563, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 89s 447ms/step - loss: 1.2555 - acc: 0.6288 - auroc: 0.7325 - val_loss: 1.9831 - val_acc: 0.6106 - val_auroc: 0.6875\n",
      "\n",
      "Epoch 00007: val_auroc did not improve from 0.69563\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 89s 447ms/step - loss: 1.1069 - acc: 0.6272 - auroc: 0.7587 - val_loss: 1.7468 - val_acc: 0.6325 - val_auroc: 0.7152\n",
      "\n",
      "Epoch 00008: val_auroc improved from 0.69563 to 0.71516, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 89s 445ms/step - loss: 1.0606 - acc: 0.6234 - auroc: 0.7607 - val_loss: 1.4611 - val_acc: 0.6138 - val_auroc: 0.7219\n",
      "\n",
      "Epoch 00009: val_auroc improved from 0.71516 to 0.72188, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 89s 445ms/step - loss: 1.0461 - acc: 0.6372 - auroc: 0.7639 - val_loss: 1.2553 - val_acc: 0.6406 - val_auroc: 0.7577\n",
      "\n",
      "Epoch 00010: val_auroc improved from 0.72188 to 0.75766, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 89s 446ms/step - loss: 0.9745 - acc: 0.6534 - auroc: 0.7933 - val_loss: 1.4011 - val_acc: 0.6312 - val_auroc: 0.7330\n",
      "\n",
      "Epoch 00011: val_auroc did not improve from 0.75766\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 89s 443ms/step - loss: 0.9629 - acc: 0.6356 - auroc: 0.7941 - val_loss: 1.2292 - val_acc: 0.6225 - val_auroc: 0.7492\n",
      "\n",
      "Epoch 00012: val_auroc did not improve from 0.75766\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 90s 448ms/step - loss: 0.9107 - acc: 0.6634 - auroc: 0.8130 - val_loss: 1.2425 - val_acc: 0.6294 - val_auroc: 0.7669\n",
      "\n",
      "Epoch 00013: val_auroc improved from 0.75766 to 0.76687, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 89s 443ms/step - loss: 0.9288 - acc: 0.6428 - auroc: 0.8087 - val_loss: 0.9884 - val_acc: 0.6494 - val_auroc: 0.7947\n",
      "\n",
      "Epoch 00014: val_auroc improved from 0.76687 to 0.79469, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 0.8670 - acc: 0.6716 - auroc: 0.8282 - val_loss: 1.0700 - val_acc: 0.6350 - val_auroc: 0.7858\n",
      "\n",
      "Epoch 00015: val_auroc did not improve from 0.79469\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 89s 443ms/step - loss: 0.8698 - acc: 0.6697 - auroc: 0.8301 - val_loss: 1.2093 - val_acc: 0.6288 - val_auroc: 0.7864\n",
      "\n",
      "Epoch 00016: val_auroc did not improve from 0.79469\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 0.8584 - acc: 0.6903 - auroc: 0.8337 - val_loss: 1.0430 - val_acc: 0.6650 - val_auroc: 0.8103\n",
      "\n",
      "Epoch 00017: val_auroc improved from 0.79469 to 0.81031, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 0.8193 - acc: 0.6928 - auroc: 0.8498 - val_loss: 1.1294 - val_acc: 0.6806 - val_auroc: 0.8009\n",
      "\n",
      "Epoch 00018: val_auroc did not improve from 0.81031\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.8463 - acc: 0.6853 - auroc: 0.8419 - val_loss: 0.9285 - val_acc: 0.6538 - val_auroc: 0.8194\n",
      "\n",
      "Epoch 00019: val_auroc improved from 0.81031 to 0.81937, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.8076 - acc: 0.6978 - auroc: 0.8616 - val_loss: 1.0558 - val_acc: 0.6444 - val_auroc: 0.7989\n",
      "\n",
      "Epoch 00020: val_auroc did not improve from 0.81937\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.7806 - acc: 0.7159 - auroc: 0.8713 - val_loss: 1.0007 - val_acc: 0.6913 - val_auroc: 0.8213\n",
      "\n",
      "Epoch 00021: val_auroc improved from 0.81937 to 0.82125, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 0.7741 - acc: 0.7188 - auroc: 0.8688 - val_loss: 0.8921 - val_acc: 0.6913 - val_auroc: 0.8397\n",
      "\n",
      "Epoch 00022: val_auroc improved from 0.82125 to 0.83969, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.7901 - acc: 0.7122 - auroc: 0.8673 - val_loss: 0.9577 - val_acc: 0.6881 - val_auroc: 0.8402\n",
      "\n",
      "Epoch 00023: val_auroc improved from 0.83969 to 0.84016, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.7637 - acc: 0.7269 - auroc: 0.8754 - val_loss: 0.9569 - val_acc: 0.6925 - val_auroc: 0.8353\n",
      "\n",
      "Epoch 00024: val_auroc did not improve from 0.84016\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.7470 - acc: 0.7347 - auroc: 0.8795 - val_loss: 0.9996 - val_acc: 0.6744 - val_auroc: 0.8083\n",
      "\n",
      "Epoch 00025: val_auroc did not improve from 0.84016\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.7393 - acc: 0.7322 - auroc: 0.8848 - val_loss: 1.0805 - val_acc: 0.7031 - val_auroc: 0.8344\n",
      "\n",
      "Epoch 00026: val_auroc did not improve from 0.84016\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.7332 - acc: 0.7438 - auroc: 0.8844 - val_loss: 0.9150 - val_acc: 0.6956 - val_auroc: 0.8650\n",
      "\n",
      "Epoch 00027: val_auroc improved from 0.84016 to 0.86500, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.7461 - acc: 0.7244 - auroc: 0.8853 - val_loss: 1.0742 - val_acc: 0.6887 - val_auroc: 0.8348\n",
      "\n",
      "Epoch 00028: val_auroc did not improve from 0.86500\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.6789 - acc: 0.7622 - auroc: 0.9067 - val_loss: 0.8834 - val_acc: 0.7137 - val_auroc: 0.8614\n",
      "\n",
      "Epoch 00029: val_auroc did not improve from 0.86500\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.7089 - acc: 0.7541 - auroc: 0.8945 - val_loss: 0.9673 - val_acc: 0.7144 - val_auroc: 0.8592\n",
      "\n",
      "Epoch 00030: val_auroc did not improve from 0.86500\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.6900 - acc: 0.7669 - auroc: 0.9027 - val_loss: 0.9609 - val_acc: 0.7219 - val_auroc: 0.8508\n",
      "\n",
      "Epoch 00031: val_auroc did not improve from 0.86500\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.6927 - acc: 0.7547 - auroc: 0.9030 - val_loss: 0.9397 - val_acc: 0.7056 - val_auroc: 0.8403\n",
      "\n",
      "Epoch 00032: val_auroc did not improve from 0.86500\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.7203 - acc: 0.7422 - auroc: 0.8900 - val_loss: 0.8788 - val_acc: 0.6900 - val_auroc: 0.8545\n",
      "\n",
      "Epoch 00033: val_auroc did not improve from 0.86500\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.6947 - acc: 0.7547 - auroc: 0.9043 - val_loss: 0.9033 - val_acc: 0.7013 - val_auroc: 0.8564\n",
      "\n",
      "Epoch 00034: val_auroc did not improve from 0.86500\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.6630 - acc: 0.7741 - auroc: 0.9109 - val_loss: 0.8771 - val_acc: 0.7031 - val_auroc: 0.8505\n",
      "\n",
      "Epoch 00035: val_auroc did not improve from 0.86500\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.6861 - acc: 0.7644 - auroc: 0.9039 - val_loss: 0.8385 - val_acc: 0.7175 - val_auroc: 0.8670\n",
      "\n",
      "Epoch 00036: val_auroc improved from 0.86500 to 0.86703, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.6852 - acc: 0.7637 - auroc: 0.9058 - val_loss: 0.8697 - val_acc: 0.7137 - val_auroc: 0.8506\n",
      "\n",
      "Epoch 00037: val_auroc did not improve from 0.86703\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.6463 - acc: 0.7797 - auroc: 0.9163 - val_loss: 0.8545 - val_acc: 0.6831 - val_auroc: 0.8534\n",
      "\n",
      "Epoch 00038: val_auroc did not improve from 0.86703\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.6488 - acc: 0.7759 - auroc: 0.9177 - val_loss: 0.9051 - val_acc: 0.6900 - val_auroc: 0.8402\n",
      "\n",
      "Epoch 00039: val_auroc did not improve from 0.86703\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.6322 - acc: 0.7956 - auroc: 0.9169 - val_loss: 0.8487 - val_acc: 0.7181 - val_auroc: 0.8711\n",
      "\n",
      "Epoch 00040: val_auroc improved from 0.86703 to 0.87109, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.6183 - acc: 0.7969 - auroc: 0.9222 - val_loss: 1.0309 - val_acc: 0.7000 - val_auroc: 0.8419\n",
      "\n",
      "Epoch 00041: val_auroc did not improve from 0.87109\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.6335 - acc: 0.7837 - auroc: 0.9109 - val_loss: 0.8811 - val_acc: 0.7156 - val_auroc: 0.8502\n",
      "\n",
      "Epoch 00042: val_auroc did not improve from 0.87109\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.6249 - acc: 0.7863 - auroc: 0.9173 - val_loss: 0.8321 - val_acc: 0.6913 - val_auroc: 0.8759\n",
      "\n",
      "Epoch 00043: val_auroc improved from 0.87109 to 0.87594, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.6205 - acc: 0.7953 - auroc: 0.9227 - val_loss: 0.9278 - val_acc: 0.6875 - val_auroc: 0.8612\n",
      "\n",
      "Epoch 00044: val_auroc did not improve from 0.87594\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.5930 - acc: 0.8066 - auroc: 0.9292 - val_loss: 0.8759 - val_acc: 0.7269 - val_auroc: 0.8600\n",
      "\n",
      "Epoch 00045: val_auroc did not improve from 0.87594\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.6086 - acc: 0.7988 - auroc: 0.9234 - val_loss: 0.9261 - val_acc: 0.7087 - val_auroc: 0.8603\n",
      "\n",
      "Epoch 00046: val_auroc did not improve from 0.87594\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.6024 - acc: 0.8106 - auroc: 0.9313 - val_loss: 0.9260 - val_acc: 0.6819 - val_auroc: 0.8488\n",
      "\n",
      "Epoch 00047: val_auroc did not improve from 0.87594\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.5929 - acc: 0.8091 - auroc: 0.9288 - val_loss: 0.7929 - val_acc: 0.7188 - val_auroc: 0.8803\n",
      "\n",
      "Epoch 00048: val_auroc improved from 0.87594 to 0.88031, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.6199 - acc: 0.8000 - auroc: 0.9255 - val_loss: 0.8254 - val_acc: 0.7081 - val_auroc: 0.8720\n",
      "\n",
      "Epoch 00049: val_auroc did not improve from 0.88031\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.6079 - acc: 0.8053 - auroc: 0.9286 - val_loss: 0.9115 - val_acc: 0.6806 - val_auroc: 0.8519\n",
      "\n",
      "Epoch 00050: val_auroc did not improve from 0.88031\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 0.5720 - acc: 0.8225 - auroc: 0.9377 - val_loss: 0.8461 - val_acc: 0.7056 - val_auroc: 0.8680\n",
      "\n",
      "Epoch 00051: val_auroc did not improve from 0.88031\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.5988 - acc: 0.8103 - auroc: 0.9297 - val_loss: 0.8591 - val_acc: 0.7006 - val_auroc: 0.8633\n",
      "\n",
      "Epoch 00052: val_auroc did not improve from 0.88031\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.5687 - acc: 0.8100 - auroc: 0.9373 - val_loss: 0.8445 - val_acc: 0.7087 - val_auroc: 0.8664\n",
      "\n",
      "Epoch 00053: val_auroc did not improve from 0.88031\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.5864 - acc: 0.8109 - auroc: 0.9321 - val_loss: 0.8664 - val_acc: 0.7137 - val_auroc: 0.8731\n",
      "\n",
      "Epoch 00054: val_auroc did not improve from 0.88031\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.5743 - acc: 0.8194 - auroc: 0.9376 - val_loss: 1.0583 - val_acc: 0.7319 - val_auroc: 0.8722\n",
      "\n",
      "Epoch 00055: val_auroc did not improve from 0.88031\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.5737 - acc: 0.8231 - auroc: 0.9385 - val_loss: 0.9574 - val_acc: 0.7000 - val_auroc: 0.8473\n",
      "\n",
      "Epoch 00056: val_auroc did not improve from 0.88031\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.5564 - acc: 0.8281 - auroc: 0.9386 - val_loss: 0.8674 - val_acc: 0.7244 - val_auroc: 0.8680\n",
      "\n",
      "Epoch 00057: val_auroc did not improve from 0.88031\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.5430 - acc: 0.8303 - auroc: 0.9422 - val_loss: 0.9097 - val_acc: 0.7319 - val_auroc: 0.8609\n",
      "\n",
      "Epoch 00058: val_auroc did not improve from 0.88031\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.5482 - acc: 0.8184 - auroc: 0.9378 - val_loss: 0.8776 - val_acc: 0.7169 - val_auroc: 0.8747\n",
      "\n",
      "Epoch 00059: val_auroc did not improve from 0.88031\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.5427 - acc: 0.8269 - auroc: 0.9420 - val_loss: 0.9142 - val_acc: 0.6956 - val_auroc: 0.8656\n",
      "\n",
      "Epoch 00060: val_auroc did not improve from 0.88031\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.5139 - acc: 0.8378 - auroc: 0.9509 - val_loss: 0.8493 - val_acc: 0.7212 - val_auroc: 0.8773\n",
      "\n",
      "Epoch 00061: val_auroc did not improve from 0.88031\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4881 - acc: 0.8450 - auroc: 0.9533 - val_loss: 0.8998 - val_acc: 0.7006 - val_auroc: 0.8653\n",
      "\n",
      "Epoch 00062: val_auroc did not improve from 0.88031\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.4946 - acc: 0.8500 - auroc: 0.9562 - val_loss: 0.9318 - val_acc: 0.7025 - val_auroc: 0.8748\n",
      "\n",
      "Epoch 00063: val_auroc did not improve from 0.88031\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4702 - acc: 0.8613 - auroc: 0.9582 - val_loss: 1.0155 - val_acc: 0.7144 - val_auroc: 0.8706\n",
      "\n",
      "Epoch 00064: val_auroc did not improve from 0.88031\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.4687 - acc: 0.8578 - auroc: 0.9578 - val_loss: 1.0428 - val_acc: 0.7087 - val_auroc: 0.8644\n",
      "\n",
      "Epoch 00065: val_auroc did not improve from 0.88031\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4570 - acc: 0.8625 - auroc: 0.9625 - val_loss: 0.9312 - val_acc: 0.7212 - val_auroc: 0.8620\n",
      "\n",
      "Epoch 00066: val_auroc did not improve from 0.88031\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4878 - acc: 0.8600 - auroc: 0.9548 - val_loss: 0.9881 - val_acc: 0.7119 - val_auroc: 0.8761\n",
      "\n",
      "Epoch 00067: val_auroc did not improve from 0.88031\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4792 - acc: 0.8634 - auroc: 0.9564 - val_loss: 0.8947 - val_acc: 0.7056 - val_auroc: 0.8842\n",
      "\n",
      "Epoch 00068: val_auroc improved from 0.88031 to 0.88422, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4660 - acc: 0.8666 - auroc: 0.9617 - val_loss: 0.9481 - val_acc: 0.6987 - val_auroc: 0.8556\n",
      "\n",
      "Epoch 00069: val_auroc did not improve from 0.88422\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.4927 - acc: 0.8488 - auroc: 0.9548 - val_loss: 0.8616 - val_acc: 0.7169 - val_auroc: 0.8730\n",
      "\n",
      "Epoch 00070: val_auroc did not improve from 0.88422\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4523 - acc: 0.8722 - auroc: 0.9628 - val_loss: 0.8997 - val_acc: 0.7050 - val_auroc: 0.8686\n",
      "\n",
      "Epoch 00071: val_auroc did not improve from 0.88422\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.4753 - acc: 0.8622 - auroc: 0.9587 - val_loss: 0.8816 - val_acc: 0.7200 - val_auroc: 0.8762\n",
      "\n",
      "Epoch 00072: val_auroc did not improve from 0.88422\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4598 - acc: 0.8644 - auroc: 0.9613 - val_loss: 0.8927 - val_acc: 0.7294 - val_auroc: 0.8767\n",
      "\n",
      "Epoch 00073: val_auroc did not improve from 0.88422\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4373 - acc: 0.8756 - auroc: 0.9645 - val_loss: 0.8791 - val_acc: 0.7194 - val_auroc: 0.8784\n",
      "\n",
      "Epoch 00074: val_auroc did not improve from 0.88422\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4343 - acc: 0.8706 - auroc: 0.9644 - val_loss: 0.8424 - val_acc: 0.7069 - val_auroc: 0.8753\n",
      "\n",
      "Epoch 00075: val_auroc did not improve from 0.88422\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4471 - acc: 0.8725 - auroc: 0.9626 - val_loss: 0.9485 - val_acc: 0.7000 - val_auroc: 0.8606\n",
      "\n",
      "Epoch 00076: val_auroc did not improve from 0.88422\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 0.4369 - acc: 0.8716 - auroc: 0.9659 - val_loss: 0.9146 - val_acc: 0.7150 - val_auroc: 0.8738\n",
      "\n",
      "Epoch 00077: val_auroc did not improve from 0.88422\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4203 - acc: 0.8741 - auroc: 0.9672 - val_loss: 0.8869 - val_acc: 0.7069 - val_auroc: 0.8697\n",
      "\n",
      "Epoch 00078: val_auroc did not improve from 0.88422\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 0.4458 - acc: 0.8669 - auroc: 0.9609 - val_loss: 0.8743 - val_acc: 0.7169 - val_auroc: 0.8817\n",
      "\n",
      "Epoch 00079: val_auroc did not improve from 0.88422\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4219 - acc: 0.8741 - auroc: 0.9667 - val_loss: 0.8901 - val_acc: 0.7188 - val_auroc: 0.8672\n",
      "\n",
      "Epoch 00080: val_auroc did not improve from 0.88422\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4305 - acc: 0.8791 - auroc: 0.9660 - val_loss: 0.8445 - val_acc: 0.7131 - val_auroc: 0.8795\n",
      "\n",
      "Epoch 00081: val_auroc did not improve from 0.88422\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.4180 - acc: 0.8797 - auroc: 0.9681 - val_loss: 0.9332 - val_acc: 0.7181 - val_auroc: 0.8667\n",
      "\n",
      "Epoch 00082: val_auroc did not improve from 0.88422\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 0.4252 - acc: 0.8822 - auroc: 0.9665 - val_loss: 0.9394 - val_acc: 0.7075 - val_auroc: 0.8786\n",
      "\n",
      "Epoch 00083: val_auroc did not improve from 0.88422\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4202 - acc: 0.8744 - auroc: 0.9662 - val_loss: 0.8288 - val_acc: 0.7319 - val_auroc: 0.8797\n",
      "\n",
      "Epoch 00084: val_auroc did not improve from 0.88422\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4172 - acc: 0.8862 - auroc: 0.9677 - val_loss: 0.9082 - val_acc: 0.7212 - val_auroc: 0.8772\n",
      "\n",
      "Epoch 00085: val_auroc did not improve from 0.88422\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 0.4277 - acc: 0.8862 - auroc: 0.9646 - val_loss: 0.9293 - val_acc: 0.7075 - val_auroc: 0.8731\n",
      "\n",
      "Epoch 00086: val_auroc did not improve from 0.88422\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 0.4506 - acc: 0.8747 - auroc: 0.9621 - val_loss: 0.9523 - val_acc: 0.7169 - val_auroc: 0.8741\n",
      "\n",
      "Epoch 00087: val_auroc did not improve from 0.88422\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.3914 - acc: 0.8881 - auroc: 0.9721 - val_loss: 0.9188 - val_acc: 0.7025 - val_auroc: 0.8759\n",
      "\n",
      "Epoch 00088: val_auroc did not improve from 0.88422\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4309 - acc: 0.8753 - auroc: 0.9662 - val_loss: 0.8616 - val_acc: 0.7206 - val_auroc: 0.8889\n",
      "\n",
      "Epoch 00089: val_auroc improved from 0.88422 to 0.88891, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 0.4334 - acc: 0.8722 - auroc: 0.9643 - val_loss: 0.9378 - val_acc: 0.7125 - val_auroc: 0.8769\n",
      "\n",
      "Epoch 00090: val_auroc did not improve from 0.88891\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4154 - acc: 0.8766 - auroc: 0.9666 - val_loss: 0.8687 - val_acc: 0.7144 - val_auroc: 0.8831\n",
      "\n",
      "Epoch 00091: val_auroc did not improve from 0.88891\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4147 - acc: 0.8806 - auroc: 0.9680 - val_loss: 1.0708 - val_acc: 0.7106 - val_auroc: 0.8652\n",
      "\n",
      "Epoch 00092: val_auroc did not improve from 0.88891\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4036 - acc: 0.8831 - auroc: 0.9708 - val_loss: 0.8812 - val_acc: 0.7256 - val_auroc: 0.8828\n",
      "\n",
      "Epoch 00093: val_auroc did not improve from 0.88891\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4235 - acc: 0.8759 - auroc: 0.9680 - val_loss: 0.9912 - val_acc: 0.7056 - val_auroc: 0.8744\n",
      "\n",
      "Epoch 00094: val_auroc did not improve from 0.88891\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.4617 - acc: 0.8669 - auroc: 0.9592 - val_loss: 0.8776 - val_acc: 0.7231 - val_auroc: 0.8800\n",
      "\n",
      "Epoch 00095: val_auroc did not improve from 0.88891\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 88s 440ms/step - loss: 0.4538 - acc: 0.8663 - auroc: 0.9587 - val_loss: 0.8944 - val_acc: 0.7181 - val_auroc: 0.8897\n",
      "\n",
      "Epoch 00096: val_auroc improved from 0.88891 to 0.88969, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 0.4264 - acc: 0.8725 - auroc: 0.9666 - val_loss: 0.9479 - val_acc: 0.6987 - val_auroc: 0.8609\n",
      "\n",
      "Epoch 00097: val_auroc did not improve from 0.88969\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4389 - acc: 0.8684 - auroc: 0.9614 - val_loss: 0.9413 - val_acc: 0.7094 - val_auroc: 0.8708\n",
      "\n",
      "Epoch 00098: val_auroc did not improve from 0.88969\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4486 - acc: 0.8747 - auroc: 0.9619 - val_loss: 0.9358 - val_acc: 0.7087 - val_auroc: 0.8728\n",
      "\n",
      "Epoch 00099: val_auroc did not improve from 0.88969\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 0.4402 - acc: 0.8784 - auroc: 0.9641 - val_loss: 0.8364 - val_acc: 0.7350 - val_auroc: 0.8914\n",
      "\n",
      "Epoch 00100: val_auroc improved from 0.88969 to 0.89141, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f1b6e87b8>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=True,\n",
    "                    validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=100, verbose=1,\n",
    "                    workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "514oUb8Kg78B"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"drive/My Drive/Face_recognition/vgg_face_cosine_focal.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4y9lhv6yeu4Y"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc',auroc], optimizer=Adam(0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LBJ7V4VIeuRd",
    "outputId": "87527c21-4336-4602-d49b-a7065a3a0a15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166it [24:50,  6.76s/it]\n"
     ]
    }
   ],
   "source": [
    "test_path = \"drive/My Drive/Face_recognition/test/\"\n",
    "def chunker(seq, size=32):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "submission = pd.read_csv('drive/My Drive/Face_recognition/sample_submission.csv')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in tqdm(chunker(submission.img_pair.values)):\n",
    "    X1 = [x.split(\"-\")[0] for x in batch]\n",
    "    X1 = np.array([read_img(test_path + x) for x in X1])\n",
    "\n",
    "    X2 = [x.split(\"-\")[1] for x in batch]\n",
    "    X2 = np.array([read_img(test_path + x) for x in X2])\n",
    "\n",
    "    pred = model.predict([X1, X2]).ravel().tolist()\n",
    "    predictions += pred\n",
    "\n",
    "submission['is_related'] = predictions\n",
    "\n",
    "submission.to_csv(\"drive/My Drive/Face_recognition/cosine_focal_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fYL1NU1DRQuD"
   },
   "source": [
    "### Test Score : 0.865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rx7ofFjoRVHQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UqkoKXTZutc5"
   },
   "source": [
    "### 6. Passing the metrics through dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T128KBOsuozQ"
   },
   "source": [
    "### Monitoring Accuracy instead of ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAFtvEafW6mm"
   },
   "outputs": [],
   "source": [
    "def cosine_focal_model2():\n",
    "    #change 2\n",
    "    input_1 = Input(shape=(197, 197, 3))\n",
    "    input_2 = Input(shape=(197, 197, 3))\n",
    "\n",
    "    base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "\n",
    "    x1 = GlobalMaxPool2D()(x1)\n",
    "    x2 = GlobalMaxPool2D()(x2)\n",
    "\n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "    x3 = Dense(100, activation = 'relu')(x3)\n",
    "\n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    x4 = Dense(100, activation = 'relu')(x4)\n",
    "    \n",
    "    \n",
    "    #https://stackoverflow.com/a/51003359/10650182\n",
    "    x5 = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([x1, x2])\n",
    "    x5 = Dense(100, activation = 'relu')(x5)\n",
    "    \n",
    "    x = Concatenate(axis=-1)([x5,x4, x3])\n",
    "\n",
    "    x = Dense(100, activation=\"relu\")(x)\n",
    "    x = Dropout(0.05)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc',auroc], optimizer=Adam(0.00001))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_Vf5FujoW6e0",
    "outputId": "c6cd793c-ff11-47a9-e89c-bdac01f6adf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
      "94699520/94694792 [==============================] - 4s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0801 01:26:19.410187 140346887079808 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0801 01:26:19.460252 140346887079808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0801 01:26:19.469247 140346887079808 deprecation.py:323] From <ipython-input-44-5d124dd4d6b8>:3: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0801 01:26:19.509076 140346887079808 deprecation.py:323] From <ipython-input-3-bc412d992b42>:14: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vggface_resnet50 (Model)        multiple             23561152    input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (None, 2048)         0           vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 2048)         0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_max_pooling2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 2048)         0           global_max_pooling2d_2[0][0]     \n",
      "                                                                 global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 2048)         0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 2048)         0           multiply_2[0][0]                 \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 2048)         0           subtract_1[0][0]                 \n",
      "                                                                 subtract_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          200         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          204900      subtract_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          204900      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 300)          0           dense_3[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          30100       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            101         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,001,353\n",
      "Trainable params: 23,948,233\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "file_path = \"drive/My Drive/Face_recognition/vgg_face_cosine_focal2\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.1, patience=10, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "model = cosine_focal_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3VpVsN8pW5xy",
    "outputId": "61a275e2-df26-4b34-bed4-e1c820d993fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "200/200 [==============================] - 621s 3s/step - loss: 13.1002 - acc: 0.5353 - auroc: 0.5678 - val_loss: 11.5723 - val_acc: 0.5238 - val_auroc: 0.5599\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.52375, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 305s 2s/step - loss: 5.4389 - acc: 0.5816 - auroc: 0.6530 - val_loss: 6.3874 - val_acc: 0.5506 - val_auroc: 0.6009\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.52375 to 0.55063, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 202s 1s/step - loss: 3.2549 - acc: 0.5778 - auroc: 0.6445 - val_loss: 4.3567 - val_acc: 0.5487 - val_auroc: 0.5866\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.55063\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 191s 953ms/step - loss: 2.0147 - acc: 0.5891 - auroc: 0.6484 - val_loss: 2.5833 - val_acc: 0.5563 - val_auroc: 0.6044\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.55063 to 0.55625, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 191s 953ms/step - loss: 1.5568 - acc: 0.5853 - auroc: 0.6647 - val_loss: 1.8283 - val_acc: 0.5644 - val_auroc: 0.6292\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.55625 to 0.56437, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 191s 954ms/step - loss: 1.3103 - acc: 0.5884 - auroc: 0.6850 - val_loss: 1.5993 - val_acc: 0.5725 - val_auroc: 0.6519\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.56437 to 0.57250, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 190s 952ms/step - loss: 1.1954 - acc: 0.5975 - auroc: 0.6938 - val_loss: 1.3337 - val_acc: 0.5494 - val_auroc: 0.6456\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.57250\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 190s 952ms/step - loss: 1.1275 - acc: 0.5913 - auroc: 0.7110 - val_loss: 1.1876 - val_acc: 0.5938 - val_auroc: 0.6817\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.57250 to 0.59375, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 191s 954ms/step - loss: 1.0627 - acc: 0.6003 - auroc: 0.7398 - val_loss: 1.1671 - val_acc: 0.5881 - val_auroc: 0.6967\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.59375\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 191s 955ms/step - loss: 1.0544 - acc: 0.6053 - auroc: 0.7347 - val_loss: 1.1389 - val_acc: 0.5837 - val_auroc: 0.7150\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.59375\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 191s 957ms/step - loss: 1.0225 - acc: 0.5994 - auroc: 0.7512 - val_loss: 1.0955 - val_acc: 0.5819 - val_auroc: 0.7220\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.59375\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 191s 957ms/step - loss: 0.9883 - acc: 0.6047 - auroc: 0.7598 - val_loss: 1.0452 - val_acc: 0.5887 - val_auroc: 0.7438\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.59375\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.9287 - acc: 0.6297 - auroc: 0.7934 - val_loss: 1.0441 - val_acc: 0.6075 - val_auroc: 0.7406\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.59375 to 0.60750, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.9204 - acc: 0.6294 - auroc: 0.7987 - val_loss: 1.0641 - val_acc: 0.6069 - val_auroc: 0.7427\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.60750\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 192s 961ms/step - loss: 0.9437 - acc: 0.6219 - auroc: 0.7916 - val_loss: 1.0063 - val_acc: 0.6069 - val_auroc: 0.7706\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.60750\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.9029 - acc: 0.6466 - auroc: 0.8083 - val_loss: 1.0480 - val_acc: 0.5869 - val_auroc: 0.7481\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.60750\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.9001 - acc: 0.6269 - auroc: 0.8080 - val_loss: 0.9892 - val_acc: 0.5813 - val_auroc: 0.7772\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.60750\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.8682 - acc: 0.6497 - auroc: 0.8282 - val_loss: 0.9705 - val_acc: 0.6444 - val_auroc: 0.7861\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.60750 to 0.64438, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.8425 - acc: 0.6659 - auroc: 0.8422 - val_loss: 0.9628 - val_acc: 0.6238 - val_auroc: 0.7845\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.64438\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.8415 - acc: 0.6725 - auroc: 0.8395 - val_loss: 0.9447 - val_acc: 0.6375 - val_auroc: 0.7895\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.64438\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.8258 - acc: 0.6738 - auroc: 0.8420 - val_loss: 1.0056 - val_acc: 0.6288 - val_auroc: 0.7606\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.64438\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.8545 - acc: 0.6594 - auroc: 0.8375 - val_loss: 0.9212 - val_acc: 0.6162 - val_auroc: 0.8064\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.64438\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 192s 962ms/step - loss: 0.8207 - acc: 0.6825 - auroc: 0.8502 - val_loss: 0.8709 - val_acc: 0.6375 - val_auroc: 0.8275\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.64438\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.8201 - acc: 0.6788 - auroc: 0.8491 - val_loss: 0.9021 - val_acc: 0.6362 - val_auroc: 0.8192\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.64438\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 191s 954ms/step - loss: 0.8073 - acc: 0.6837 - auroc: 0.8530 - val_loss: 0.9691 - val_acc: 0.6331 - val_auroc: 0.7870\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.64438\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 191s 953ms/step - loss: 0.7943 - acc: 0.6950 - auroc: 0.8598 - val_loss: 0.9554 - val_acc: 0.6375 - val_auroc: 0.7961\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.64438\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 191s 954ms/step - loss: 0.7534 - acc: 0.7150 - auroc: 0.8792 - val_loss: 0.9343 - val_acc: 0.6569 - val_auroc: 0.8127\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.64438 to 0.65687, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 191s 957ms/step - loss: 0.7719 - acc: 0.7131 - auroc: 0.8720 - val_loss: 0.9265 - val_acc: 0.6581 - val_auroc: 0.8008\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.65687 to 0.65812, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.7587 - acc: 0.7150 - auroc: 0.8748 - val_loss: 0.9197 - val_acc: 0.6469 - val_auroc: 0.8241\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.65812\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.7125 - acc: 0.7413 - auroc: 0.8904 - val_loss: 0.9072 - val_acc: 0.6681 - val_auroc: 0.8191\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.65812 to 0.66812, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 191s 957ms/step - loss: 0.7525 - acc: 0.7306 - auroc: 0.8770 - val_loss: 0.8602 - val_acc: 0.6775 - val_auroc: 0.8402\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.66812 to 0.67750, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.7489 - acc: 0.7256 - auroc: 0.8796 - val_loss: 0.8791 - val_acc: 0.6794 - val_auroc: 0.8278\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.67750 to 0.67937, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.7446 - acc: 0.7241 - auroc: 0.8784 - val_loss: 0.8530 - val_acc: 0.6706 - val_auroc: 0.8392\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.67937\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 192s 961ms/step - loss: 0.7220 - acc: 0.7328 - auroc: 0.8904 - val_loss: 0.8638 - val_acc: 0.6619 - val_auroc: 0.8398\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.67937\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.7108 - acc: 0.7519 - auroc: 0.8928 - val_loss: 0.9258 - val_acc: 0.6281 - val_auroc: 0.8216\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.67937\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.7008 - acc: 0.7538 - auroc: 0.8972 - val_loss: 0.8398 - val_acc: 0.6944 - val_auroc: 0.8598\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.67937 to 0.69437, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 192s 961ms/step - loss: 0.6900 - acc: 0.7581 - auroc: 0.9009 - val_loss: 0.8615 - val_acc: 0.6956 - val_auroc: 0.8433\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.69437 to 0.69563, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 192s 961ms/step - loss: 0.6780 - acc: 0.7528 - auroc: 0.9041 - val_loss: 0.8633 - val_acc: 0.6806 - val_auroc: 0.8391\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.69563\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 192s 961ms/step - loss: 0.6900 - acc: 0.7594 - auroc: 0.8982 - val_loss: 0.8597 - val_acc: 0.6950 - val_auroc: 0.8467\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.69563\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 192s 961ms/step - loss: 0.6650 - acc: 0.7591 - auroc: 0.9070 - val_loss: 0.8159 - val_acc: 0.6975 - val_auroc: 0.8603\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.69563 to 0.69750, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.6979 - acc: 0.7541 - auroc: 0.8989 - val_loss: 0.8492 - val_acc: 0.6831 - val_auroc: 0.8414\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.69750\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.6757 - acc: 0.7616 - auroc: 0.9038 - val_loss: 0.8234 - val_acc: 0.7013 - val_auroc: 0.8611\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.69750 to 0.70125, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.7088 - acc: 0.7503 - auroc: 0.8958 - val_loss: 0.9257 - val_acc: 0.6737 - val_auroc: 0.8219\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.70125\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.6419 - acc: 0.7694 - auroc: 0.9168 - val_loss: 0.8689 - val_acc: 0.7212 - val_auroc: 0.8495\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.70125 to 0.72125, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.6620 - acc: 0.7716 - auroc: 0.9106 - val_loss: 0.7788 - val_acc: 0.7300 - val_auroc: 0.8731\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.72125 to 0.73000, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 192s 961ms/step - loss: 0.6391 - acc: 0.7819 - auroc: 0.9144 - val_loss: 0.9142 - val_acc: 0.6731 - val_auroc: 0.8272\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.73000\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 191s 956ms/step - loss: 0.6373 - acc: 0.7856 - auroc: 0.9170 - val_loss: 0.8170 - val_acc: 0.7087 - val_auroc: 0.8672\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.73000\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 191s 956ms/step - loss: 0.6482 - acc: 0.7747 - auroc: 0.9108 - val_loss: 0.8145 - val_acc: 0.7006 - val_auroc: 0.8581\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.73000\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 191s 957ms/step - loss: 0.6248 - acc: 0.7984 - auroc: 0.9252 - val_loss: 0.8537 - val_acc: 0.6956 - val_auroc: 0.8514\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.73000\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.6260 - acc: 0.7869 - auroc: 0.9205 - val_loss: 0.8388 - val_acc: 0.6950 - val_auroc: 0.8639\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.73000\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.5874 - acc: 0.8091 - auroc: 0.9340 - val_loss: 0.8690 - val_acc: 0.7056 - val_auroc: 0.8459\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.73000\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.6317 - acc: 0.7884 - auroc: 0.9212 - val_loss: 0.9198 - val_acc: 0.6931 - val_auroc: 0.8383\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.73000\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.6151 - acc: 0.7962 - auroc: 0.9225 - val_loss: 0.8576 - val_acc: 0.6869 - val_auroc: 0.8541\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.73000\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.6128 - acc: 0.7975 - auroc: 0.9221 - val_loss: 0.8882 - val_acc: 0.6963 - val_auroc: 0.8488\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.73000\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.5640 - acc: 0.8169 - auroc: 0.9383 - val_loss: 0.7910 - val_acc: 0.7406 - val_auroc: 0.8834\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.73000 to 0.74062, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal2\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.5954 - acc: 0.8097 - auroc: 0.9303 - val_loss: 0.8968 - val_acc: 0.6944 - val_auroc: 0.8397\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.74062\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.5730 - acc: 0.8191 - auroc: 0.9345 - val_loss: 0.8840 - val_acc: 0.7150 - val_auroc: 0.8500\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.74062\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.5769 - acc: 0.8097 - auroc: 0.9346 - val_loss: 0.8820 - val_acc: 0.6881 - val_auroc: 0.8620\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.74062\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.5793 - acc: 0.8078 - auroc: 0.9331 - val_loss: 0.8691 - val_acc: 0.7019 - val_auroc: 0.8552\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.74062\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 191s 957ms/step - loss: 0.5431 - acc: 0.8341 - auroc: 0.9442 - val_loss: 0.8513 - val_acc: 0.6987 - val_auroc: 0.8689\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.74062\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.5612 - acc: 0.8175 - auroc: 0.9409 - val_loss: 0.8813 - val_acc: 0.7144 - val_auroc: 0.8636\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.74062\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.5731 - acc: 0.8128 - auroc: 0.9342 - val_loss: 0.8609 - val_acc: 0.7250 - val_auroc: 0.8562\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.74062\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.5700 - acc: 0.8144 - auroc: 0.9365 - val_loss: 0.8283 - val_acc: 0.7087 - val_auroc: 0.8712\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.74062\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.5535 - acc: 0.8178 - auroc: 0.9377 - val_loss: 0.8589 - val_acc: 0.6981 - val_auroc: 0.8648\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.74062\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 191s 956ms/step - loss: 0.5477 - acc: 0.8303 - auroc: 0.9416 - val_loss: 0.8510 - val_acc: 0.7369 - val_auroc: 0.8688\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.74062\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 191s 957ms/step - loss: 0.5340 - acc: 0.8334 - auroc: 0.9450 - val_loss: 0.8634 - val_acc: 0.7212 - val_auroc: 0.8623\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.74062\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 191s 956ms/step - loss: 0.5354 - acc: 0.8366 - auroc: 0.9424 - val_loss: 0.8429 - val_acc: 0.7250 - val_auroc: 0.8673\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.74062\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 191s 957ms/step - loss: 0.4981 - acc: 0.8450 - auroc: 0.9515 - val_loss: 0.8292 - val_acc: 0.7281 - val_auroc: 0.8702\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.74062\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 191s 956ms/step - loss: 0.5288 - acc: 0.8378 - auroc: 0.9461 - val_loss: 0.9288 - val_acc: 0.6987 - val_auroc: 0.8500\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.74062\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.4993 - acc: 0.8425 - auroc: 0.9510 - val_loss: 0.8632 - val_acc: 0.7013 - val_auroc: 0.8638\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.74062\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.4858 - acc: 0.8484 - auroc: 0.9555 - val_loss: 0.8932 - val_acc: 0.7063 - val_auroc: 0.8603\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.74062\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.4939 - acc: 0.8406 - auroc: 0.9514 - val_loss: 0.8866 - val_acc: 0.7100 - val_auroc: 0.8736\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.74062\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.5183 - acc: 0.8466 - auroc: 0.9462 - val_loss: 0.8745 - val_acc: 0.7206 - val_auroc: 0.8653\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.74062\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.4906 - acc: 0.8416 - auroc: 0.9550 - val_loss: 0.8648 - val_acc: 0.7194 - val_auroc: 0.8603\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.74062\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.4698 - acc: 0.8538 - auroc: 0.9559 - val_loss: 0.8636 - val_acc: 0.6981 - val_auroc: 0.8612\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.74062\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 191s 957ms/step - loss: 0.4774 - acc: 0.8609 - auroc: 0.9570 - val_loss: 0.8611 - val_acc: 0.7275 - val_auroc: 0.8689\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.74062\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.4934 - acc: 0.8534 - auroc: 0.9520 - val_loss: 0.9273 - val_acc: 0.7137 - val_auroc: 0.8567\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.74062\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 191s 957ms/step - loss: 0.4831 - acc: 0.8556 - auroc: 0.9543 - val_loss: 0.8816 - val_acc: 0.7219 - val_auroc: 0.8603\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.74062\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.4979 - acc: 0.8566 - auroc: 0.9524 - val_loss: 0.9047 - val_acc: 0.7150 - val_auroc: 0.8591\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.74062\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.4809 - acc: 0.8553 - auroc: 0.9556 - val_loss: 0.8907 - val_acc: 0.7106 - val_auroc: 0.8514\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.74062\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 191s 957ms/step - loss: 0.4717 - acc: 0.8606 - auroc: 0.9577 - val_loss: 0.8482 - val_acc: 0.7219 - val_auroc: 0.8778\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.74062\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 192s 959ms/step - loss: 0.4686 - acc: 0.8594 - auroc: 0.9544 - val_loss: 0.8125 - val_acc: 0.7312 - val_auroc: 0.8895\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.74062\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 192s 961ms/step - loss: 0.4766 - acc: 0.8538 - auroc: 0.9555 - val_loss: 0.8590 - val_acc: 0.7219 - val_auroc: 0.8627\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.74062\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 192s 961ms/step - loss: 0.4560 - acc: 0.8584 - auroc: 0.9591 - val_loss: 0.8638 - val_acc: 0.7194 - val_auroc: 0.8745\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.74062\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.4988 - acc: 0.8538 - auroc: 0.9512 - val_loss: 0.8780 - val_acc: 0.7075 - val_auroc: 0.8600\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.74062\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 192s 960ms/step - loss: 0.5100 - acc: 0.8522 - auroc: 0.9480 - val_loss: 0.8220 - val_acc: 0.7238 - val_auroc: 0.8827\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.74062\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.4687 - acc: 0.8581 - auroc: 0.9586 - val_loss: 0.8206 - val_acc: 0.7381 - val_auroc: 0.8828\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.74062\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.4567 - acc: 0.8681 - auroc: 0.9621 - val_loss: 0.8886 - val_acc: 0.7169 - val_auroc: 0.8689\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.74062\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 191s 956ms/step - loss: 0.4347 - acc: 0.8684 - auroc: 0.9678 - val_loss: 0.9263 - val_acc: 0.7063 - val_auroc: 0.8550\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.74062\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 191s 957ms/step - loss: 0.4647 - acc: 0.8616 - auroc: 0.9594 - val_loss: 0.8855 - val_acc: 0.7144 - val_auroc: 0.8698\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.74062\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 191s 956ms/step - loss: 0.4722 - acc: 0.8484 - auroc: 0.9558 - val_loss: 0.8795 - val_acc: 0.7238 - val_auroc: 0.8634\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.74062\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 192s 958ms/step - loss: 0.4807 - acc: 0.8584 - auroc: 0.9570 - val_loss: 0.8215 - val_acc: 0.7319 - val_auroc: 0.8772\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.74062\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 191s 954ms/step - loss: 0.4869 - acc: 0.8584 - auroc: 0.9557 - val_loss: 0.8941 - val_acc: 0.7125 - val_auroc: 0.8647\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.74062\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 191s 954ms/step - loss: 0.4941 - acc: 0.8475 - auroc: 0.9535 - val_loss: 0.9007 - val_acc: 0.7106 - val_auroc: 0.8748\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.74062\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 191s 955ms/step - loss: 0.4785 - acc: 0.8516 - auroc: 0.9555 - val_loss: 0.8935 - val_acc: 0.7131 - val_auroc: 0.8669\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.74062\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 191s 954ms/step - loss: 0.4541 - acc: 0.8634 - auroc: 0.9588 - val_loss: 0.8724 - val_acc: 0.7194 - val_auroc: 0.8644\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.74062\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 191s 953ms/step - loss: 0.5132 - acc: 0.8438 - auroc: 0.9490 - val_loss: 0.8936 - val_acc: 0.7175 - val_auroc: 0.8725\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.74062\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 191s 955ms/step - loss: 0.4433 - acc: 0.8703 - auroc: 0.9652 - val_loss: 0.8438 - val_acc: 0.7262 - val_auroc: 0.8739\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.74062\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 192s 962ms/step - loss: 0.4628 - acc: 0.8628 - auroc: 0.9585 - val_loss: 0.8782 - val_acc: 0.7131 - val_auroc: 0.8580\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.74062\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 192s 961ms/step - loss: 0.4621 - acc: 0.8653 - auroc: 0.9616 - val_loss: 0.8676 - val_acc: 0.7150 - val_auroc: 0.8628\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.74062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa463509080>"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=True,\n",
    "                    validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=100, verbose=1,\n",
    "                    workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1D9wm1yuoWe"
   },
   "outputs": [],
   "source": [
    "# def triplet_loss(y_true, y_pred, alpha = 0.3):    \n",
    "#     anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]    \n",
    "#     pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)    \n",
    "#     neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)    \n",
    "#     basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)    \n",
    "#     loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))       \n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ai0iJmyW5r5"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"drive/My Drive/Face_recognition/vgg_face_cosine_focal2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGLVOhNkW5lY"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc',auroc], optimizer=Adam(0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PxRBWDUvW5b1",
    "outputId": "f6832657-4d55-4783-cef1-bed8c4a8ab22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166it [54:19, 14.17s/it]\n"
     ]
    }
   ],
   "source": [
    "test_path = \"drive/My Drive/Face_recognition/test/\"\n",
    "def chunker(seq, size=32):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "submission = pd.read_csv('drive/My Drive/Face_recognition/sample_submission.csv')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in tqdm(chunker(submission.img_pair.values)):\n",
    "    X1 = [x.split(\"-\")[0] for x in batch]\n",
    "    X1 = np.array([read_img(test_path + x) for x in X1])\n",
    "\n",
    "    X2 = [x.split(\"-\")[1] for x in batch]\n",
    "    X2 = np.array([read_img(test_path + x) for x in X2])\n",
    "\n",
    "    pred = model.predict([X1, X2]).ravel().tolist()\n",
    "    predictions += pred\n",
    "\n",
    "submission['is_related'] = predictions\n",
    "\n",
    "submission.to_csv(\"drive/My Drive/Face_recognition/cosine_focal_submission2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rB28wIWHVqQF"
   },
   "source": [
    "### Test Score 0.8666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X44ag-eH9fSh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BWCsKPG_x29M"
   },
   "source": [
    "### 7. Siamese model using custom layers instead of VGGFace with 197X197X3 input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8-L5jzlDRsN"
   },
   "source": [
    "### https://github.com/hlamba28/One-Shot-Learning-with-Siamese-Networks/blob/master/Siamese%20on%20Omniglot%20Dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4JbsscSk5Ug"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sRekVlANmLjE"
   },
   "outputs": [],
   "source": [
    "def initialize_bias(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-ap7Y3Tk5YN"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_siamese_model(input_shape=(197, 197, 3)):\n",
    "    \"\"\"\n",
    "        Model architecture\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7,7), activation='relu',\n",
    "                     kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "o7VRDnI0lK6V",
    "outputId": "2f3ae8b4-4fd4-43a2-d67a-830a4b0feadf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\prabh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"siamese_model1.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_auroc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_auroc\", mode=\"max\", factor=0.1, patience=20, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "model = get_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "id": "00Nr82d8todH",
    "outputId": "91250a17-9540-4a8a-9724-684402fbbb61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-35-a8e5eda55064>:4: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", metrics=['acc',auroc], optimizer=Adam(0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "i7bovkz0BgKo",
    "outputId": "b7d03d60-48a9-457f-c028-2db240dd089f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4096)         304250176   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4096)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 304,254,273\n",
      "Trainable params: 304,254,273\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DwYfLWzAlR9b"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(gen(train, train_person_to_images_map, batch_size=16),\n",
    "                    validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=20, verbose=2,\n",
    "                    callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtK5p-mZtfQX"
   },
   "outputs": [],
   "source": [
    "### The above model takes a lot of time and runs out of memroy  so, reducing the trainable params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RCZ2KEU92tS"
   },
   "outputs": [],
   "source": [
    "### Siamese model with 160X160X3 input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJT4q1m0937y"
   },
   "outputs": [],
   "source": [
    "#from keras.preprocessing import image\n",
    "def read_img2(path):\n",
    "    #change1\n",
    "    img = image.load_img(path, target_size=(160, 160))\n",
    "    img = np.array(img).astype(np.float)\n",
    "    return img\n",
    "def gen2(list_tuples, person_to_images_map, batch_size=16):\n",
    "    ppl = list(person_to_images_map.keys())\n",
    "    while True:\n",
    "        #sample() Chooses k unique random elements from a population sequence or set\n",
    "        # Filling batch tuples with half 1 lables\n",
    "        batch_tuples = sample(list_tuples, batch_size // 2)\n",
    "        # Assigning 1 label to all the pairs given in relationships file\n",
    "        labels = [1] * len(batch_tuples)\n",
    "        # Filling half batch_tuples with 0 labels\n",
    "        while len(batch_tuples) < batch_size:\n",
    "            p1 = choice(ppl)\n",
    "            p2 = choice(ppl)\n",
    "\n",
    "            if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:\n",
    "                batch_tuples.append((p1, p2))\n",
    "                labels.append(0)\n",
    "\n",
    "        for x in batch_tuples:\n",
    "            if not len(person_to_images_map[x[0]]):\n",
    "                print(x[0])\n",
    "        \n",
    "        # Selecting a single image out of many provided for each user\n",
    "        X1 = [choice(person_to_images_map[x[0]]) for x in batch_tuples]\n",
    "        X1 = np.array([read_img2(x) for x in X1])\n",
    "        \n",
    "        # Selecting a single image out of many provided for each user\n",
    "        X2 = [choice(person_to_images_map[x[1]]) for x in batch_tuples]\n",
    "        X2 = np.array([read_img2(x) for x in X2])\n",
    "\n",
    "        yield [X1, X2], labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VgDlZ4CDDRsi"
   },
   "outputs": [],
   "source": [
    "def get_siamese_model2(input_shape=(160, 160,3)):\n",
    "    \"\"\"\n",
    "        Model architecture\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7,7), activation='relu',\n",
    "                     kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net\n",
    "\n",
    "file_path = \"siamese_model2.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_auroc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_auroc\", mode=\"max\", factor=0.1, patience=20, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "model = get_siamese_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SWU_eY8BDRsm",
    "outputId": "24c11d80-98d4-440b-e4e0-6b7338a9110e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 160, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 160, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 4096)         152206656   input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 4096)         0           sequential_3[1][0]               \n",
      "                                                                 sequential_3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            4097        lambda_3[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 152,210,753\n",
      "Trainable params: 152,210,753\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", metrics=['acc',auroc], optimizer=Adam(0.0001))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBTG8yGmDRso"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-kgSC18DRsp",
    "outputId": "21533d2a-525e-449e-f314-684d60d68bee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\prabh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 865s 9s/step - loss: 10.7282 - acc: 0.5187 - auroc: 0.5380 - val_loss: 6.7384 - val_acc: 0.5000 - val_auroc: 0.4980\n",
      "\n",
      "Epoch 00001: val_auroc improved from -inf to 0.49797, saving model to siamese_model1.h5\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 854s 9s/step - loss: 4.7585 - acc: 0.5000 - auroc: 0.5149 - val_loss: 3.3080 - val_acc: 0.5000 - val_auroc: 0.4872\n",
      "\n",
      "Epoch 00002: val_auroc did not improve from 0.49797\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 774s 8s/step - loss: 2.5574 - acc: 0.5000 - auroc: 0.5130 - val_loss: 1.9874 - val_acc: 0.5000 - val_auroc: 0.5055\n",
      "\n",
      "Epoch 00003: val_auroc improved from 0.49797 to 0.50555, saving model to siamese_model1.h5\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 777s 8s/step - loss: 1.6681 - acc: 0.5000 - auroc: 0.5066 - val_loss: 1.4157 - val_acc: 0.5000 - val_auroc: 0.5403\n",
      "\n",
      "Epoch 00004: val_auroc improved from 0.50555 to 0.54031, saving model to siamese_model1.h5\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 869s 9s/step - loss: 1.2762 - acc: 0.5000 - auroc: 0.4935 - val_loss: 1.1464 - val_acc: 0.5000 - val_auroc: 0.4764\n",
      "\n",
      "Epoch 00005: val_auroc did not improve from 0.54031\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 892s 9s/step - loss: 1.0616 - acc: 0.5000 - auroc: 0.5125 - val_loss: 0.9913 - val_acc: 0.5000 - val_auroc: 0.5016\n",
      "\n",
      "Epoch 00006: val_auroc did not improve from 0.54031\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 893s 9s/step - loss: 0.9433 - acc: 0.5000 - auroc: 0.5089 - val_loss: 0.9029 - val_acc: 0.5000 - val_auroc: 0.5081\n",
      "\n",
      "Epoch 00007: val_auroc did not improve from 0.54031\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 894s 9s/step - loss: 0.8773 - acc: 0.5000 - auroc: 0.5048 - val_loss: 0.8527 - val_acc: 0.5000 - val_auroc: 0.4981\n",
      "\n",
      "Epoch 00008: val_auroc did not improve from 0.54031\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 899s 9s/step - loss: 0.8341 - acc: 0.5000 - auroc: 0.5040 - val_loss: 0.8169 - val_acc: 0.5000 - val_auroc: 0.4973\n",
      "\n",
      "Epoch 00009: val_auroc did not improve from 0.54031\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 827s 8s/step - loss: 0.8071 - acc: 0.5000 - auroc: 0.5020 - val_loss: 0.7954 - val_acc: 0.5000 - val_auroc: 0.5156\n",
      "\n",
      "Epoch 00010: val_auroc did not improve from 0.54031\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 779s 8s/step - loss: 0.7875 - acc: 0.5000 - auroc: 0.5022 - val_loss: 0.7820 - val_acc: 0.5000 - val_auroc: 0.4972\n",
      "\n",
      "Epoch 00011: val_auroc did not improve from 0.54031\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 772s 8s/step - loss: 0.7761 - acc: 0.5000 - auroc: 0.5338 - val_loss: 0.7764 - val_acc: 0.5000 - val_auroc: 0.4894\n",
      "\n",
      "Epoch 00012: val_auroc did not improve from 0.54031\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 788s 8s/step - loss: 0.7752 - acc: 0.5000 - auroc: 0.5003 - val_loss: 0.7711 - val_acc: 0.5000 - val_auroc: 0.4958\n",
      "\n",
      "Epoch 00013: val_auroc did not improve from 0.54031\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 892s 9s/step - loss: 0.7708 - acc: 0.5000 - auroc: 0.5175 - val_loss: 0.7783 - val_acc: 0.5000 - val_auroc: 0.4942\n",
      "\n",
      "Epoch 00014: val_auroc did not improve from 0.54031\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 865s 9s/step - loss: 0.7812 - acc: 0.5000 - auroc: 0.5001 - val_loss: 0.7809 - val_acc: 0.5000 - val_auroc: 0.5144\n",
      "\n",
      "Epoch 00015: val_auroc did not improve from 0.54031\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 816s 8s/step - loss: 0.7783 - acc: 0.5000 - auroc: 0.4937 - val_loss: 0.7744 - val_acc: 0.5000 - val_auroc: 0.4927\n",
      "\n",
      "Epoch 00016: val_auroc did not improve from 0.54031\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 768s 8s/step - loss: 0.7709 - acc: 0.5000 - auroc: 0.4973 - val_loss: 0.7679 - val_acc: 0.5000 - val_auroc: 0.4942\n",
      "\n",
      "Epoch 00017: val_auroc did not improve from 0.54031\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 955s 10s/step - loss: 0.7643 - acc: 0.5000 - auroc: 0.5277 - val_loss: 0.7619 - val_acc: 0.5000 - val_auroc: 0.5028\n",
      "\n",
      "Epoch 00018: val_auroc did not improve from 0.54031\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 995s 10s/step - loss: 0.7598 - acc: 0.5000 - auroc: 0.4902 - val_loss: 0.7587 - val_acc: 0.5000 - val_auroc: 0.4933\n",
      "\n",
      "Epoch 00019: val_auroc did not improve from 0.54031\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 800s 8s/step - loss: 0.7583 - acc: 0.5000 - auroc: 0.5174 - val_loss: 0.7571 - val_acc: 0.5000 - val_auroc: 0.5077\n",
      "\n",
      "Epoch 00020: val_auroc did not improve from 0.54031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d8012f400>"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen2(train, train_person_to_images_map, batch_size=16),\n",
    "                    validation_data=gen2(val, val_person_to_images_map, batch_size=16), epochs=20, verbose=1,\n",
    "                    callbacks=callbacks_list, steps_per_epoch=100, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNeHls08DRss"
   },
   "outputs": [],
   "source": [
    "model.load_weights('siamese_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVkefbbyDRst"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", metrics=['acc',auroc], optimizer=Adam(0.0001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wXYEKU5IdAGP"
   },
   "source": [
    "#### Ignoring the above model due to low scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R0l1qMih4sP8"
   },
   "source": [
    "### 8. Using pre-trained models for feature extraction and using those features in classical ml models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "mGSTeqL8dH4l",
    "outputId": "da733cad-21f1-41c0-8df9-f077e3aae506"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 16:12:53.832464 139786712209280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0801 16:12:53.885083 139786712209280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0801 16:12:53.894682 139786712209280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0801 16:12:53.943369 139786712209280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0801 16:12:53.944971 139786712209280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0801 16:12:56.863303 139786712209280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0801 16:12:56.953384 139786712209280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0801 16:13:02.571284 139786712209280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
      "94699520/94694792 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = VGGFace(model='resnet50', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IVOxQfuUdIXz",
    "outputId": "8365eee5-0987-4074-d435-9c6752fbbc65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 197, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(read_img('drive/My Drive/Face_recognition/train/F0002/MID1/P00010_face4.jpg')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HTmpMe5QeZnq",
    "outputId": "4ab08d9c-063f-4363-f7f4-52bbde31845d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 197, 197, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(np.array(read_img('drive/My Drive/Face_recognition/train/F0002/MID1/P00010_face4.jpg')), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g9T1x-WFd9kx",
    "outputId": "9f62f037-48ec-47e8-900b-66dcdff9ae86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 2048)"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.predict(np.expand_dims(np.array(read_img('drive/My Drive/Face_recognition/train/F0002/MID1/P00010_face4.jpg')), axis=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H3TQYPsqeL5z",
    "outputId": "a0e70c81-5bb3-4ab5-dc72-b77544184587"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.predict(np.expand_dims(np.array(read_img('drive/My Drive/Face_recognition/train/F0002/MID1/P00010_face4.jpg')), axis=0)).reshape((2048)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbg4OsJ0kHH1"
   },
   "outputs": [],
   "source": [
    "### Generating training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lyDTeqWunupC"
   },
   "outputs": [],
   "source": [
    "training_set = []\n",
    "training_labels = []\n",
    "ppl = list(train_person_to_images_map.keys())\n",
    "for p1,p2 in train:\n",
    "    #print(p1)\n",
    "    img1 = choice(train_person_to_images_map[p1])\n",
    "    img2 = choice(train_person_to_images_map[p2])\n",
    "    \n",
    "    #print(base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)).shape)\n",
    "    training_set.append(np.concatenate((base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)), base_model.predict(np.expand_dims(np.array(read_img(img2)), axis=0)).reshape((2048)))))\n",
    "    training_labels.append(1)\n",
    "    \n",
    "    flag = 0\n",
    "    while(flag == 0):\n",
    "        p1 = choice(ppl)\n",
    "        p2 = choice(ppl)\n",
    "        \n",
    "        if p1 != p2 and (p1, p2) not in train and (p2, p1) not in train:\n",
    "            flag=1\n",
    "            img1 = choice(train_person_to_images_map[p1])\n",
    "            img2 = choice(train_person_to_images_map[p2])\n",
    "            #print(base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)).shape)\n",
    "            training_set.append(np.concatenate((base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)), base_model.predict(np.expand_dims(np.array(read_img(img2)), axis=0)).reshape((2048)))))\n",
    "            training_labels.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yMxnRm06z7G"
   },
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gkHAjUrX9THw",
    "outputId": "ce678053-0ed7-4b7c-afe2-f97e7f05decd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6132, 4096)"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pGQJSb149xZa",
    "outputId": "8fff1a3a-2273-4962-cf41-a68b471c1c98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6132"
      ]
     },
     "execution_count": 113,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wbra-rHE-ySX",
    "outputId": "6729783a-833c-48ec-a914-3550ba085119"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6132"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UvVb6SLu__Bt",
    "outputId": "752927cc-c62a-4520-dc48-ab6f3fb8716a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install joblib\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D_nBm04qUd-G",
    "outputId": "16d06cf1-96f5-4a89-e851-7f30148af846"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drive/My Drive/Face_recognition/X_train1']"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(training_set,\"drive/My Drive/Face_recognition/X_train1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QVK6DgcDYrvl",
    "outputId": "4e03b3ef-42c1-4a65-cf88-261b5957383a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drive/My Drive/Face_recognition/y_train1']"
      ]
     },
     "execution_count": 122,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(training_labels,\"drive/My Drive/Face_recognition/y_train1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q2atyCZOY4pW",
    "outputId": "d01f7e5c-89f4-401d-f143-e247ae53f445"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6132, 4096)"
      ]
     },
     "execution_count": 124,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4getbPHbZhdE"
   },
   "outputs": [],
   "source": [
    "val_set = []\n",
    "val_labels = []\n",
    "ppl = list(val_person_to_images_map.keys())\n",
    "for p1,p2 in val:\n",
    "    #print(p1)\n",
    "    img1 = choice(val_person_to_images_map[p1])\n",
    "    img2 = choice(val_person_to_images_map[p2])\n",
    "    \n",
    "    #print(base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)).shape)\n",
    "    val_set.append(np.concatenate((base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)), base_model.predict(np.expand_dims(np.array(read_img(img2)), axis=0)).reshape((2048)))))\n",
    "    val_labels.append(1)\n",
    "    \n",
    "    flag = 0\n",
    "    while(flag == 0):\n",
    "        p1 = choice(ppl)\n",
    "        p2 = choice(ppl)\n",
    "        \n",
    "        if p1 != p2 and (p1, p2) not in val and (p2, p1) not in val:\n",
    "            flag=1\n",
    "            img1 = choice(val_person_to_images_map[p1])\n",
    "            img2 = choice(val_person_to_images_map[p2])\n",
    "            #print(base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)).shape)\n",
    "            val_set.append(np.concatenate((base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)), base_model.predict(np.expand_dims(np.array(read_img(img2)), axis=0)).reshape((2048)))))\n",
    "            val_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ugxxMpRuecxe",
    "outputId": "8ea60ce6-8d9c-4eea-d96d-bbc68b1d9b8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drive/My Drive/Face_recognition/y_val1']"
      ]
     },
     "execution_count": 138,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(val_set,\"drive/My Drive/Face_recognition/X_val1\")\n",
    "joblib.dump(val_labels,\"drive/My Drive/Face_recognition/y_val1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yM8eNzXxePDs",
    "outputId": "8effc463-4ceb-4888-c084-6d53b508cd94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x6Ic7bCid9Rp"
   },
   "outputs": [],
   "source": [
    "val_set = np.array(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iMZpgktyeFr5",
    "outputId": "b3b9d09d-7ece-4fce-d106-0cf7a3a97a96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 4096)"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7Pe9ElumeKlo",
    "outputId": "fce18350-9155-4b50-bd46-c5e7502f8f39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 134,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TozDh0pdJQE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FcBbArHQRLxW"
   },
   "source": [
    "#### Getting base scores on a simple RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hrp_HAg1Y9gR"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "FHqzXQDOZFgP",
    "outputId": "6c8bb890-717b-47f7-e03f-bee7518fa57b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(training_set, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qc41QrKUZHvZ"
   },
   "outputs": [],
   "source": [
    "val_pred = rf.predict(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kOtb4m9wfve4"
   },
   "outputs": [],
   "source": [
    "val_prob = rf.predict_proba(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bp9pHENexal"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WEzipbeEe-IN",
    "outputId": "b9e6fd2b-2cc5-44b2-b139-20371e2af508"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6606213476990505"
      ]
     },
     "execution_count": 149,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(val_labels, val_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFYEhK9ifU9v"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "X_train = joblib.load(\"drive/My Drive/Face_recognition/X_train1\")\n",
    "y_train = joblib.load(\"drive/My Drive/Face_recognition/y_train1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2t89AQk3ELJ"
   },
   "outputs": [],
   "source": [
    "X_val = joblib.load(\"drive/My Drive/Face_recognition/X_val1\")\n",
    "y_val = joblib.load(\"drive/My Drive/Face_recognition/y_val1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkhuugx-RT4L"
   },
   "source": [
    "#### Trying out tuning of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cff0saldeO6q"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "-6oYMWD8fExI",
    "outputId": "797b982e-6e7c-4bcf-d05c-2d0bc96de06f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 88.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=-1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 4, 6, 8],\n",
       "                         'n_estimators': [10, 50, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_depth':[2,4,6,8], 'n_estimators':[10,50,100,200]}\n",
    "model = GridSearchCV(XGBClassifier(n_jobs=-1), param_grid=params,scoring='roc_auc',n_jobs=-1,cv=3, return_train_score=True, verbose=1)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "px5hVu_x1OHL",
    "outputId": "07b275c0-0038-4794-a43c-4508df4b9a5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6681436320071281"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lfsR08zE1QXm",
    "outputId": "a101b722-6663-46fa-9ceb-a03d31afad7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drive/My Drive/Face_recognition/xgb1']"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model,\"drive/My Drive/Face_recognition/xgb1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMGvdkV_1cA7"
   },
   "outputs": [],
   "source": [
    "val_proba = model.best_estimator_.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6PSImG_U3NRc",
    "outputId": "6bf9e4e9-aa43-4285-d8b6-312a77d47f5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6959459459459459"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val,val_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_Qd5zpcReHC"
   },
   "source": [
    "#### Experimenting by tripling the size of train and val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WxtNe5723R6j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4KiKp7pUPt8"
   },
   "outputs": [],
   "source": [
    "training_set = []\n",
    "training_labels = []\n",
    "ppl = list(train_person_to_images_map.keys())\n",
    "count = 0\n",
    "while(count !=3):\n",
    "    for p1,p2 in train:\n",
    "        #print(p1)\n",
    "        img1 = choice(train_person_to_images_map[p1])\n",
    "        img2 = choice(train_person_to_images_map[p2])\n",
    "\n",
    "        #print(base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)).shape)\n",
    "        training_set.append(np.concatenate((base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)), base_model.predict(np.expand_dims(np.array(read_img(img2)), axis=0)).reshape((2048)))))\n",
    "        training_labels.append(1)\n",
    "\n",
    "        flag = 0\n",
    "        while(flag == 0):\n",
    "            p1 = choice(ppl)\n",
    "            p2 = choice(ppl)\n",
    "\n",
    "            if p1 != p2 and (p1, p2) not in train and (p2, p1) not in train:\n",
    "                flag=1\n",
    "                img1 = choice(train_person_to_images_map[p1])\n",
    "                img2 = choice(train_person_to_images_map[p2])\n",
    "                #print(base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)).shape)\n",
    "                training_set.append(np.concatenate((base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)), base_model.predict(np.expand_dims(np.array(read_img(img2)), axis=0)).reshape((2048)))))\n",
    "                training_labels.append(0)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fM6k6u2XoPU"
   },
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "25OgY80msiIy",
    "outputId": "2a00b6ad-1a98-4f1b-c4a0-65af4b6fd2cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drive/My Drive/Face_recognition/X_train2']"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(training_set,\"drive/My Drive/Face_recognition/X_train2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "45w7TYWIs5bb",
    "outputId": "46fe9488-2e77-43df-c09e-e3d2e2a822fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drive/My Drive/Face_recognition/y_train2']"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(training_labels,\"drive/My Drive/Face_recognition/y_train2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7VuDFlutUPZ"
   },
   "outputs": [],
   "source": [
    "val_set = []\n",
    "val_labels = []\n",
    "ppl = list(val_person_to_images_map.keys())\n",
    "count=0\n",
    "while(count !=3):\n",
    "    for p1,p2 in val:\n",
    "        #print(p1)\n",
    "        img1 = choice(val_person_to_images_map[p1])\n",
    "        img2 = choice(val_person_to_images_map[p2])\n",
    "\n",
    "        #print(base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)).shape)\n",
    "        val_set.append(np.concatenate((base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)), base_model.predict(np.expand_dims(np.array(read_img(img2)), axis=0)).reshape((2048)))))\n",
    "        val_labels.append(1)\n",
    "\n",
    "        flag = 0\n",
    "        while(flag == 0):\n",
    "            p1 = choice(ppl)\n",
    "            p2 = choice(ppl)\n",
    "\n",
    "            if p1 != p2 and (p1, p2) not in val and (p2, p1) not in val:\n",
    "                flag=1\n",
    "                img1 = choice(val_person_to_images_map[p1])\n",
    "                img2 = choice(val_person_to_images_map[p2])\n",
    "                #print(base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)).shape)\n",
    "                val_set.append(np.concatenate((base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)), base_model.predict(np.expand_dims(np.array(read_img(img2)), axis=0)).reshape((2048)))))\n",
    "                val_labels.append(0)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "28nc--Nqtohq"
   },
   "outputs": [],
   "source": [
    "val_set = np.array(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iYaqSK47yT4p",
    "outputId": "381d0de9-29f7-42b0-f5ca-20f5b4e7d4ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drive/My Drive/Face_recognition/y_val2']"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(val_set, \"drive/My Drive/Face_recognition/val_train2\")\n",
    "joblib.dump(val_labels, \"drive/My Drive/Face_recognition/y_val2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYuIe8iAyW9d"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "25pzD4tIzUi8"
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "Ns2g0xa-zajv",
    "outputId": "9fbdb36b-7ee9-4dba-bb0d-5a326253f437"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_set,training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MKvCoY6zhaz"
   },
   "outputs": [],
   "source": [
    "train_proba = model.predict(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "quxKJHvA3Y5F",
    "outputId": "920a6c72-d121-465f-a6b9-2f2d7ae3d08e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(training_labels, train_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A9TV_Nuk3l4T",
    "outputId": "ed1e834b-f974-44c6-c558-6f362867cc2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6373873873873873"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_proba = model.predict(val_set)\n",
    "metrics.roc_auc_score(val_labels, val_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHi3IROo34wm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pw6Noct1j3Np"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qmfWjjRj3Ih"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vVhYambFRqax"
   },
   "source": [
    "### Adding distance metrics and cosine sim along with featurized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c-WeW1c77Tob",
    "outputId": "f8ca95bd-6ef5-4ed6-9b9a-f5ec80892887"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6132, 4096)"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZVrm3ogrYff7",
    "outputId": "966ff267-8b2e-4de6-8453-f4209199600f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 4096)"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ok9KisGUYhWX"
   },
   "outputs": [],
   "source": [
    "euc_train = X_train[:,:2048]**2 - X_train[:,2048:]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMm1IFiipryw"
   },
   "outputs": [],
   "source": [
    "euc_val = X_val[:,:2048]**2 - X_val[:,2048:]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WFELcO88ZGQi"
   },
   "outputs": [],
   "source": [
    "euc_train = np.sum(euc_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ick74MxRp1YH"
   },
   "outputs": [],
   "source": [
    "euc_val = np.sum(euc_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ENpBBLI2YsFM"
   },
   "outputs": [],
   "source": [
    "dis_train = (X_train[:,:2048] - X_train[:,2048:])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mn7diuteZWcA"
   },
   "outputs": [],
   "source": [
    "dis_train = np.sum(dis_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PM6m9cKzp6su"
   },
   "outputs": [],
   "source": [
    "dis_val = (X_val[:,:2048] - X_val[:,2048:])**2\n",
    "dis_val = np.sum(dis_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9txE4wxZXf-"
   },
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAs1D5ROar-w"
   },
   "outputs": [],
   "source": [
    "cosine_train = np.array(list(map(lambda x,y: 1-spatial.distance.cosine(x,y), X_train[:,:2048], X_train[:,2048:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGUfg9i5qEPy"
   },
   "outputs": [],
   "source": [
    "cosine_val = np.array(list(map(lambda x,y: 1-spatial.distance.cosine(x,y), X_val[:,:2048], X_val[:,2048:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "a1bY2InXatNV",
    "outputId": "1b02e64b-a5de-4a48-c0c3-f495111d2bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6132, 4096)\n",
      "(6132,)\n",
      "(6132,)\n",
      "(6132,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(euc_train.shape)\n",
    "print(dis_train.shape)\n",
    "print(cosine_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZI7ReKfbb7I"
   },
   "outputs": [],
   "source": [
    "X_train = np.column_stack((X_train, euc_train, dis_train, cosine_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVNyl7dIqNp8"
   },
   "outputs": [],
   "source": [
    "X_val = np.column_stack((X_val, euc_val, dis_val, cosine_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3AZF4DUBooZM",
    "outputId": "488f4539-f6a6-49d8-f820-959874843072"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6132, 4099)"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XLGJ_lY2qUT-",
    "outputId": "df486aea-f72b-46b7-d795-5c4500984e99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 4099)"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gK3QiAKQcBJH"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "gTyXtL30cT39",
    "outputId": "fd025bbc-88f3-4851-f9db-37810c03d3bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 132,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = XGBClassifier(max_depth=5,n_estimators=200)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eg1FizRHolvD"
   },
   "outputs": [],
   "source": [
    "train_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmL3oUO8pcuc"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5s-Qo8olpe1K",
    "outputId": "52f58110-8f09-4fda-9c6e-d3d734fce994"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 142,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics.roc_auc_score(y_train, train_pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F3QassO0pnj9",
    "outputId": "4fe4e4ca-7a06-4637-be31-0cf74a1bfebc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8506665449233017"
      ]
     },
     "execution_count": 145,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred_proba = rf.predict_proba(X_val)\n",
    "metrics.roc_auc_score(y_val, val_pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4iHBVvPkB8P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8yeLRF_ykB3U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2eg-VEDkByg"
   },
   "outputs": [],
   "source": [
    "### Hyper param tuning the XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "V3bkR-3akBtW",
    "outputId": "bca2523e-4c67-44e1-9e71-10d4b0c5d6fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 88.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=-1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 4, 6, 8],\n",
       "                         'n_estimators': [10, 50, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_depth':[2,4,6,8], 'n_estimators':[10,50,100,200]}\n",
    "model = GridSearchCV(XGBClassifier(n_jobs=-1), param_grid=params,scoring='roc_auc',n_jobs=-1,cv=3, return_train_score=True, verbose=1)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPJelQgI6Bnn"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kd--IrRH56Fm",
    "outputId": "96cecf59-7cdb-431c-8063-d387d914c964"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8591487918117144"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_proba = model.best_estimator_.predict_proba(X_train)\n",
    "metrics.roc_auc_score(y_train, train_pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sWKjlwGx558H",
    "outputId": "9599fdac-f342-4fa6-f7c0-0e2ab50eee22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8528465120525931"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred_proba = model.best_estimator_.predict_proba(X_val)\n",
    "metrics.roc_auc_score(y_val, val_pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jbvqATEu78E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0JkAMoFqcl-"
   },
   "outputs": [],
   "source": [
    "# test_path = \"drive/My Drive/Face_recognition/test/\"\n",
    "# def chunker(seq, size=32):\n",
    "#     return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# submission = pd.read_csv('drive/My Drive/Face_recognition/sample_submission.csv')\n",
    "\n",
    "# predictions = []\n",
    "\n",
    "# for batch in tqdm(chunker(submission.img_pair.values)):\n",
    "#     X1 = [x.split(\"-\")[0] for x in batch]\n",
    "#     X1 = np.array([read_img(test_path + x) for x in X1])\n",
    "\n",
    "#     X2 = [x.split(\"-\")[1] for x in batch]\n",
    "#     X2 = np.array([read_img(test_path + x) for x in X2])\n",
    "\n",
    "#     pred = model.predict([X1, X2]).ravel().tolist()\n",
    "#     predictions += pred\n",
    "\n",
    "# submission['is_related'] = predictions\n",
    "\n",
    "# submission.to_csv(\"vgg_face.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzIp3p0XkAs8"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('drive/My Drive/Face_recognition/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyu18lOrkAn-"
   },
   "outputs": [],
   "source": [
    "test_path = \"drive/My Drive/Face_recognition/test/\"\n",
    "X_test = []\n",
    "for img_pair in submission['img_pair'].values:\n",
    "    x1 = img_pair.split('-')[0]\n",
    "    x1 = np.array(read_img(test_path + x1))\n",
    "    x1 = base_model.predict(np.expand_dims(x1,axis=0)).reshape(2048)\n",
    "    x2 = img_pair.split('-')[1]\n",
    "    x2 = np.array(read_img(test_path + x2))\n",
    "    x2 = base_model.predict(np.expand_dims(x2,axis=0)).reshape(2048)\n",
    "    euc = np.sum(x1**2 - x2**2)\n",
    "    dis = np.sum((x1-x2)**2)\n",
    "    cosine = 1-spatial.distance.cosine(x1,x2)\n",
    "    ip = np.concatenate((x1,x2, [euc,dis,cosine]))\n",
    "    X_test.append(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWUeywpm-_dv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xvvQY4AOkAjD"
   },
   "outputs": [],
   "source": [
    "test_proba = model.best_estimator_.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phL0WKNlkAee"
   },
   "outputs": [],
   "source": [
    "submission['is_related'] = test_proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWI2eigJOK8e"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"drive/My Drive/Face_recognition/xgbpred.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OM62Li_aPARN"
   },
   "source": [
    "### Test score: 84.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Taking mean of different models and other miscellaneous experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Osilfq01zbX"
   },
   "outputs": [],
   "source": [
    "sub_files = ['/content/drive/My Drive/Face_recognition/cosine_focal_submission.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/cosine_focal_submission2.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/cosine_submission.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/cosine_submission2.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/xgbpred.csv'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "8f8CEXMA1Qxi",
    "outputId": "dce49537-7dc0-4bc0-b79c-c75f10518596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      img_pair  is_related\n",
      "0  face05508.jpg-face01210.jpg    0.042997\n",
      "1  face05750.jpg-face00898.jpg    0.658368\n",
      "2  face05820.jpg-face03938.jpg    0.579603\n",
      "3  face02104.jpg-face01172.jpg    0.633630\n",
      "4  face02428.jpg-face05611.jpg    0.624601\n",
      "                      img_pair  is_related\n",
      "0  face05508.jpg-face01210.jpg    0.090727\n",
      "1  face05750.jpg-face00898.jpg    0.665668\n",
      "2  face05820.jpg-face03938.jpg    0.507103\n",
      "3  face02104.jpg-face01172.jpg    0.572642\n",
      "4  face02428.jpg-face05611.jpg    0.531363\n",
      "                      img_pair  is_related\n",
      "0  face05508.jpg-face01210.jpg    0.000461\n",
      "1  face05750.jpg-face00898.jpg    0.946379\n",
      "2  face05820.jpg-face03938.jpg    0.584920\n",
      "3  face02104.jpg-face01172.jpg    0.623860\n",
      "4  face02428.jpg-face05611.jpg    0.844366\n",
      "                      img_pair  is_related\n",
      "0  face05508.jpg-face01210.jpg    0.000461\n",
      "1  face05750.jpg-face00898.jpg    0.946379\n",
      "2  face05820.jpg-face03938.jpg    0.584920\n",
      "3  face02104.jpg-face01172.jpg    0.623860\n",
      "4  face02428.jpg-face05611.jpg    0.844366\n",
      "                      img_pair  is_related\n",
      "0  face05508.jpg-face01210.jpg    0.198339\n",
      "1  face05750.jpg-face00898.jpg    0.593600\n",
      "2  face05820.jpg-face03938.jpg    0.736615\n",
      "3  face02104.jpg-face01172.jpg    0.847105\n",
      "4  face02428.jpg-face05611.jpg    0.572516\n"
     ]
    }
   ],
   "source": [
    "for f in sub_files:\n",
    "    d = pd.read_csv(f)\n",
    "    print(d.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_VltIO-szyol"
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for f in sub_files:\n",
    "    d = pd.read_csv(f)\n",
    "    scores.append(np.array(d['is_related']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nosAwV3MrvcH"
   },
   "outputs": [],
   "source": [
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R3T26kwDsFZ6",
    "outputId": "33b6cb7f-1c46-467d-ce38-9565d808843f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5310)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDTCa46ssG8s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "421FlXB9sV5_"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/content/drive/My Drive/Face_recognition/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xELeFipWsqH2"
   },
   "outputs": [],
   "source": [
    "submission['is_related'] = np.sum(scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "Q89ayAUJsruO",
    "outputId": "e17c706d-7a71-4bb0-a052-f355f956cef9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_pair</th>\n",
       "      <th>is_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>face05508.jpg-face01210.jpg</td>\n",
       "      <td>0.332984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>face05750.jpg-face00898.jpg</td>\n",
       "      <td>3.810393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>face05820.jpg-face03938.jpg</td>\n",
       "      <td>2.993161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>face02104.jpg-face01172.jpg</td>\n",
       "      <td>3.301096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>face02428.jpg-face05611.jpg</td>\n",
       "      <td>3.417211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      img_pair  is_related\n",
       "0  face05508.jpg-face01210.jpg    0.332984\n",
       "1  face05750.jpg-face00898.jpg    3.810393\n",
       "2  face05820.jpg-face03938.jpg    2.993161\n",
       "3  face02104.jpg-face01172.jpg    3.301096\n",
       "4  face02428.jpg-face05611.jpg    3.417211"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PBKqqDSIs09O"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"/content/drive/My Drive/Face_recognition/sub5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "GIb1ONuzt3nQ",
    "outputId": "044a425a-be9b-4e27-8097-a11e64f5df4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/drive/My Drive/Face_recognition/cosine_focal_submission.csv',\n",
       " '/content/drive/My Drive/Face_recognition/cosine_focal_submission2.csv',\n",
       " '/content/drive/My Drive/Face_recognition/cosine_submission.csv',\n",
       " '/content/drive/My Drive/Face_recognition/cosine_submission2.csv',\n",
       " '/content/drive/My Drive/Face_recognition/xgbpred.csv']"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "5hM96KQ8C5Pe",
    "outputId": "f2619be4-fc58-4b85-dc3b-eab8ccdc6338"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04299739, 0.65836751, 0.57960308, ..., 0.5060814 , 0.41394684,\n",
       "       0.43831879])"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxQdoxMvC_EC"
   },
   "outputs": [],
   "source": [
    "scores[0] = scores[0]*0.3\n",
    "scores[1] = scores[1]*0.3\n",
    "scores[2] = scores[2]*0.15\n",
    "scores[3] = scores[3]*0.15\n",
    "scores[4] = scores[4]*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALrBhbDgDNyE"
   },
   "outputs": [],
   "source": [
    "submission['is_related'] = np.sum(scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4SWeOCv0DxU_"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"/content/drive/My Drive/Face_recognition/sub6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KG0g1lXiDzEs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8vRsuDlwNff"
   },
   "outputs": [],
   "source": [
    "#from keras.preprocessing import image\n",
    "def read_img_facenet(path):\n",
    "    #change1\n",
    "    img = image.load_img(path, target_size=(160, 160))\n",
    "    img = np.array(img).astype(np.float)\n",
    "    return preprocess_input(img, version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_hYQU3vwNyF"
   },
   "outputs": [],
   "source": [
    "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
    "    ppl = list(person_to_images_map.keys())\n",
    "    while True:\n",
    "        #sample() Chooses k unique random elements from a population sequence or set\n",
    "        # Filling batch tuples with half 1 lables\n",
    "        batch_tuples = sample(list_tuples, batch_size // 2)\n",
    "        # Assigning 1 label to all the pairs given in relationships file\n",
    "        labels = [1] * len(batch_tuples)\n",
    "        # Filling half batch_tuples with 0 labels\n",
    "        while len(batch_tuples) < batch_size:\n",
    "            p1 = choice(ppl)\n",
    "            p2 = choice(ppl)\n",
    "\n",
    "            if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:\n",
    "                batch_tuples.append((p1, p2))\n",
    "                labels.append(0)\n",
    "\n",
    "        for x in batch_tuples:\n",
    "            if not len(person_to_images_map[x[0]]):\n",
    "                print(x[0])\n",
    "        \n",
    "        # Selecting a single image out of many provided for each user\n",
    "        X1 = [choice(person_to_images_map[x[0]]) for x in batch_tuples]\n",
    "        X1 = np.array([read_img_facenet(x) for x in X1])\n",
    "        \n",
    "        # Selecting a single image out of many provided for each user\n",
    "        X2 = [choice(person_to_images_map[x[1]]) for x in batch_tuples]\n",
    "        X2 = np.array([read_img_facenet(x) for x in X2])\n",
    "\n",
    "        yield [X1, X2], labels\n",
    "        \n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(K.epsilon()+pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tMIUVgOixMcA"
   },
   "outputs": [],
   "source": [
    "\n",
    "# example of loading the keras facenet model\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "44H7DuN01FCG",
    "outputId": "9dd43caf-96d3-4519-b216-107f4f754d72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "base_model = load_model('/content/drive/My Drive/Face_recognition/facenet_keras.h5')\n",
    "t = base_model.predict(np.expand_dims(np.array(read_img_facenet('drive/My Drive/Face_recognition/train/F0002/MID1/P00010_face4.jpg')), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4fXe7osn1Gp7",
    "outputId": "0b5b9437-43e5-42a4-83ce-5835d625c889"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXDuHn_uwXl3"
   },
   "outputs": [],
   "source": [
    "def face_cosine_focal_model():\n",
    "    #change 2\n",
    "    input_1 = Input(shape=(160, 160, 3))\n",
    "    input_2 = Input(shape=(160, 160, 3))\n",
    "\n",
    "    base_model = load_model('/content/drive/My Drive/Face_recognition/facenet_keras.h5')\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "\n",
    "    #x1 = GlobalAvgPool2D()(x1)\n",
    "    #x2 = GlobalAvgPool2D()(x2)\n",
    "\n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "\n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    \n",
    "    #https://stackoverflow.com/a/51003359/10650182\n",
    "    x5 = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([x1, x2])\n",
    "    \n",
    "    x = Concatenate(axis=-1)([x5,x4, x3])\n",
    "\n",
    "    x = Dense(100, activation=\"relu\")(x)\n",
    "    x = Dropout(0.01)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc',auroc], optimizer=Adam(0.00001))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0WNa2gR7wQtq",
    "outputId": "82115ef5-c4c1-406a-9f71-1a23908545ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "W0806 02:58:22.415379 140359944357760 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0806 02:58:22.427185 140359944357760 deprecation.py:323] From <ipython-input-57-512924c48ae6>:34: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0806 02:58:22.469060 140359944357760 deprecation.py:323] From <ipython-input-2-bc412d992b42>:14: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 160, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 160, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inception_resnet_v1 (Model)     (None, 128)          22808144    input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 128)          0           inception_resnet_v1[1][0]        \n",
      "                                                                 inception_resnet_v1[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 128)          0           inception_resnet_v1[2][0]        \n",
      "                                                                 inception_resnet_v1[2][0]        \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 128)          0           inception_resnet_v1[1][0]        \n",
      "                                                                 inception_resnet_v1[2][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           inception_resnet_v1[1][0]        \n",
      "                                                                 inception_resnet_v1[2][0]        \n",
      "__________________________________________________________________________________________________\n",
      "subtract_4 (Subtract)           (None, 128)          0           multiply_5[0][0]                 \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 128)          0           subtract_3[0][0]                 \n",
      "                                                                 subtract_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 257)          0           lambda_1[0][0]                   \n",
      "                                                                 subtract_4[0][0]                 \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          25800       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            101         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,834,045\n",
      "Trainable params: 22,805,213\n",
      "Non-trainable params: 28,832\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "file_path = \"drive/My Drive/Face_recognition/facenet_cosine_focal.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_auroc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_auroc\", mode=\"max\", factor=0.1, patience=10, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "model = face_cosine_focal_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uykBo2wC0Tqz",
    "outputId": "86f1340f-11a2-4d9d-caa2-cac3c45d24c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 522s 3s/step - loss: 14.4668 - acc: 0.4959 - auroc: 0.4809 - val_loss: 8.5882 - val_acc: 0.5231 - val_auroc: 0.5422\n",
      "\n",
      "Epoch 00001: val_auroc improved from -inf to 0.54219, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 233s 1s/step - loss: 7.1287 - acc: 0.5278 - auroc: 0.5331 - val_loss: 6.0816 - val_acc: 0.5294 - val_auroc: 0.5506\n",
      "\n",
      "Epoch 00002: val_auroc improved from 0.54219 to 0.55063, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 152s 758ms/step - loss: 5.3286 - acc: 0.5406 - auroc: 0.5727 - val_loss: 5.6818 - val_acc: 0.5169 - val_auroc: 0.5436\n",
      "\n",
      "Epoch 00003: val_auroc did not improve from 0.55063\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 141s 705ms/step - loss: 4.7327 - acc: 0.5269 - auroc: 0.5711 - val_loss: 4.4726 - val_acc: 0.5531 - val_auroc: 0.6067\n",
      "\n",
      "Epoch 00004: val_auroc improved from 0.55063 to 0.60672, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 141s 704ms/step - loss: 4.7083 - acc: 0.5381 - auroc: 0.5690 - val_loss: 4.5058 - val_acc: 0.5394 - val_auroc: 0.6000\n",
      "\n",
      "Epoch 00005: val_auroc did not improve from 0.60672\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 139s 695ms/step - loss: 4.3808 - acc: 0.5453 - auroc: 0.5924 - val_loss: 4.0820 - val_acc: 0.5419 - val_auroc: 0.6062\n",
      "\n",
      "Epoch 00006: val_auroc did not improve from 0.60672\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 142s 711ms/step - loss: 4.1318 - acc: 0.5422 - auroc: 0.6038 - val_loss: 4.3484 - val_acc: 0.5325 - val_auroc: 0.5814\n",
      "\n",
      "Epoch 00007: val_auroc did not improve from 0.60672\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 142s 709ms/step - loss: 3.7004 - acc: 0.5663 - auroc: 0.6272 - val_loss: 3.7964 - val_acc: 0.5563 - val_auroc: 0.6166\n",
      "\n",
      "Epoch 00008: val_auroc improved from 0.60672 to 0.61656, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 3.8894 - acc: 0.5609 - auroc: 0.6151 - val_loss: 4.2099 - val_acc: 0.5450 - val_auroc: 0.6048\n",
      "\n",
      "Epoch 00009: val_auroc did not improve from 0.61656\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 3.4283 - acc: 0.5672 - auroc: 0.6348 - val_loss: 3.7873 - val_acc: 0.5531 - val_auroc: 0.6075\n",
      "\n",
      "Epoch 00010: val_auroc did not improve from 0.61656\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 3.3673 - acc: 0.5744 - auroc: 0.6533 - val_loss: 3.9095 - val_acc: 0.5475 - val_auroc: 0.6030\n",
      "\n",
      "Epoch 00011: val_auroc did not improve from 0.61656\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 3.0476 - acc: 0.5872 - auroc: 0.6655 - val_loss: 4.0600 - val_acc: 0.5419 - val_auroc: 0.6058\n",
      "\n",
      "Epoch 00012: val_auroc did not improve from 0.61656\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 2.9482 - acc: 0.5981 - auroc: 0.6695 - val_loss: 3.6429 - val_acc: 0.5763 - val_auroc: 0.6352\n",
      "\n",
      "Epoch 00013: val_auroc improved from 0.61656 to 0.63516, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 142s 709ms/step - loss: 2.8312 - acc: 0.5978 - auroc: 0.6934 - val_loss: 3.3755 - val_acc: 0.5519 - val_auroc: 0.6291\n",
      "\n",
      "Epoch 00014: val_auroc did not improve from 0.63516\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 142s 711ms/step - loss: 2.8109 - acc: 0.5972 - auroc: 0.6869 - val_loss: 3.2658 - val_acc: 0.5669 - val_auroc: 0.6272\n",
      "\n",
      "Epoch 00015: val_auroc did not improve from 0.63516\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 141s 707ms/step - loss: 2.7365 - acc: 0.5966 - auroc: 0.6848 - val_loss: 3.1167 - val_acc: 0.5737 - val_auroc: 0.6398\n",
      "\n",
      "Epoch 00016: val_auroc improved from 0.63516 to 0.63984, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 143s 715ms/step - loss: 2.7334 - acc: 0.5962 - auroc: 0.6950 - val_loss: 3.2432 - val_acc: 0.5787 - val_auroc: 0.6408\n",
      "\n",
      "Epoch 00017: val_auroc improved from 0.63984 to 0.64078, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 2.5985 - acc: 0.6000 - auroc: 0.6905 - val_loss: 3.3758 - val_acc: 0.5700 - val_auroc: 0.6286\n",
      "\n",
      "Epoch 00018: val_auroc did not improve from 0.64078\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 142s 712ms/step - loss: 2.3153 - acc: 0.6166 - auroc: 0.7202 - val_loss: 2.9167 - val_acc: 0.5644 - val_auroc: 0.6600\n",
      "\n",
      "Epoch 00019: val_auroc improved from 0.64078 to 0.66000, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 141s 705ms/step - loss: 2.5143 - acc: 0.6109 - auroc: 0.6950 - val_loss: 3.1668 - val_acc: 0.5837 - val_auroc: 0.6545\n",
      "\n",
      "Epoch 00020: val_auroc did not improve from 0.66000\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 2.0286 - acc: 0.6400 - auroc: 0.7448 - val_loss: 3.0628 - val_acc: 0.5919 - val_auroc: 0.6539\n",
      "\n",
      "Epoch 00021: val_auroc did not improve from 0.66000\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 2.2291 - acc: 0.6197 - auroc: 0.7220 - val_loss: 2.7802 - val_acc: 0.5931 - val_auroc: 0.6758\n",
      "\n",
      "Epoch 00022: val_auroc improved from 0.66000 to 0.67578, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 143s 715ms/step - loss: 2.0503 - acc: 0.6350 - auroc: 0.7395 - val_loss: 2.6374 - val_acc: 0.5825 - val_auroc: 0.6623\n",
      "\n",
      "Epoch 00023: val_auroc did not improve from 0.67578\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 143s 713ms/step - loss: 1.9637 - acc: 0.6506 - auroc: 0.7440 - val_loss: 2.6220 - val_acc: 0.5850 - val_auroc: 0.6791\n",
      "\n",
      "Epoch 00024: val_auroc improved from 0.67578 to 0.67906, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.9520 - acc: 0.6406 - auroc: 0.7460 - val_loss: 2.5536 - val_acc: 0.6150 - val_auroc: 0.6808\n",
      "\n",
      "Epoch 00025: val_auroc improved from 0.67906 to 0.68078, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 2.1154 - acc: 0.6244 - auroc: 0.7316 - val_loss: 2.3411 - val_acc: 0.6156 - val_auroc: 0.6911\n",
      "\n",
      "Epoch 00026: val_auroc improved from 0.68078 to 0.69109, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 142s 712ms/step - loss: 1.9921 - acc: 0.6206 - auroc: 0.7494 - val_loss: 2.0802 - val_acc: 0.6200 - val_auroc: 0.7145\n",
      "\n",
      "Epoch 00027: val_auroc improved from 0.69109 to 0.71453, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 142s 709ms/step - loss: 1.9503 - acc: 0.6344 - auroc: 0.7454 - val_loss: 2.3410 - val_acc: 0.5913 - val_auroc: 0.6758\n",
      "\n",
      "Epoch 00028: val_auroc did not improve from 0.71453\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 142s 712ms/step - loss: 1.9078 - acc: 0.6447 - auroc: 0.7471 - val_loss: 2.4067 - val_acc: 0.5931 - val_auroc: 0.6700\n",
      "\n",
      "Epoch 00029: val_auroc did not improve from 0.71453\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 1.7605 - acc: 0.6541 - auroc: 0.7605 - val_loss: 2.4654 - val_acc: 0.5944 - val_auroc: 0.6731\n",
      "\n",
      "Epoch 00030: val_auroc did not improve from 0.71453\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 1.7209 - acc: 0.6434 - auroc: 0.7648 - val_loss: 2.2690 - val_acc: 0.6131 - val_auroc: 0.6797\n",
      "\n",
      "Epoch 00031: val_auroc did not improve from 0.71453\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 1.6544 - acc: 0.6466 - auroc: 0.7755 - val_loss: 2.3207 - val_acc: 0.6131 - val_auroc: 0.7063\n",
      "\n",
      "Epoch 00032: val_auroc did not improve from 0.71453\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.8121 - acc: 0.6338 - auroc: 0.7450 - val_loss: 2.2250 - val_acc: 0.6119 - val_auroc: 0.6992\n",
      "\n",
      "Epoch 00033: val_auroc did not improve from 0.71453\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 1.6347 - acc: 0.6559 - auroc: 0.7704 - val_loss: 2.1834 - val_acc: 0.6062 - val_auroc: 0.6984\n",
      "\n",
      "Epoch 00034: val_auroc did not improve from 0.71453\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 143s 715ms/step - loss: 1.7067 - acc: 0.6522 - auroc: 0.7651 - val_loss: 2.0712 - val_acc: 0.6225 - val_auroc: 0.6883\n",
      "\n",
      "Epoch 00035: val_auroc did not improve from 0.71453\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 143s 714ms/step - loss: 1.5772 - acc: 0.6547 - auroc: 0.7748 - val_loss: 2.1539 - val_acc: 0.6069 - val_auroc: 0.6894\n",
      "\n",
      "Epoch 00036: val_auroc did not improve from 0.71453\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 143s 713ms/step - loss: 1.6499 - acc: 0.6578 - auroc: 0.7699 - val_loss: 2.2287 - val_acc: 0.6019 - val_auroc: 0.6761\n",
      "\n",
      "Epoch 00037: val_auroc did not improve from 0.71453\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 1.4775 - acc: 0.6725 - auroc: 0.7971 - val_loss: 2.2594 - val_acc: 0.5737 - val_auroc: 0.6641\n",
      "\n",
      "Epoch 00038: val_auroc did not improve from 0.71453\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 1.5130 - acc: 0.6772 - auroc: 0.7932 - val_loss: 2.0236 - val_acc: 0.6169 - val_auroc: 0.6897\n",
      "\n",
      "Epoch 00039: val_auroc did not improve from 0.71453\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 1.5854 - acc: 0.6697 - auroc: 0.7774 - val_loss: 2.1004 - val_acc: 0.5875 - val_auroc: 0.6772\n",
      "\n",
      "Epoch 00040: val_auroc did not improve from 0.71453\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 1.6443 - acc: 0.6484 - auroc: 0.7616 - val_loss: 2.0843 - val_acc: 0.6106 - val_auroc: 0.6841\n",
      "\n",
      "Epoch 00041: val_auroc did not improve from 0.71453\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 145s 724ms/step - loss: 1.5366 - acc: 0.6603 - auroc: 0.7826 - val_loss: 2.0779 - val_acc: 0.6075 - val_auroc: 0.6792\n",
      "\n",
      "Epoch 00042: val_auroc did not improve from 0.71453\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 1.5561 - acc: 0.6684 - auroc: 0.7823 - val_loss: 2.0216 - val_acc: 0.6188 - val_auroc: 0.7002\n",
      "\n",
      "Epoch 00043: val_auroc did not improve from 0.71453\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 143s 715ms/step - loss: 1.5642 - acc: 0.6625 - auroc: 0.7784 - val_loss: 1.8676 - val_acc: 0.6269 - val_auroc: 0.7016\n",
      "\n",
      "Epoch 00044: val_auroc did not improve from 0.71453\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 143s 713ms/step - loss: 1.5227 - acc: 0.6591 - auroc: 0.7832 - val_loss: 2.0190 - val_acc: 0.6044 - val_auroc: 0.6884\n",
      "\n",
      "Epoch 00045: val_auroc did not improve from 0.71453\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 141s 706ms/step - loss: 1.5665 - acc: 0.6572 - auroc: 0.7808 - val_loss: 1.9417 - val_acc: 0.6188 - val_auroc: 0.7025\n",
      "\n",
      "Epoch 00046: val_auroc did not improve from 0.71453\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 1.5965 - acc: 0.6500 - auroc: 0.7680 - val_loss: 1.9865 - val_acc: 0.6162 - val_auroc: 0.6978\n",
      "\n",
      "Epoch 00047: val_auroc did not improve from 0.71453\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.6004 - acc: 0.6516 - auroc: 0.7799 - val_loss: 2.0509 - val_acc: 0.6012 - val_auroc: 0.6859\n",
      "\n",
      "Epoch 00048: val_auroc did not improve from 0.71453\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 1.5850 - acc: 0.6547 - auroc: 0.7690 - val_loss: 2.1497 - val_acc: 0.6269 - val_auroc: 0.6948\n",
      "\n",
      "Epoch 00049: val_auroc did not improve from 0.71453\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 1.4879 - acc: 0.6694 - auroc: 0.7934 - val_loss: 1.9788 - val_acc: 0.6394 - val_auroc: 0.7303\n",
      "\n",
      "Epoch 00050: val_auroc improved from 0.71453 to 0.73031, saving model to drive/My Drive/Face_recognition/facenet_cosine_focal.h5\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 1.4963 - acc: 0.6675 - auroc: 0.7859 - val_loss: 2.1725 - val_acc: 0.6131 - val_auroc: 0.6802\n",
      "\n",
      "Epoch 00051: val_auroc did not improve from 0.73031\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 1.4417 - acc: 0.6756 - auroc: 0.7938 - val_loss: 1.8967 - val_acc: 0.6106 - val_auroc: 0.7042\n",
      "\n",
      "Epoch 00052: val_auroc did not improve from 0.73031\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.5365 - acc: 0.6562 - auroc: 0.7800 - val_loss: 2.1284 - val_acc: 0.6100 - val_auroc: 0.6959\n",
      "\n",
      "Epoch 00053: val_auroc did not improve from 0.73031\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 143s 714ms/step - loss: 1.5084 - acc: 0.6716 - auroc: 0.7858 - val_loss: 1.8558 - val_acc: 0.6138 - val_auroc: 0.7009\n",
      "\n",
      "Epoch 00054: val_auroc did not improve from 0.73031\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 145s 724ms/step - loss: 1.5714 - acc: 0.6797 - auroc: 0.7817 - val_loss: 1.9169 - val_acc: 0.6294 - val_auroc: 0.7256\n",
      "\n",
      "Epoch 00055: val_auroc did not improve from 0.73031\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 1.6015 - acc: 0.6619 - auroc: 0.7740 - val_loss: 2.0974 - val_acc: 0.6025 - val_auroc: 0.6803\n",
      "\n",
      "Epoch 00056: val_auroc did not improve from 0.73031\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 1.5872 - acc: 0.6528 - auroc: 0.7813 - val_loss: 1.8696 - val_acc: 0.6181 - val_auroc: 0.7078\n",
      "\n",
      "Epoch 00057: val_auroc did not improve from 0.73031\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 1.5126 - acc: 0.6528 - auroc: 0.7783 - val_loss: 1.9444 - val_acc: 0.5956 - val_auroc: 0.6819\n",
      "\n",
      "Epoch 00058: val_auroc did not improve from 0.73031\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 1.5511 - acc: 0.6622 - auroc: 0.7735 - val_loss: 1.9679 - val_acc: 0.6112 - val_auroc: 0.6939\n",
      "\n",
      "Epoch 00059: val_auroc did not improve from 0.73031\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 1.5472 - acc: 0.6512 - auroc: 0.7765 - val_loss: 2.0006 - val_acc: 0.6106 - val_auroc: 0.6863\n",
      "\n",
      "Epoch 00060: val_auroc did not improve from 0.73031\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 1.5129 - acc: 0.6675 - auroc: 0.7891 - val_loss: 1.9799 - val_acc: 0.6244 - val_auroc: 0.6961\n",
      "\n",
      "Epoch 00061: val_auroc did not improve from 0.73031\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 1.5375 - acc: 0.6613 - auroc: 0.7820 - val_loss: 2.0559 - val_acc: 0.6212 - val_auroc: 0.6980\n",
      "\n",
      "Epoch 00062: val_auroc did not improve from 0.73031\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 1.5968 - acc: 0.6575 - auroc: 0.7757 - val_loss: 2.0841 - val_acc: 0.6131 - val_auroc: 0.6823\n",
      "\n",
      "Epoch 00063: val_auroc did not improve from 0.73031\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 145s 724ms/step - loss: 1.4986 - acc: 0.6734 - auroc: 0.7923 - val_loss: 2.0656 - val_acc: 0.6075 - val_auroc: 0.6892\n",
      "\n",
      "Epoch 00064: val_auroc did not improve from 0.73031\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.6313 - acc: 0.6466 - auroc: 0.7632 - val_loss: 2.0118 - val_acc: 0.6238 - val_auroc: 0.6973\n",
      "\n",
      "Epoch 00065: val_auroc did not improve from 0.73031\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 1.4992 - acc: 0.6738 - auroc: 0.7851 - val_loss: 1.9304 - val_acc: 0.6250 - val_auroc: 0.7014\n",
      "\n",
      "Epoch 00066: val_auroc did not improve from 0.73031\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 1.5818 - acc: 0.6559 - auroc: 0.7693 - val_loss: 2.0238 - val_acc: 0.6231 - val_auroc: 0.6994\n",
      "\n",
      "Epoch 00067: val_auroc did not improve from 0.73031\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 1.4245 - acc: 0.6653 - auroc: 0.7962 - val_loss: 2.0222 - val_acc: 0.5956 - val_auroc: 0.6900\n",
      "\n",
      "Epoch 00068: val_auroc did not improve from 0.73031\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 1.5934 - acc: 0.6550 - auroc: 0.7664 - val_loss: 2.2081 - val_acc: 0.6050 - val_auroc: 0.6956\n",
      "\n",
      "Epoch 00069: val_auroc did not improve from 0.73031\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 145s 724ms/step - loss: 1.4578 - acc: 0.6731 - auroc: 0.7943 - val_loss: 1.9316 - val_acc: 0.6325 - val_auroc: 0.7058\n",
      "\n",
      "Epoch 00070: val_auroc did not improve from 0.73031\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.5615 - acc: 0.6587 - auroc: 0.7777 - val_loss: 1.9066 - val_acc: 0.6288 - val_auroc: 0.7020\n",
      "\n",
      "Epoch 00071: val_auroc did not improve from 0.73031\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 1.5712 - acc: 0.6675 - auroc: 0.7829 - val_loss: 2.1443 - val_acc: 0.5944 - val_auroc: 0.6878\n",
      "\n",
      "Epoch 00072: val_auroc did not improve from 0.73031\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 1.5291 - acc: 0.6631 - auroc: 0.7885 - val_loss: 2.2143 - val_acc: 0.5919 - val_auroc: 0.6639\n",
      "\n",
      "Epoch 00073: val_auroc did not improve from 0.73031\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 1.5290 - acc: 0.6753 - auroc: 0.7872 - val_loss: 1.9816 - val_acc: 0.6075 - val_auroc: 0.6925\n",
      "\n",
      "Epoch 00074: val_auroc did not improve from 0.73031\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 1.6282 - acc: 0.6603 - auroc: 0.7712 - val_loss: 2.0333 - val_acc: 0.6100 - val_auroc: 0.6995\n",
      "\n",
      "Epoch 00075: val_auroc did not improve from 0.73031\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 142s 712ms/step - loss: 1.5475 - acc: 0.6738 - auroc: 0.7873 - val_loss: 2.0819 - val_acc: 0.6262 - val_auroc: 0.7244\n",
      "\n",
      "Epoch 00076: val_auroc did not improve from 0.73031\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 1.4914 - acc: 0.6641 - auroc: 0.7866 - val_loss: 2.2755 - val_acc: 0.5831 - val_auroc: 0.6484\n",
      "\n",
      "Epoch 00077: val_auroc did not improve from 0.73031\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 1.5170 - acc: 0.6703 - auroc: 0.7828 - val_loss: 1.9277 - val_acc: 0.6394 - val_auroc: 0.7130\n",
      "\n",
      "Epoch 00078: val_auroc did not improve from 0.73031\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 145s 724ms/step - loss: 1.5161 - acc: 0.6544 - auroc: 0.7797 - val_loss: 1.9784 - val_acc: 0.6144 - val_auroc: 0.7066\n",
      "\n",
      "Epoch 00079: val_auroc did not improve from 0.73031\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 1.5418 - acc: 0.6497 - auroc: 0.7749 - val_loss: 1.9855 - val_acc: 0.6188 - val_auroc: 0.6936\n",
      "\n",
      "Epoch 00080: val_auroc did not improve from 0.73031\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 1.4892 - acc: 0.6772 - auroc: 0.7932 - val_loss: 1.8143 - val_acc: 0.6312 - val_auroc: 0.7203\n",
      "\n",
      "Epoch 00081: val_auroc did not improve from 0.73031\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 1.5123 - acc: 0.6684 - auroc: 0.7880 - val_loss: 1.9345 - val_acc: 0.6119 - val_auroc: 0.6953\n",
      "\n",
      "Epoch 00082: val_auroc did not improve from 0.73031\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 143s 715ms/step - loss: 1.5738 - acc: 0.6459 - auroc: 0.7801 - val_loss: 2.0702 - val_acc: 0.5944 - val_auroc: 0.6883\n",
      "\n",
      "Epoch 00083: val_auroc did not improve from 0.73031\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.5211 - acc: 0.6572 - auroc: 0.7788 - val_loss: 2.0618 - val_acc: 0.6138 - val_auroc: 0.6994\n",
      "\n",
      "Epoch 00084: val_auroc did not improve from 0.73031\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 1.5723 - acc: 0.6606 - auroc: 0.7791 - val_loss: 2.0401 - val_acc: 0.6138 - val_auroc: 0.6900\n",
      "\n",
      "Epoch 00085: val_auroc did not improve from 0.73031\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.5367 - acc: 0.6666 - auroc: 0.7867 - val_loss: 2.1064 - val_acc: 0.6112 - val_auroc: 0.6936\n",
      "\n",
      "Epoch 00086: val_auroc did not improve from 0.73031\n",
      "Epoch 87/100\n",
      " 31/200 [===>..........................] - ETA: 1:46 - loss: 1.3983 - acc: 0.6653 - auroc: 0.7908"
     ]
    }
   ],
   "source": [
    "model.fit_generator(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=True,\n",
    "                    validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=100, verbose=1,\n",
    "                    workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8dzv1uRM3hmR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kOtujUw2Yp-P"
   },
   "outputs": [],
   "source": [
    "def sum_output_shape(shapes):\n",
    "    #print(\"***********************\",shapes)\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1,1)\n",
    "\n",
    "def sum_fn(x):\n",
    "    return K.sum(x, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lnNqgHttmhUA"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmnduxpkoIUh"
   },
   "outputs": [],
   "source": [
    "# def cosine_focal_model2():\n",
    "#     #change 2\n",
    "#     input_1 = Input(shape=(197, 197, 3))\n",
    "#     input_2 = Input(shape=(197, 197, 3))\n",
    "\n",
    "#     base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "#     for x in base_model.layers[:-3]:\n",
    "#         x.trainable = True\n",
    "\n",
    "#     x1 = base_model(input_1)\n",
    "#     x2 = base_model(input_2)\n",
    "\n",
    "#     x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)])\n",
    "#     x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n",
    "\n",
    "#     x3 = Subtract()([x1, x2])\n",
    "#     x3 = Multiply()([x3, x3])\n",
    "#     x3 = Lambda(sum_fn, output_shape=sum_output_shape)(x3)\n",
    "\n",
    "#     x1_ = Multiply()([x1, x1])\n",
    "#     x2_ = Multiply()([x2, x2])\n",
    "#     x4 = Subtract()([x1_, x2_])\n",
    "#     x4 = Lambda(sum_fn, output_shape=sum_output_shape)(x4)\n",
    "    \n",
    "#     #https://stackoverflow.com/a/51003359/10650182\n",
    "#     x5 = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([x1, x2])\n",
    "    \n",
    "#     x = Concatenate(axis=-1)([x5,x4, x3, x1, x2])\n",
    "\n",
    "#     x = Dense(100, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.01)(x)\n",
    "#     out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "#     model = Model([input_1, input_2], out)\n",
    "\n",
    "#     model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc',auroc], optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True))\n",
    "\n",
    "#     model.summary()\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3exUq1QVYp3T"
   },
   "outputs": [],
   "source": [
    "def cosine_focal_model2():\n",
    "    #change 2\n",
    "    input_1 = Input(shape=(197, 197, 3))\n",
    "    input_2 = Input(shape=(197, 197, 3))\n",
    "\n",
    "    base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "\n",
    "    x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)])\n",
    "    x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n",
    "\n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "\n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #https://stackoverflow.com/a/51003359/10650182\n",
    "    x5 = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([x1, x2])\n",
    "    \n",
    "    x6 = Lambda(sum_fn, output_shape=sum_output_shape)(x3)\n",
    "    \n",
    "    x7 = Lambda(sum_fn, output_shape=sum_output_shape)(x4)\n",
    "    \n",
    "    \n",
    "    x = Concatenate(axis=-1)([x7, x6, x5,x4, x3])\n",
    "\n",
    "    x = Dense(200, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc',auroc], optimizer=Adam(0.00001))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MLIwuLBIb5t6"
   },
   "outputs": [],
   "source": [
    "#model = cosine_focal_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lykx1sK-cAhw",
    "outputId": "8dd51abf-d3bc-42a7-d91d-f5a863680a6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vggface_resnet50 (Model)        multiple             23561152    input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalM (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_4 (GlobalM (None, 2048)         0           vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 2048)         0           vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4096)         0           global_max_pooling2d_3[0][0]     \n",
      "                                                                 global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 4096)         0           global_max_pooling2d_4[0][0]     \n",
      "                                                                 global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 4096)         0           concatenate_4[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 4096)         0           concatenate_5[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 4096)         0           concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract_4 (Subtract)           (None, 4096)         0           multiply_5[0][0]                 \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 4096)         0           subtract_3[0][0]                 \n",
      "                                                                 subtract_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1)            0           subtract_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1)            0           concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8195)         0           lambda_6[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 subtract_4[0][0]                 \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 200)          1639200     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50)           10050       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            51          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 25,210,453\n",
      "Trainable params: 25,157,333\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"drive/My Drive/Face_recognition/vgg_face_cosine_focal_withvectors.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_auroc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_auroc\", mode=\"max\", factor=0.1, patience=10, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "model = cosine_focal_model2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interrupting the cell below because of score stuck at 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XAtq1OKEjHgU",
    "outputId": "619123f8-00a1-4d9d-f7a7-2d1a974ffe47"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 92/200 [============>.................] - ETA: 2:03 - loss: 32.2362 - acc: 0.5000 - auroc: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-48:\n",
      "Process ForkPoolWorker-45:\n",
      "Process ForkPoolWorker-41:\n",
      "Process ForkPoolWorker-43:\n",
      "Process ForkPoolWorker-46:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-44:\n",
      "Process ForkPoolWorker-42:\n",
      "Process ForkPoolWorker-47:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 626, in next_sample\n",
      "    return six.next(_SHARED_SEQUENCES[uid])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"<ipython-input-40-f112435959b0>\", line 28, in gen\n",
      "    X2 = np.array([read_img(x) for x in X2])\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"<ipython-input-40-f112435959b0>\", line 28, in <listcomp>\n",
      "    X2 = np.array([read_img(x) for x in X2])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-30-4a8ec4dc9549>\", line 4, in read_img\n",
      "    img = np.array(img).astype(np.float)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-8279149ad808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit_generator(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=True,\n\u001b[1;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_person_to_images_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=True,\n",
    "                    validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=100, verbose=1,\n",
    "                    workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "0v3TUvxfjXik",
    "outputId": "8892d291-929b-40fd-921e-db3c45f51c4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0807 02:10:21.755585 140385125271424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0807 02:10:21.804287 140385125271424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0807 02:10:21.813905 140385125271424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0807 02:10:21.857730 140385125271424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0807 02:10:21.859973 140385125271424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0807 02:10:24.812133 140385125271424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0807 02:10:24.901563 140385125271424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0807 02:10:30.425071 140385125271424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
      "94699520/94694792 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = VGGFace(model='resnet50', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yi3mWzBB_qJ7"
   },
   "outputs": [],
   "source": [
    "training_set = []\n",
    "training_labels = []\n",
    "ppl = list(train_person_to_images_map.keys())\n",
    "count = 0\n",
    "while(count !=3):\n",
    "    for p1,p2 in train:\n",
    "        #print(p1)\n",
    "        img1 = choice(train_person_to_images_map[p1])\n",
    "        img2 = choice(train_person_to_images_map[p2])\n",
    "\n",
    "        #print(base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)).shape)\n",
    "        training_set.append((base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)) - base_model.predict(np.expand_dims(np.array(read_img(img2)), axis=0)).reshape((2048)))**2)\n",
    "        training_labels.append(1)\n",
    "\n",
    "        flag = 0\n",
    "        while(flag == 0):\n",
    "            p1 = choice(ppl)\n",
    "            p2 = choice(ppl)\n",
    "\n",
    "            if p1 != p2 and (p1, p2) not in train and (p2, p1) not in train:\n",
    "                flag=1\n",
    "                img1 = choice(train_person_to_images_map[p1])\n",
    "                img2 = choice(train_person_to_images_map[p2])\n",
    "                #print(base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)).shape)\n",
    "                training_set.append((base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)) - base_model.predict(np.expand_dims(np.array(read_img(img2)), axis=0)).reshape((2048)))**2)\n",
    "                training_labels.append(0)\n",
    "    count+=1\n",
    "training_set = np.array(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-1mPTxdUxZO"
   },
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulgSOYxTTx2R"
   },
   "outputs": [],
   "source": [
    "training_sim_metrics = []\n",
    "training_set = []\n",
    "training_labels = []\n",
    "ppl = list(train_person_to_images_map.keys())\n",
    "count = 0\n",
    "while(count !=3):\n",
    "    for p1,p2 in train:\n",
    "        #print(p1)\n",
    "        img1 = choice(train_person_to_images_map[p1])\n",
    "        img2 = choice(train_person_to_images_map[p2])\n",
    "\n",
    "        #print(base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)).shape)\n",
    "        pred1 = base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048))\n",
    "        pred2 = base_model.predict(np.expand_dims(np.array(read_img(img2)), axis=0)).reshape((2048))\n",
    "        \n",
    "        training_sim_metrics.append([np.sum((pred1-pred2)**2), np.sum((pred1**2 - pred2**2)), 1 - spatial.distance.cosine(pred1, pred2)] )\n",
    "        training_set.append((pred1-pred2)**2)\n",
    "        training_labels.append(1)\n",
    "\n",
    "        flag = 0\n",
    "        while(flag == 0):\n",
    "            p1 = choice(ppl)\n",
    "            p2 = choice(ppl)\n",
    "\n",
    "            if p1 != p2 and (p1, p2) not in train and (p2, p1) not in train:\n",
    "                flag=1\n",
    "                img1 = choice(train_person_to_images_map[p1])\n",
    "                img2 = choice(train_person_to_images_map[p2])\n",
    "                #print(base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)).shape)\n",
    "                #training_set.append((base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048)) - base_model.predict(np.expand_dims(np.array(read_img(img2)), axis=0)).reshape((2048)))**2)\n",
    "                \n",
    "                pred1 = base_model.predict(np.expand_dims(np.array(read_img(img1)), axis=0)).reshape((2048))\n",
    "                pred2 = base_model.predict(np.expand_dims(np.array(read_img(img2)), axis=0)).reshape((2048))\n",
    "        \n",
    "                training_sim_metrics.append([np.sum((pred1-pred2)**2), np.sum((pred1**2 - pred2**2)), 1 - spatial.distance.cosine(pred1, pred2)] )\n",
    "                training_set.append((pred1-pred2)**2)\n",
    "                training_labels.append(0)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fsp8mab0dhe6"
   },
   "outputs": [],
   "source": [
    "training_set = np.array(training_set)\n",
    "training_sim_metrics = np.array(training_sim_metrics)\n",
    "training_labels = np.array(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L1VjDwpWN96d",
    "outputId": "44098718-e05e-4f42-95ef-c280f3264691"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.86470840e+04, -6.60191211e+03,  2.22686201e-01])"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sim_metrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "OI8vJKjqzetd",
    "outputId": "f1c04953-4f5d-4d5d-ee43-96734b6573e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18396, 2048)\n",
      "(18396, 3)\n",
      "(18396,)\n"
     ]
    }
   ],
   "source": [
    "print(training_set.shape)\n",
    "print(training_sim_metrics.shape)\n",
    "print(training_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5kfOrdHFsDJ"
   },
   "outputs": [],
   "source": [
    "X_train = np.column_stack((training_set, training_sim_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JqkwdzYiAWUV",
    "outputId": "5fdb077b-226c-49cc-a5d5-a381a1bc9319"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/drive/My Drive/Face_recognition/y_train2']"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X_train,\"/content/drive/My Drive/Face_recognition/X_train2\")\n",
    "joblib.dump(training_labels,\"/content/drive/My Drive/Face_recognition/y_train2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2K8WUMTLQyB"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Nha2lsDLS4Y"
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "R9g6aWmrKDqH",
    "outputId": "b285f929-6242-45cd-a7a0-25d00ab8be48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6sMzi0LEL2Vv"
   },
   "outputs": [],
   "source": [
    "train_proba = xgb.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41i3ILKbaQOD"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KrhdD-AsaVJb",
    "outputId": "fae8a790-8eca-40e9-accd-4fecdb222071"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8655705344208948"
      ]
     },
     "execution_count": 117,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(training_labels, train_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UXr1EYN_aexN"
   },
   "outputs": [],
   "source": [
    "test_path = \"drive/My Drive/Face_recognition/test/\"\n",
    "X_test = []\n",
    "for img_pair in submission['img_pair'].values:\n",
    "    x1 = img_pair.split('-')[0]\n",
    "    x1 = np.array(read_img(test_path + x1))\n",
    "    x1 = base_model.predict(np.expand_dims(x1,axis=0)).reshape(2048)\n",
    "    x2 = img_pair.split('-')[1]\n",
    "    x2 = np.array(read_img(test_path + x2))\n",
    "    x2 = base_model.predict(np.expand_dims(x2,axis=0)).reshape(2048)\n",
    "    \n",
    "    dis = np.sum((x1-x2)**2)\n",
    "    euc = np.sum(x1**2 - x2**2)\n",
    "    cosine = 1-spatial.distance.cosine(x1,x2)\n",
    "    \n",
    "    ip = np.concatenate(((x1-x2)**2, [dis,euc,cosine]))\n",
    "    X_test.append(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWOwrIRAdfSa"
   },
   "outputs": [],
   "source": [
    "test_proba = xgb.predict_proba(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYrTQcCJpkOC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YEywfzaxdlgC"
   },
   "outputs": [],
   "source": [
    "submission['is_related'] =test_proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uKipeI90pc2i"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"/content/drive/My Drive/Face_recognition/sub_6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rx9XMaNrp2TC"
   },
   "outputs": [],
   "source": [
    "sub_files = ['/content/drive/My Drive/Face_recognition/cosine_focal_submission.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/cosine_focal_submission2.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/cosine_submission.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/cosine_submission2.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/xgbpred.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/sub_6.csv'\n",
    "        ]\n",
    "scores = []\n",
    "for f in sub_files:\n",
    "    d = pd.read_csv(f)\n",
    "    scores.append(np.array(d['is_related']))\n",
    "scores = np.array(scores)\n",
    "submission = pd.read_csv('/content/drive/My Drive/Face_recognition/sample_submission.csv')\n",
    "submission['is_related'] = np.sum(scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2-mkOuEqrNv"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"/content/drive/My Drive/Face_recognition/sub_7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9jLVPKCAqtnY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9BhFGjM0QJM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hukzk4S0QBf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w0TZ3HMm0P6i"
   },
   "outputs": [],
   "source": [
    "sub_files = ['/content/drive/My Drive/Face_recognition/cosine_focal_submission.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/cosine_focal_submission2.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/cosine_submission.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/cosine_submission2.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/xgbpred.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/sub_6.csv',\n",
    "         '/content/drive/My Drive/Face_recognition/vgg_face (2) (1).csv'\n",
    "        ]\n",
    "scores = []\n",
    "for f in sub_files:\n",
    "    d = pd.read_csv(f)\n",
    "    scores.append(np.array(d['is_related']))\n",
    "scores = np.array(scores)\n",
    "submission = pd.read_csv('/content/drive/My Drive/Face_recognition/sample_submission.csv')\n",
    "submission['is_related'] = np.sum(scores, axis=0)\n",
    "submission.to_csv(\"/content/drive/My Drive/Face_recognition/sub_9.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xvkzld4F0M0L"
   },
   "outputs": [],
   "source": [
    "def cosine_focal_model3():\n",
    "    #change 2\n",
    "    input_1 = Input(shape=(197, 197, 3))\n",
    "    input_2 = Input(shape=(197, 197, 3))\n",
    "\n",
    "    base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "\n",
    "    x1 = GlobalMaxPool2D()(x1)\n",
    "    x2 = GlobalMaxPool2D()(x2)\n",
    "\n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "    #x3 = Dense(100, activation = 'relu')(x3)\n",
    "\n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    #x4 = Dense(100, activation = 'relu')(x4)\n",
    "    \n",
    "    \n",
    "    #https://stackoverflow.com/a/51003359/10650182\n",
    "    x5 = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([x1, x2])\n",
    "    #x5 = Dense(100, activation = 'relu')(x5)\n",
    "    \n",
    "    x = Concatenate(axis=-1)([x5,x4, x3])\n",
    "\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc',auroc], optimizer=Adam(0.0001))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6Rk9JylHIFF-",
    "outputId": "1199f1d4-5d21-4818-fff7-054cb29c6964"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0808 02:48:49.752418 139852148569984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0808 02:48:49.814620 139852148569984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0808 02:48:49.825923 139852148569984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0808 02:48:49.865954 139852148569984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0808 02:48:49.867467 139852148569984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0808 02:48:52.728067 139852148569984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0808 02:48:52.820637 139852148569984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0808 02:48:58.341189 139852148569984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
      "94699520/94694792 [==============================] - 8s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0808 02:49:19.382060 139852148569984 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0808 02:49:19.432348 139852148569984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0808 02:49:19.441350 139852148569984 deprecation.py:323] From <ipython-input-42-fdd85ade61a6>:4: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0808 02:49:19.480211 139852148569984 deprecation.py:323] From <ipython-input-2-bc412d992b42>:14: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vggface_resnet50 (Model)        multiple             23561152    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (None, 2048)         0           vggface_resnet50[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 2048)         0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_max_pooling2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 2048)         0           global_max_pooling2d_2[0][0]     \n",
      "                                                                 global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 2048)         0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 2048)         0           multiply_2[0][0]                 \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 2048)         0           subtract_1[0][0]                 \n",
      "                                                                 subtract_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4097)         0           lambda_1[0][0]                   \n",
      "                                                                 subtract_2[0][0]                 \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          1049088     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,610,497\n",
      "Trainable params: 24,557,377\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "file_path = \"drive/My Drive/Face_recognition/vgg_face_cosine_focal3\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.1, patience=10, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "model = cosine_focal_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4cKwss6hINYX",
    "outputId": "81c6614e-c21f-4184-f2f2-5806045733e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 402s 2s/step - loss: 6.9778 - acc: 0.5619 - auroc: 0.6318 - val_loss: 1.3286 - val_acc: 0.6156 - val_auroc: 0.6855\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.61562, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal3\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 205s 1s/step - loss: 1.1079 - acc: 0.6003 - auroc: 0.7245 - val_loss: 1.0724 - val_acc: 0.6169 - val_auroc: 0.7367\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.61562 to 0.61687, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal3\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 187s 934ms/step - loss: 1.0102 - acc: 0.6006 - auroc: 0.7585 - val_loss: 0.9616 - val_acc: 0.6169 - val_auroc: 0.7758\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.61687\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 187s 934ms/step - loss: 0.9370 - acc: 0.6312 - auroc: 0.8016 - val_loss: 0.9171 - val_acc: 0.6531 - val_auroc: 0.8058\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.61687 to 0.65312, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal3\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 187s 934ms/step - loss: 0.9144 - acc: 0.6331 - auroc: 0.8035 - val_loss: 0.9080 - val_acc: 0.6706 - val_auroc: 0.8027\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.65312 to 0.67063, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal3\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 187s 935ms/step - loss: 0.8559 - acc: 0.6750 - auroc: 0.8342 - val_loss: 0.8771 - val_acc: 0.6744 - val_auroc: 0.8242\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.67063 to 0.67437, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal3\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 187s 933ms/step - loss: 0.8852 - acc: 0.6550 - auroc: 0.8178 - val_loss: 0.8263 - val_acc: 0.6981 - val_auroc: 0.8512\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.67437 to 0.69812, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal3\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 187s 936ms/step - loss: 0.8371 - acc: 0.6712 - auroc: 0.8426 - val_loss: 0.8656 - val_acc: 0.6769 - val_auroc: 0.8281\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.69812\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 186s 929ms/step - loss: 0.8020 - acc: 0.7069 - auroc: 0.8620 - val_loss: 0.9071 - val_acc: 0.6562 - val_auroc: 0.8117\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.69812\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 186s 929ms/step - loss: 0.8246 - acc: 0.6931 - auroc: 0.8449 - val_loss: 0.8859 - val_acc: 0.6725 - val_auroc: 0.8209\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.69812\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 185s 927ms/step - loss: 0.8139 - acc: 0.6909 - auroc: 0.8525 - val_loss: 0.8392 - val_acc: 0.6925 - val_auroc: 0.8425\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.69812\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 186s 931ms/step - loss: 0.7924 - acc: 0.7025 - auroc: 0.8622 - val_loss: 0.8962 - val_acc: 0.6969 - val_auroc: 0.8134\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.69812\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 186s 931ms/step - loss: 0.7834 - acc: 0.7159 - auroc: 0.8700 - val_loss: 0.9325 - val_acc: 0.6737 - val_auroc: 0.8044\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.69812\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 186s 930ms/step - loss: 0.7832 - acc: 0.7188 - auroc: 0.8673 - val_loss: 0.8245 - val_acc: 0.6850 - val_auroc: 0.8497\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.69812\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 186s 930ms/step - loss: 0.7748 - acc: 0.7241 - auroc: 0.8674 - val_loss: 0.8757 - val_acc: 0.6763 - val_auroc: 0.8195\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.69812\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 186s 931ms/step - loss: 0.7856 - acc: 0.7097 - auroc: 0.8642 - val_loss: 0.8533 - val_acc: 0.6906 - val_auroc: 0.8372\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.69812\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 186s 930ms/step - loss: 0.7777 - acc: 0.7097 - auroc: 0.8667 - val_loss: 0.9929 - val_acc: 0.6706 - val_auroc: 0.7853\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.69812\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 187s 933ms/step - loss: 0.7664 - acc: 0.7056 - auroc: 0.8676 - val_loss: 0.8233 - val_acc: 0.6863 - val_auroc: 0.8533\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.69812\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 187s 933ms/step - loss: 0.6993 - acc: 0.7469 - auroc: 0.8971 - val_loss: 0.8214 - val_acc: 0.7144 - val_auroc: 0.8538\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.69812 to 0.71437, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal3\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 186s 931ms/step - loss: 0.6834 - acc: 0.7538 - auroc: 0.9052 - val_loss: 0.8000 - val_acc: 0.7238 - val_auroc: 0.8652\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.71437 to 0.72375, saving model to drive/My Drive/Face_recognition/vgg_face_cosine_focal3\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 187s 936ms/step - loss: 0.6606 - acc: 0.7672 - auroc: 0.9134 - val_loss: 0.8360 - val_acc: 0.6881 - val_auroc: 0.8472\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.72375\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 186s 929ms/step - loss: 0.6606 - acc: 0.7647 - auroc: 0.9093 - val_loss: 0.8114 - val_acc: 0.6963 - val_auroc: 0.8573\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.72375\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 185s 926ms/step - loss: 0.6453 - acc: 0.7738 - auroc: 0.9127 - val_loss: 0.8298 - val_acc: 0.7031 - val_auroc: 0.8541\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.72375\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 187s 933ms/step - loss: 0.6066 - acc: 0.7844 - auroc: 0.9270 - val_loss: 0.8578 - val_acc: 0.7169 - val_auroc: 0.8619\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.72375\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 186s 930ms/step - loss: 0.6216 - acc: 0.7916 - auroc: 0.9234 - val_loss: 0.8558 - val_acc: 0.7069 - val_auroc: 0.8491\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.72375\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 186s 931ms/step - loss: 0.6061 - acc: 0.8087 - auroc: 0.9227 - val_loss: 0.7885 - val_acc: 0.7212 - val_auroc: 0.8709\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.72375\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.6030 - acc: 0.8050 - auroc: 0.9279 - val_loss: 0.7880 - val_acc: 0.7225 - val_auroc: 0.8694\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.72375\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 187s 934ms/step - loss: 0.6059 - acc: 0.8003 - auroc: 0.9245 - val_loss: 0.8529 - val_acc: 0.6963 - val_auroc: 0.8584\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.72375\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 186s 931ms/step - loss: 0.5975 - acc: 0.8056 - auroc: 0.9270 - val_loss: 0.8391 - val_acc: 0.7000 - val_auroc: 0.8659\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.72375\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 187s 933ms/step - loss: 0.5739 - acc: 0.8191 - auroc: 0.9346 - val_loss: 0.8885 - val_acc: 0.7144 - val_auroc: 0.8508\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.72375\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 187s 934ms/step - loss: 0.5713 - acc: 0.8122 - auroc: 0.9348 - val_loss: 0.8676 - val_acc: 0.7013 - val_auroc: 0.8573\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.72375\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.5690 - acc: 0.8116 - auroc: 0.9380 - val_loss: 0.8937 - val_acc: 0.6994 - val_auroc: 0.8509\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.72375\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 187s 934ms/step - loss: 0.5745 - acc: 0.8166 - auroc: 0.9334 - val_loss: 0.7915 - val_acc: 0.7225 - val_auroc: 0.8748\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.72375\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.5455 - acc: 0.8184 - auroc: 0.9427 - val_loss: 0.8773 - val_acc: 0.7087 - val_auroc: 0.8583\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.72375\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 187s 934ms/step - loss: 0.5885 - acc: 0.8169 - auroc: 0.9325 - val_loss: 0.8599 - val_acc: 0.6919 - val_auroc: 0.8572\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.72375\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.5320 - acc: 0.8200 - auroc: 0.9451 - val_loss: 0.8372 - val_acc: 0.7081 - val_auroc: 0.8558\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.72375\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 187s 934ms/step - loss: 0.5743 - acc: 0.8225 - auroc: 0.9357 - val_loss: 0.8118 - val_acc: 0.7238 - val_auroc: 0.8752\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.72375\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.5628 - acc: 0.8103 - auroc: 0.9370 - val_loss: 0.8597 - val_acc: 0.6963 - val_auroc: 0.8597\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.72375\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 187s 933ms/step - loss: 0.5767 - acc: 0.8116 - auroc: 0.9308 - val_loss: 0.8405 - val_acc: 0.7131 - val_auroc: 0.8527\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.72375\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 186s 929ms/step - loss: 0.5381 - acc: 0.8262 - auroc: 0.9436 - val_loss: 0.8823 - val_acc: 0.7031 - val_auroc: 0.8494\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.72375\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 186s 930ms/step - loss: 0.5740 - acc: 0.8103 - auroc: 0.9320 - val_loss: 0.8765 - val_acc: 0.7087 - val_auroc: 0.8639\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.72375\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 186s 930ms/step - loss: 0.5592 - acc: 0.8103 - auroc: 0.9373 - val_loss: 0.8509 - val_acc: 0.7125 - val_auroc: 0.8633\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.72375\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 186s 931ms/step - loss: 0.5460 - acc: 0.8134 - auroc: 0.9402 - val_loss: 0.8463 - val_acc: 0.7031 - val_auroc: 0.8620\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.72375\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 186s 931ms/step - loss: 0.5529 - acc: 0.8156 - auroc: 0.9388 - val_loss: 0.8554 - val_acc: 0.6919 - val_auroc: 0.8528\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.72375\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.5507 - acc: 0.8212 - auroc: 0.9364 - val_loss: 0.8857 - val_acc: 0.7000 - val_auroc: 0.8522\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.72375\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 187s 935ms/step - loss: 0.5771 - acc: 0.8097 - auroc: 0.9330 - val_loss: 0.8279 - val_acc: 0.7194 - val_auroc: 0.8642\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.72375\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 186s 931ms/step - loss: 0.5310 - acc: 0.8262 - auroc: 0.9441 - val_loss: 0.8683 - val_acc: 0.7137 - val_auroc: 0.8555\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.72375\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 187s 933ms/step - loss: 0.5286 - acc: 0.8247 - auroc: 0.9427 - val_loss: 0.8418 - val_acc: 0.7131 - val_auroc: 0.8639\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.72375\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.5552 - acc: 0.8272 - auroc: 0.9391 - val_loss: 0.8552 - val_acc: 0.7163 - val_auroc: 0.8800\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.72375\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 187s 933ms/step - loss: 0.5416 - acc: 0.8225 - auroc: 0.9390 - val_loss: 0.8342 - val_acc: 0.7194 - val_auroc: 0.8650\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.72375\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 187s 934ms/step - loss: 0.5410 - acc: 0.8300 - auroc: 0.9459 - val_loss: 0.8911 - val_acc: 0.6919 - val_auroc: 0.8453\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.72375\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.5467 - acc: 0.8187 - auroc: 0.9426 - val_loss: 0.7933 - val_acc: 0.7181 - val_auroc: 0.8794\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.72375\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 187s 935ms/step - loss: 0.5264 - acc: 0.8253 - auroc: 0.9459 - val_loss: 0.8080 - val_acc: 0.7219 - val_auroc: 0.8780\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.72375\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.5781 - acc: 0.8087 - auroc: 0.9331 - val_loss: 0.8174 - val_acc: 0.7131 - val_auroc: 0.8653\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.72375\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 187s 934ms/step - loss: 0.5697 - acc: 0.8150 - auroc: 0.9342 - val_loss: 0.8625 - val_acc: 0.6994 - val_auroc: 0.8642\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.72375\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 186s 931ms/step - loss: 0.5160 - acc: 0.8369 - auroc: 0.9481 - val_loss: 0.8362 - val_acc: 0.7081 - val_auroc: 0.8575\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.72375\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 187s 937ms/step - loss: 0.5564 - acc: 0.8197 - auroc: 0.9364 - val_loss: 0.8308 - val_acc: 0.7156 - val_auroc: 0.8636\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.72375\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.5519 - acc: 0.8113 - auroc: 0.9384 - val_loss: 0.8532 - val_acc: 0.7050 - val_auroc: 0.8580\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.72375\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.5433 - acc: 0.8309 - auroc: 0.9428 - val_loss: 0.8261 - val_acc: 0.7063 - val_auroc: 0.8681\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.72375\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 187s 937ms/step - loss: 0.5560 - acc: 0.8156 - auroc: 0.9373 - val_loss: 0.7873 - val_acc: 0.7194 - val_auroc: 0.8725\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.72375\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 187s 937ms/step - loss: 0.5538 - acc: 0.8244 - auroc: 0.9390 - val_loss: 0.8442 - val_acc: 0.7113 - val_auroc: 0.8667\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.72375\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 188s 942ms/step - loss: 0.5387 - acc: 0.8259 - auroc: 0.9416 - val_loss: 0.8312 - val_acc: 0.6894 - val_auroc: 0.8666\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.72375\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 188s 938ms/step - loss: 0.5523 - acc: 0.8237 - auroc: 0.9363 - val_loss: 0.8176 - val_acc: 0.7081 - val_auroc: 0.8719\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.72375\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 188s 939ms/step - loss: 0.5752 - acc: 0.8041 - auroc: 0.9339 - val_loss: 0.8575 - val_acc: 0.7144 - val_auroc: 0.8628\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.72375\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 188s 940ms/step - loss: 0.5441 - acc: 0.8313 - auroc: 0.9434 - val_loss: 0.8482 - val_acc: 0.7137 - val_auroc: 0.8514\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.72375\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 188s 939ms/step - loss: 0.5482 - acc: 0.8241 - auroc: 0.9406 - val_loss: 0.8409 - val_acc: 0.6994 - val_auroc: 0.8642\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.72375\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 188s 939ms/step - loss: 0.5508 - acc: 0.8237 - auroc: 0.9411 - val_loss: 0.8373 - val_acc: 0.7169 - val_auroc: 0.8708\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.72375\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 188s 939ms/step - loss: 0.5566 - acc: 0.8219 - auroc: 0.9369 - val_loss: 0.7840 - val_acc: 0.7156 - val_auroc: 0.8708\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.72375\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 188s 940ms/step - loss: 0.5477 - acc: 0.8244 - auroc: 0.9401 - val_loss: 0.8822 - val_acc: 0.6869 - val_auroc: 0.8466\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.72375\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 188s 939ms/step - loss: 0.5532 - acc: 0.8256 - auroc: 0.9415 - val_loss: 0.8326 - val_acc: 0.7219 - val_auroc: 0.8683\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.72375\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 188s 938ms/step - loss: 0.5425 - acc: 0.8269 - auroc: 0.9405 - val_loss: 0.8282 - val_acc: 0.7175 - val_auroc: 0.8666\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.72375\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 188s 938ms/step - loss: 0.5356 - acc: 0.8262 - auroc: 0.9455 - val_loss: 0.8355 - val_acc: 0.7119 - val_auroc: 0.8739\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.72375\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 188s 940ms/step - loss: 0.5602 - acc: 0.8216 - auroc: 0.9355 - val_loss: 0.8431 - val_acc: 0.7125 - val_auroc: 0.8680\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.72375\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 188s 938ms/step - loss: 0.5614 - acc: 0.8256 - auroc: 0.9397 - val_loss: 0.8567 - val_acc: 0.7131 - val_auroc: 0.8683\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.72375\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 188s 938ms/step - loss: 0.5562 - acc: 0.8228 - auroc: 0.9395 - val_loss: 0.8114 - val_acc: 0.7106 - val_auroc: 0.8752\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.72375\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 187s 936ms/step - loss: 0.5581 - acc: 0.8225 - auroc: 0.9405 - val_loss: 0.8118 - val_acc: 0.7238 - val_auroc: 0.8777\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.72375\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 188s 938ms/step - loss: 0.5292 - acc: 0.8228 - auroc: 0.9452 - val_loss: 0.8156 - val_acc: 0.7087 - val_auroc: 0.8670\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.72375\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 187s 935ms/step - loss: 0.5725 - acc: 0.8175 - auroc: 0.9331 - val_loss: 0.8138 - val_acc: 0.7113 - val_auroc: 0.8753\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.72375\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 187s 937ms/step - loss: 0.5447 - acc: 0.8294 - auroc: 0.9419 - val_loss: 0.8327 - val_acc: 0.7188 - val_auroc: 0.8684\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.72375\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 187s 935ms/step - loss: 0.5510 - acc: 0.8191 - auroc: 0.9376 - val_loss: 0.8037 - val_acc: 0.7219 - val_auroc: 0.8823\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.72375\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 187s 936ms/step - loss: 0.5581 - acc: 0.8156 - auroc: 0.9382 - val_loss: 0.8861 - val_acc: 0.6863 - val_auroc: 0.8531\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.72375\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 187s 937ms/step - loss: 0.5484 - acc: 0.8166 - auroc: 0.9421 - val_loss: 0.8547 - val_acc: 0.7156 - val_auroc: 0.8672\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.72375\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 187s 935ms/step - loss: 0.5336 - acc: 0.8281 - auroc: 0.9445 - val_loss: 0.8406 - val_acc: 0.7044 - val_auroc: 0.8506\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.72375\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 187s 936ms/step - loss: 0.5061 - acc: 0.8372 - auroc: 0.9526 - val_loss: 0.8592 - val_acc: 0.7013 - val_auroc: 0.8573\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.72375\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.5371 - acc: 0.8244 - auroc: 0.9414 - val_loss: 0.8570 - val_acc: 0.6913 - val_auroc: 0.8642\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.72375\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 187s 934ms/step - loss: 0.5504 - acc: 0.8200 - auroc: 0.9420 - val_loss: 0.8980 - val_acc: 0.7013 - val_auroc: 0.8494\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.72375\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 187s 936ms/step - loss: 0.5382 - acc: 0.8334 - auroc: 0.9437 - val_loss: 0.9206 - val_acc: 0.7100 - val_auroc: 0.8520\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.72375\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 188s 938ms/step - loss: 0.5294 - acc: 0.8294 - auroc: 0.9451 - val_loss: 0.8550 - val_acc: 0.7006 - val_auroc: 0.8606\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.72375\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 187s 934ms/step - loss: 0.5472 - acc: 0.8219 - auroc: 0.9395 - val_loss: 0.8328 - val_acc: 0.6956 - val_auroc: 0.8656\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.72375\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 187s 936ms/step - loss: 0.5396 - acc: 0.8228 - auroc: 0.9425 - val_loss: 0.8425 - val_acc: 0.6963 - val_auroc: 0.8606\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.72375\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 187s 937ms/step - loss: 0.5543 - acc: 0.8222 - auroc: 0.9377 - val_loss: 0.8983 - val_acc: 0.6875 - val_auroc: 0.8545\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.72375\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 187s 936ms/step - loss: 0.5642 - acc: 0.8187 - auroc: 0.9331 - val_loss: 0.8144 - val_acc: 0.7106 - val_auroc: 0.8697\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.72375\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 187s 933ms/step - loss: 0.5533 - acc: 0.8269 - auroc: 0.9423 - val_loss: 0.8878 - val_acc: 0.6956 - val_auroc: 0.8505\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.72375\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 187s 934ms/step - loss: 0.5597 - acc: 0.8159 - auroc: 0.9355 - val_loss: 0.8716 - val_acc: 0.7013 - val_auroc: 0.8517\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.72375\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 187s 935ms/step - loss: 0.5302 - acc: 0.8284 - auroc: 0.9456 - val_loss: 0.8853 - val_acc: 0.7019 - val_auroc: 0.8514\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.72375\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 187s 935ms/step - loss: 0.5463 - acc: 0.8306 - auroc: 0.9402 - val_loss: 0.8397 - val_acc: 0.7063 - val_auroc: 0.8742\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.72375\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 187s 935ms/step - loss: 0.5458 - acc: 0.8209 - auroc: 0.9387 - val_loss: 0.8701 - val_acc: 0.7056 - val_auroc: 0.8573\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.72375\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.5517 - acc: 0.8113 - auroc: 0.9373 - val_loss: 0.8511 - val_acc: 0.7094 - val_auroc: 0.8648\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.72375\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 186s 932ms/step - loss: 0.5393 - acc: 0.8281 - auroc: 0.9425 - val_loss: 0.8495 - val_acc: 0.7069 - val_auroc: 0.8633\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.72375\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 186s 930ms/step - loss: 0.5476 - acc: 0.8234 - auroc: 0.9415 - val_loss: 0.8191 - val_acc: 0.7075 - val_auroc: 0.8755\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.72375\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3182612da0>"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=True,\n",
    "                    validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=100, verbose=1,\n",
    "                    workers = 4, callbacks=callbacks_list, steps_per_epoch=200, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_3T63w2IVyA"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"drive/My Drive/Face_recognition/vgg_face_cosine_focal3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oV-kgP65YyuL"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc',auroc], optimizer=Adam(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OCAaRsDHZhG0",
    "outputId": "7b344617-f88b-40a2-e77c-ae677803db92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166it [34:41,  9.47s/it]\n"
     ]
    }
   ],
   "source": [
    "test_path = \"drive/My Drive/Face_recognition/test/\"\n",
    "def chunker(seq, size=32):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "submission = pd.read_csv('drive/My Drive/Face_recognition/sample_submission.csv')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in tqdm(chunker(submission.img_pair.values)):\n",
    "    X1 = [x.split(\"-\")[0] for x in batch]\n",
    "    X1 = np.array([read_img(test_path + x) for x in X1])\n",
    "\n",
    "    X2 = [x.split(\"-\")[1] for x in batch]\n",
    "    X2 = np.array([read_img(test_path + x) for x in X2])\n",
    "\n",
    "    pred = model.predict([X1, X2]).ravel().tolist()\n",
    "    predictions += pred\n",
    "\n",
    "submission['is_related'] = predictions\n",
    "\n",
    "submission.to_csv(\"drive/My Drive/Face_recognition/cosine_focal_submission3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNaXnURrZqkm"
   },
   "outputs": [],
   "source": [
    "sub_files = ['/content/drive/My Drive/Face_recognition/cosine_focal_submission.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/cosine_focal_submission2.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/cosine_submission.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/cosine_submission2.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/xgbpred.csv',\n",
    "        '/content/drive/My Drive/Face_recognition/sub_6.csv',\n",
    "         '/content/drive/My Drive/Face_recognition/vgg_face (2).csv',\n",
    "         \"drive/My Drive/Face_recognition/cosine_focal_submission3.csv\"\n",
    "        ]\n",
    "scores = []\n",
    "for f in sub_files:\n",
    "    d = pd.read_csv(f)\n",
    "    scores.append(np.array(d['is_related']))\n",
    "scores = np.array(scores)\n",
    "submission = pd.read_csv('/content/drive/My Drive/Face_recognition/sample_submission.csv')\n",
    "submission['is_related'] = np.sum(scores, axis=0)\n",
    "submission.to_csv(\"/content/drive/My Drive/Face_recognition/sub_10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r4RRpYB6peCP"
   },
   "source": [
    "#### Final Best Score on kaggle leaderbaord: 0.908\n",
    "#### LB rank: 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyper\n",
      "  Downloading https://files.pythonhosted.org/packages/96/c3/e77072050a8d3a22255695d0cd7fde19bfe962364a6f6870ef47a9f9f66b/hyper-0.7.0-py2.py3-none-any.whl (269kB)\n",
      "Collecting h2<3.0,>=2.4 (from hyper)\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/8b/8d5610e8ddbcde6d014907526b4c6c294520a7233fc456d7be1fcade3bbc/h2-2.6.2-py2.py3-none-any.whl (71kB)\n",
      "Collecting hyperframe<4.0,>=3.2 (from hyper)\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/89/44ff46f15dba53a8c16cb8cab89ecb1e44f8aa211628b43d341004cfcf7a/hyperframe-3.2.0-py2.py3-none-any.whl\n",
      "Collecting hpack<4,>=2.2 (from h2<3.0,>=2.4->hyper)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
      "Installing collected packages: hpack, hyperframe, h2, hyper\n",
      "Successfully installed h2-2.6.2 hpack-3.0.0 hyper-0.7.0 hyperframe-3.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/f0/a22d41d3846d1f46a4f20086141e0428ccc9c6d644aacbfd30990cf46886/googletrans-2.4.0.tar.gz\n",
      "Requirement already satisfied: requests in c:\\users\\prabh\\anaconda3\\lib\\site-packages (from googletrans) (2.21.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\prabh\\anaconda3\\lib\\site-packages (from requests->googletrans) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prabh\\anaconda3\\lib\\site-packages (from requests->googletrans) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\prabh\\anaconda3\\lib\\site-packages (from requests->googletrans) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\prabh\\anaconda3\\lib\\site-packages (from requests->googletrans) (1.24.1)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py): started\n",
      "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-2.4.0-cp37-none-any.whl size=15782 sha256=7c75aa6e8ee21bc5f6a73b714d9d9ba5a462a6fbeed0c1d699caa03d4af3fc54\n",
      "  Stored in directory: C:\\Users\\prabh\\AppData\\Local\\pip\\Cache\\wheels\\50\\d6\\e7\\a8efd5f2427d5eb258070048718fa56ee5ac57fd6f53505f95\n",
      "Successfully built googletrans\n",
      "Installing collected packages: googletrans\n",
      "Successfully installed googletrans-2.4.0\n"
     ]
    }
   ],
   "source": [
    "! pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t = translator.translate(\"এই সময় ডিজিটাল ডেস্ক: দেশের প্রত্যন্ত গ্রামের অতি সাধারণ একটি স্কুলকে 'অসাধারণ' হিসেবে গড়ে তুলে বিশ্বের সেরা শিক্ষক হলেন কেনিয়ার এক শিক্ষক। সম্প্রতি দুবাইয়ে তাঁর হাতে পুরস্কার এবং ১০ লক্ষ মার্কিন ডলার অর্থ তুলে দেওয়া হয়েছে। কেনিয়ার শুষ্ক রিফট উপত্যকার প্রত্যন্ত গ্রাম পওয়ানি। এই গ্রামের কেরিকো মিক্সড ডে সেকেন্ডারি স্কুলে অঙ্ক এবং পদার্থবিদ্যার শিক্ষক হিসেবে যোগ দিয়েছিলেন পিটার তাবিচি। এই স্কুলের ৯০ শতাংশ পড়ুয়া অতি দরিদ্র পরিবার থেকে উঠে আসা। এক সময় যেখানে পড়াশোনার বুনিয়াদি সুযোগ সুবিধা পর্যন্ত ছিল না সম্প্রতি সেই স্কুল জাতীয় বিজ্ঞান প্রতিযোগিতায় সেরা হয়েছে। আর স্কুলের এই সাফল্যের মূল কারিগর ৩৬ বছর বয়সী অংক এবং পদার্থবিদ্যার শিক্ষক তাবিচি। গ্লোবাল টিটার প্রাইজ ফর ২০১৯-এর আয়োজক ভারকি ফাউন্ডেশনের তরফে জানানো হয়েছে, মাসিক আয়ের ৮০ শতাংশ অর্থ দরিদ্রদের মধ্যে বিলিয়ে দেন পিটার তাবিচি। রিফট উপত্যকার যে গ্রামে খরা এবং দুর্ভিক্ষ নিয়মিত ঘটনা সেখানকার একটি স্কুলকে দেশের মধ্যে সেরা স্কুল হিসেবে তুলে ধরার স্বীকৃতি হিসেবে পিটার তাবিচিকে পুরস্কৃত করা হয়েছে। পুরস্কার গ্রহণের পরে তাবিচ বলেছেন, 'আফ্রিকায় আমরা প্রতি দিন নতুন পৃষ্ঠা এবং নতুন অধ্যায় যুক্ত করছি। এই পুরস্কার আমাকে নয়, বরং এই মহাদেশের তরুণ যুবককের প্রচেষ্টাকে স্বীকৃতি দিল। আমার স্কুলর পড়ুয়াদের সাফল্যের কারণে আজ আমি এখানে দাঁড়িয়ে আছি।\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This time the digital desk: Kenya\\'s teacher is one of the best teachers in the world, setting up a very ordinary school in a remote village in the country. He was recently given a prize and $ 1 million in Dubai in Dubai. Pawani, a remote village in Kenya\\'s dry rift valley. Peter Tabichi joined Carrick Mixed Day Secondary School as a math and physics teacher in this village. Five percent of the students in this school come from very poor families. At a time when the basics of study were not up to the mark, the school recently excelled in the national science competition. And the key to this school\\'s success is the 4-year-old marksman and physics teacher Tabichi. According to the Varki Foundation, the organizer of the Global Titter Prize for 20, Peter Tabichi spends 5 percent of his monthly income on the poor. Peter Tabichi has been awarded for recognizing a school in the Rift Valley village as one of the best schools in the country. After receiving the award, Tabich says, \"In Africa we are adding new pages and new chapters every day. This award recognizes the efforts of the young people of this continent, not me. I stand here today because of the success of my schoolteachers.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 195 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t = translator.translate(\"This time the digital desk: Kenya\\'s teacher is one of the best teachers in the world, setting up a very ordinary school in a remote village in the country. He was recently given a prize and $ 1 million in Dubai in Dubai. Pawani, a remote village in Kenya\\'s dry rift valley. Peter Tabichi joined Carrick Mixed Day Secondary School as a math and physics teacher in this village. Five percent of the students in this school come from very poor families. At a time when the basics of study were not up to the mark, the school recently excelled in the national science competition. And the key to this school\\'s success is the 4-year-old marksman and physics teacher Tabichi. According to the Varki Foundation, the organizer of the Global Titter Prize for 20, Peter Tabichi spends 5 percent of his monthly income on the poor. Peter Tabichi has been awarded for recognizing a school in the Rift Valley village as one of the best schools in the country. After receiving the award, Tabich says, 'In Africa we are adding new pages and new chapters every day. This award recognizes the efforts of the young people of this continent, not me. I stand here today because of the success of my schoolteachers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This time the digital desk: Kenya's teacher is one of the best teachers in the world, setting up a very ordinary school in a remote village in the country. He was recently given a prize and $ 1 million in Dubai in Dubai. Pawani, a remote village in Kenya's dry rift valley. Peter Tabichi joined Carrick Mixed Day Secondary School as a math and physics teacher in this village. Five percent of the students in this school come from very poor families. At a time when the basics of study were not up to the mark, the school recently excelled in the national science competition. And the key to this school's success is the 4-year-old marksman and physics teacher Tabichi. According to the Varki Foundation, the organizer of the Global Titter Prize for 20, Peter Tabichi spends 5 percent of his monthly income on the poor. Peter Tabichi has been awarded for recognizing a school in the Rift Valley village as one of the best schools in the country. After receiving the award, Tabich says, 'In Africa we are adding new pages and new chapters every day. This award recognizes the efforts of the young people of this continent, not me. I stand here today because of the success of my schoolteachers.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "kinship (1).ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
